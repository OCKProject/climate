<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="review-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Philos Trans A Math Phys Eng Sci</journal-id><journal-id journal-id-type="iso-abbrev">Philos Trans A Math Phys Eng Sci</journal-id><journal-id journal-id-type="publisher-id">RSTA</journal-id><journal-id journal-id-type="hwp">roypta</journal-id><journal-title-group><journal-title>Philosophical transactions. Series A, Mathematical, physical, and engineering sciences</journal-title></journal-title-group><issn pub-type="ppub">1364-503X</issn><issn pub-type="epub">1471-2962</issn><publisher><publisher-name>The Royal Society Publishing</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6388006</article-id><article-id pub-id-type="doi">10.1098/rsta.2018.0147</article-id><article-id pub-id-type="publisher-id">rsta20180147</article-id><article-categories><subj-group subj-group-type="hwp-journal-coll"><subject>1003</subject><subject>50</subject><subject>1008</subject><subject>119</subject><subject>168</subject></subj-group><subj-group subj-group-type="heading"><subject>Articles</subject></subj-group><subj-group subj-group-type="leader"><subject>Review Article</subject></subj-group></article-categories><title-group><article-title>Mastering the scales: a survey on the benefits of multiscale computing software</article-title><alt-title alt-title-type="short">multiscale computing software benefits</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-7463-3765</contrib-id><name><surname>Groen</surname><given-names>Derek</given-names></name><xref ref-type="aff" rid="af1">1</xref><xref ref-type="corresp" rid="cor1"/></contrib><contrib contrib-type="author"><name><surname>Knap</surname><given-names>Jaroslaw</given-names></name><xref ref-type="aff" rid="af2">2</xref></contrib><contrib contrib-type="author"><name><surname>Neumann</surname><given-names>Philipp</given-names></name><xref ref-type="aff" rid="af3">3</xref></contrib><contrib contrib-type="author"><name><surname>Suleimenova</surname><given-names>Diana</given-names></name><xref ref-type="aff" rid="af1">1</xref></contrib><contrib contrib-type="author"><name><surname>Veen</surname><given-names>Lourens</given-names></name><xref ref-type="aff" rid="af4">4</xref></contrib><contrib contrib-type="author"><name><surname>Leiter</surname><given-names>Kenneth</given-names></name><xref ref-type="aff" rid="af2">2</xref></contrib></contrib-group><aff id="af1"><label>1</label><addr-line>Department of Computer Science</addr-line>, <institution>Brunel University London</institution>, <addr-line>Uxbridge</addr-line>, <country>UK</country></aff><aff id="af2"><label>2</label><addr-line>US Army Research Laboratory</addr-line>, <addr-line>Aberdeen Proving Ground</addr-line>, <addr-line>Aberdeen, MD</addr-line>, <addr-line>USA</addr-line></aff><aff id="af3"><label>3</label><addr-line>Department of Scientific Computing</addr-line>, <institution>University of Hamburg</institution>, <addr-line>Hamburg</addr-line>, <country>Germany</country></aff><aff id="af4"><label>4</label><addr-line>Netherlands eScience Center</addr-line>, <addr-line>Amsterdam</addr-line>, <country>The Netherlands</country></aff><author-notes><corresp id="cor1">e-mail:
<email>derek.groen@brunel.ac.uk</email></corresp><fn fn-type="other"><p>Electronic supplementary material is available online at <uri xlink:href="https://dx.doi.org/10.6084/m9.figshare.c.4352660">https://dx.doi.org/10.6084/m9.figshare.c.4352660</uri>.</p></fn><fn fn-type="other"><p>One contribution of 11 to a theme issue &#x02018;<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsta/377/2142">Multiscale modelling, simulation and computing: from the desktop to the exascale</ext-link>&#x02019;.</p></fn></author-notes><pub-date pub-type="ppub"><day>8</day><month>4</month><year>2019</year></pub-date><pub-date pub-type="epub"><day>18</day><month>2</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>18</day><month>2</month><year>2019</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. --><volume>377</volume><issue>2142</issue><issue-title>Theme issue &#x02018;Multiscale modelling, simulation and computing: from the desktop to the exascale&#x02019; compiled and edited by Alfons G. Hoekstra, Simon Portegies Zwart and Peter Coveney</issue-title><elocation-id>20180147</elocation-id><history><date date-type="accepted"><day>6</day><month>11</month><year>2018</year></date></history><permissions><copyright-statement>&#x000a9; 2019 The Authors.</copyright-statement><copyright-year>2019</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>Published by the Royal Society under the terms of the Creative Commons Attribution License <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>, which permits unrestricted use, provided the original author and source are credited.</license-p></license><?release-delay 0|0?></permissions><self-uri content-type="pdf" xlink:href="rsta20180147.pdf"/><abstract><p>In the last few decades, multiscale modelling has emerged as one of the dominant modelling paradigms in many areas of science and engineering. Its rise to dominance is primarily driven by advancements in computing power and the need to model systems of increasing complexity. The multiscale modelling paradigm is now accompanied by a vibrant ecosystem of multiscale computing software (MCS) which promises to address many challenges in the development of multiscale applications. In this paper, we define the common steps in the multiscale application development process and investigate to what degree a set of 21 representative MCS tools enhance each development step. We observe several gaps in the features provided by MCS tools, especially for application deployment and the preparation and management of production runs. In addition, we find that many MCS tools are tailored to a particular multiscale computing pattern, even though they are otherwise application agnostic. We conclude that the gaps we identify are characteristic of a field that is still maturing and features that enhance the deployment and production steps of multiscale application development are desirable for the long-term success of MCS in its application fields.</p><p>This article is part of the theme issue &#x02018;Multiscale modelling, simulation and computing: from the desktop to the exascale&#x02019;.</p></abstract><kwd-group><kwd>multiscale computing</kwd><kwd>multiscale modelling</kwd><kwd>multiscale simulation</kwd><kwd>high-performance computing</kwd><kwd>usability</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution>European Union's Horizon 2020 Research and Innovation Programme</institution></institution-wrap></funding-source><award-id>800925</award-id><award-id>671564</award-id></award-group><award-group><funding-source><institution-wrap><institution>Task-based load balancing and auto-tuning in particle simulations</institution></institution-wrap></funding-source><award-id>01IH16008B</award-id></award-group></funding-group><custom-meta-group><custom-meta><meta-name>cover-date</meta-name><meta-value>April 8, 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><label>1.</label><title>Introduction</title><p>Many phenomena in science and engineering are amenable to multiscale modelling. Multiscale modelling is a divide-and-conquer paradigm in which multiscale models are built as assemblies of individual unit processes, often also referred to as at-scale models, operating at distinct spatial or temporal scales. With the inclusion of relevant unit processes, multiscale models are capable of accurately characterizing phenomena in regimes not easily observed <italic>in vivo</italic> or <italic>in vitro</italic>. Multiscale modelling is primarily a computational endeavour and, over the last two decades, a range of supporting software has emerged for building computational multiscale models, for example, facilitating the <italic>coupling</italic> of existing at-scale models, enabling the use of (remote) high-performance computing resources, or simplifying the management of multiscale simulation runs through automation. Although current <italic>multiscale computing software</italic> (MCS) has been shown to provide benefits, as evidenced by their uptake [<xref rid="RSTA20180147C1" ref-type="bibr">1</xref>,<xref rid="RSTA20180147C2" ref-type="bibr">2</xref>], we seek to more clearly analyse their current added value to the multiscale application development process, and find previously under-prioritized areas in which software could provide further support.</p><p>In this article, we define MCS as software that provides added value during one or more stages of the multiscale application development process, and has an explicitly formulated orientation towards multiscale, multiphysics, multimodel or other coupled applications. Using this definition, we then analyse a representative set of existing MCS in order to establish the current state of the art in MCS, identify the main obstacles preventing a widespread adoption of MCS in science and engineering, and chart a path forward for development of the next-generation MCS. To that end, we start by summarizing the recent developments in MCS in &#x000a7;<xref ref-type="sec" rid="s2">2</xref>, review the common steps in the process of developing a multiscale application in &#x000a7;<xref ref-type="sec" rid="s3">3</xref>, and reflect on the scope, advantages and drawbacks of adopting generic MCS in &#x000a7;<xref ref-type="sec" rid="s4">4</xref>. In &#x000a7;<xref ref-type="sec" rid="s5">5</xref>, we present our analysis approach, followed by an overview of key results from our analysis in &#x000a7;<xref ref-type="sec" rid="s6">6</xref>, and a discussion with conclusion in &#x000a7;<xref ref-type="sec" rid="s7">7</xref>.</p></sec><sec id="s2"><label>2.</label><title>Recent developments in multiscale computing software</title><p>Following the formulation of mathematical foundations of multiscale modelling (cf. [<xref rid="RSTA20180147C3" ref-type="bibr">3</xref>,<xref rid="RSTA20180147C4" ref-type="bibr">4</xref>] for an overview), computational aspects of multiscale modelling have only recently become the focus of the scientific community. This interest has yielded a number of MCS aiming to ease creation of multiscale models, especially those relying on modern high-performance computing architectures. In particular, emerging exascale computing architectures present both a challenge and an opportunity for MCS development [<xref rid="RSTA20180147C5" ref-type="bibr">5</xref>]. On the one hand, exascale computers promise to provide an unprecedented compute capacity, most probably required for multiscale modelling. On the other hand, in order to fully harness this capacity, significant algorithmic advances are necessary to handle fault tolerance and robustness, heterogeneity of processors and memory and energy-efficiency, to name a few.</p><p>Multiscale modelling is a divide-and-conquer endeavour. Relevant scales, both temporal and spatial, are identified and models developed at each individual scale. These at-scale models are then combined to form a multiscale model. The description of a multiscale model can be formally handled by means of the scale-separation map which defines the individual scales in a multiscale model along with the interactions between scales [<xref rid="RSTA20180147C6" ref-type="bibr">6</xref>]. The scale separation map is often encoded in the multiscale modelling language (MML), a descriptive language for multiscale model development [<xref rid="RSTA20180147C7" ref-type="bibr">7</xref>]. More recently, multiscale computing patterns (MCP), higher-level abstractions serving as a basis for more generic MCS software, have been introduced [<xref rid="RSTA20180147C8" ref-type="bibr">8</xref>]. MCP are categories of multiscale models that exhibit common scale-separation maps and coupling topologies between model components. Example MCP include the Extreme Scaling (ES) pattern where a single at-scale model dominates computational cost within a multiscale model, the Heterogeneous Multiscale Computing (HMC) pattern based on the heterogeneous multiscale method (HMM) [<xref rid="RSTA20180147C4" ref-type="bibr">4</xref>] where many microscale models are coupled to a macroscale model and launched on-demand, and the Replica Computing (RC) pattern where a large number of individual model ensembles are evaluated under a range of initial conditions.</p><p>By their nature, multiscale models are composed of individual at-scale (or single scale) model components. Each at-scale component is frequently a complex parallel software developed over many years. This fact has motivated a shift away from monolithic approaches to multiscale model development and towards more heterogeneous component-based approaches, capable of incorporating existing at-scale models with minimal software modifications. One such approach, the cooperative parallelism programming model, is a task-based multiple-program multiple-data approach to parallel programming [<xref rid="RSTA20180147C9" ref-type="bibr">9</xref>]. In cooperative parallelism, single unit computation tasks named symponents (a portmanteau of simulation and component) are executed by a runtime system. Symponents are able to interact dynamically with the runtime system to launch, communicate with, and destroy additional symponent calculations. The Co-op MCS implements the cooperative parallelism programming model and leverages the Babel software [<xref rid="RSTA20180147C10" ref-type="bibr">10</xref>] to integrate symponents together that are written in different programming languages [<xref rid="RSTA20180147C11" ref-type="bibr">11</xref>,<xref rid="RSTA20180147C12" ref-type="bibr">12</xref>]. The cooperative parallelism programming model is well-suited for development of multiscale models [<xref rid="RSTA20180147C13" ref-type="bibr">13</xref>] and the Co-op MCS has been successfully employed for multiscale modelling of materials [<xref rid="RSTA20180147C14" ref-type="bibr">14</xref>].</p><p>Owing to the modularity of the cooperative parallelism approach, developers can easily mix-and-match various at-scale models and incorporate surrogate models to reduce computational cost. For example, adaptive sampling algorithms have been developed within the Co-op system to automatically construct surrogate models during multiscale model evaluation [<xref rid="RSTA20180147C15" ref-type="bibr">15</xref>]. In adaptive sampling, input and output data obtained from evaluation of at-scale model components are used to construct surrogate models that are stored in a metric-tree database. The surrogate models are much cheaper to compute and can often be evaluated in place of at-scale models with manageable errors. The use of adaptive sampling techniques in a multiscale model can reduce computational cost by several orders of magnitude [<xref rid="RSTA20180147C14" ref-type="bibr">14</xref>,<xref rid="RSTA20180147C16" ref-type="bibr">16</xref>]. Moreover, the modular nature of the Co-op system allows for the use of adaptive sampling techniques in any multiscale model developed within the framework. In addition to its implementation in Co-op, the adaptive sampling method has been released in software as the Adaptive Sampling Proxy Application (ASPA) [<xref rid="RSTA20180147C17" ref-type="bibr">17</xref>].</p><p>A modular component-based approach to multiscale modelling is also fundamental to the Multiscale Coupling Library and Environment (MUSCLE) [<xref rid="RSTA20180147C18" ref-type="bibr">18</xref>]. The MUSCLE software has matured over many years and several different versions have been released. The original MUSCLE is tailored to complex automata modelling and multi-agent computing [<xref rid="RSTA20180147C19" ref-type="bibr">19</xref>&#x02013;<xref rid="RSTA20180147C21" ref-type="bibr">21</xref>]. A subsequent version, MUSCLE 2, is designed for distributed multiscale computation where at-scale model components execute across disparate and potentially geographically separate computers [<xref rid="RSTA20180147C22" ref-type="bibr">22</xref>]. MUSCLE 2 is able to incorporate at-scale model components written in a variety of programming languages including Java, C, C++, Python and Fortran and is able to directly generate runtime configurations using the MML specification of a multiscale model. Among other things it has been embedded in the VPH Hypermodelling Framework [<xref rid="RSTA20180147C23" ref-type="bibr">23</xref>]. The newest version, MUSCLE 3, aims to more tightly integrate an extended version of the MML, with better support for dynamic submodel instantiation, surrogate modelling and uncertainty quantification and sensitivity analysis.</p><p>Another computational framework for scale-bridging in multiscale modelling is the Hierarchical Multiscale Simulation (HMS) framework [<xref rid="RSTA20180147C24" ref-type="bibr">24</xref>]. The HMS framework closely follows the HMM for multiscale model construction. HMS combines hierarchies of at-scale model components together and implements a runtime system to schedule and execute at-scale models on available computational resources. Each at-scale model component is taken to be a standalone executable written in any programming language to ease incorporation of existing complex at-scale models into a multiscale model. The HMS framework has been extended to allow for execution of at-scale model components across multiple high-performance computers [<xref rid="RSTA20180147C25" ref-type="bibr">25</xref>]. In addition, an adaptive sampling algorithm has been introduced into the framework to reduce computational expense [<xref rid="RSTA20180147C16" ref-type="bibr">16</xref>].</p><p>MCS has also arisen within a number of scientific areas, including astrophysics, climate modelling, materials modelling, plasma physics and systems biology [<xref rid="RSTA20180147C2" ref-type="bibr">2</xref>]. An exhaustive bibliography of multiphysics and multiscale software frameworks through 2015 has been provided in [<xref rid="RSTA20180147C1" ref-type="bibr">1</xref>]. These MCS are frequently tailored to a particular phenomenon under consideration by each community. Yet, they are often sufficiently generic to be adapted to other areas with minimal effort. One example in astrophysics, the Astrophysical Multipurpose Software Environment (AMUSE), is a Python-based software framework to combine simulation codes together for astrophysical simulations [<xref rid="RSTA20180147C26" ref-type="bibr">26</xref>]. AMUSE includes a large number of community astrophysics simulation codes to handle gravitational dynamics, stellar evolution, hydrodynamics, and radiative transfer and implements user-friendly features including a unit algebra model to simplify unit-conversions between models in the framework. The AMUSE approach has been proven successful and it now serves as the basis for the Oceanographic Multipurpose Software Environment (OMUSE) for ocean modelling [<xref rid="RSTA20180147C27" ref-type="bibr">27</xref>]. Other MCS for atmosphere and ocean modelling includes The Earth System Modelling Framework (ESMF), a component-based software platform under development since the early 2000s [<xref rid="RSTA20180147C28" ref-type="bibr">28</xref>].</p><p>For materials science applications, the Exascale Co-design Center for Materials in Extreme Environments (ExMatEx) has developed a number of MCS [<xref rid="RSTA20180147C29" ref-type="bibr">29</xref>]. ExMatEx has placed a particular emphasis on new exascale computing architectures as an enabler for new approaches to multiscale modelling including task-based computation and adaptive fault-tolerant algorithms [<xref rid="RSTA20180147C30" ref-type="bibr">30</xref>]. In order to facilitate the creation of new multiscale computing algorithms, ExMatEx has developed a number of proxy apps: simplified at-scale models which mimic the computational workload of more complex models. The proxy apps are designed to be simpler to work with than more complex models for the development of new multiscale computing algorithms. Through the use of the proxy apps, ExMatEx has created and released several software packages for multiscale computing. The Task-based Scale-bridging Code (TaBaSCo) uses Charm++ to execute an adaptive and asynchronous task-based computation of an embedded viscoplasticity model (CoEVP) for the constitutive response of a continuum model of Lagrangian hydrodynamics [<xref rid="RSTA20180147C31" ref-type="bibr">31</xref>,<xref rid="RSTA20180147C32" ref-type="bibr">32</xref>]. The software is written to evaluate multiscale computing approaches on the Trinity Advanced Technology System supercomputer, a pre-exascale system at Los Alamos National Laboratory. Another software, the Distributed Database Kriging for Adaptive Sampling (D<sup>2</sup>KAS) implements a redis in-memory data store in combination with locally aware hashing to construct and evaluate kriging surrogate models on-the-fly from at-scale model data [<xref rid="RSTA20180147C33" ref-type="bibr">33</xref>]. A twist on the adaptive sampling approach is a method which avoids use of a data store entirely, but samples an at-scale model at a set of spatial points at each timestep to construct a surrogate model using Akima splines [<xref rid="RSTA20180147C34" ref-type="bibr">34</xref>].</p><p>In systems biology, the ENteric Immunity Simulator Multi-scale Modelling (ENISI MSM) is a Java-based system for multiscale modelling of immunological processes [<xref rid="RSTA20180147C35" ref-type="bibr">35</xref>]. ENISI MSM combines together agent-based models, ordinary differential equation-based models, and partial differential equation-based models along with a visualization interface to control the simulation. A recent version of ENISI MSM has been released for high-performance computing environments.</p><p>In addition to the task-based integrative frameworks for multiscale modelling described above, there exist a number of coupling frameworks for multiphysics and multiscale modelling. Coupling frameworks are mainly designed to facilitate the exchange of data between different models. Such data exchange occurs at an interface or handshake region between models, as is often the case in partitioned-domain multiscale methods [<xref rid="RSTA20180147C36" ref-type="bibr">36</xref>]. Coupling frameworks typically implement methods for the interpolation of data between different meshes and parallel data exchange between individual processes in each model. Software implementing this type of coupling includes the Model Coupling Toolkit (MCT) [<xref rid="RSTA20180147C37" ref-type="bibr">37</xref>] and Multiscale Universal Interface [<xref rid="RSTA20180147C38" ref-type="bibr">38</xref>]. MCT has been employed in OASIS-MCT to couple two-dimensional fields for climate system modelling [<xref rid="RSTA20180147C39" ref-type="bibr">39</xref>]. The Macro-Micro-Coupling Tool (MaMiCo) enables coupling molecular dynamics and computational fluid dynamics codes and includes capabilities to perform ensemble sampling of molecular dynamics trajectories to obtain statistically converged flow field quantities [<xref rid="RSTA20180147C40" ref-type="bibr">40</xref>,<xref rid="RSTA20180147C41" ref-type="bibr">41</xref>].</p><p>Since multiscale models are inherently complex software with individual components which are themselves large-scale parallel applications, tools to aid developers and users of multiscale models are required for multiscale modelling approaches to become widely adopted. For example, the deployment of a multiscale model across multiple high-performance computers where each system has a different compiler suite, MPI version, node configuration, etc., still presents a formidable challenge. Fortunately, these needs are not unique to multiscale modelling, and it is likely that software tools developed in other areas, for example in cloud-based distributed systems, can be easily adopted to form a complete MCS stack.</p><p>One effort to address the relative lack of supportive tools for deployment of multiscale models is FabSim [<xref rid="RSTA20180147C42" ref-type="bibr">42</xref>]. FabSim aims for reproducible execution of complex workflows across multiple high-performance computers and has been successfully applied to multiscale models requiring ensembles of molecular dynamics simulations [<xref rid="RSTA20180147C43" ref-type="bibr">43</xref>], as well as blood flow [<xref rid="RSTA20180147C44" ref-type="bibr">44</xref>]. A larger framework like Automated Interactive Infrastructure and Database for computational science (AiiDA) [<xref rid="RSTA20180147C45" ref-type="bibr">45</xref>] can also be used for this purpose, while tools such as Longbow [<xref rid="RSTA20180147C46" ref-type="bibr">46</xref>] are suitable alternatives for running single jobs remotely using quick one-liner commands. Workflow packages which can be used to help execute multiscale applications include the Kepler Project [<xref rid="RSTA20180147C47" ref-type="bibr">47</xref>], the Swift scripting language [<xref rid="RSTA20180147C48" ref-type="bibr">48</xref>], the Ensemble Toolkit [<xref rid="RSTA20180147C49" ref-type="bibr">49</xref>] and Parsl [<xref rid="RSTA20180147C50" ref-type="bibr">50</xref>] which allow for development and execution of parallel workflows involving many individual programmes across clouds and supercomputers.</p></sec><sec id="s3"><label>3.</label><title>Multiscale computing applications: the development process</title><p>Before assessing in what ways MCS can benefit the developer of multiscale computing applications, we review a number of common steps we recognize in the development process for multiscale applications.</p><p>We identify the typical steps required when developing a multiscale computing application in <xref ref-type="fig" rid="RSTA20180147F1">figure 1</xref>. Development starts with the design of the conceptual models to address a scientific challenge of interest (Design Step). This includes selecting necessary single-scale models and determining which of these need to be coupled directly. Next, the computational models are adapted, and coupling mechanisms are implemented to facilitate the transport of data between the submodels (Implementation Step). This can, for example, be done using coupling libraries or workflow tools. Once the single-scale models and coupling mechanisms have been established, the implementation can be applied to the specific scientific problem of interest (Instantiation). This includes adding relevant data and parameters, e.g. force field definitions and initial particle configurations for a multiscale molecular application.
<fig id="RSTA20180147F1" orientation="portrait" position="float"><label>Figure 1.</label><caption><p>Overview of a typical process for developing multiscale computing applications. (Online version in colour.)</p></caption><graphic xlink:href="rsta20180147-g1"/></fig></p><p>After Instantiation, the application is made operational at the target platform (e.g. cluster, cloud or supercomputer, Deployment Step), upon which it is (initially) run (Execution Step). Deployment is complicated due to the fact that various single-scale models and their coupling have to be orchestrated, potentially on a heterogeneous platform (CPU/GPU supercomputer) or even multiple platforms (combining clusters or working in a cloud). After the initial run, the application is usually subject to a cycle of further optimizations (Optimization Step) and executions (or repetitions of earlier steps as needed). Optimization in the context of this paper refers to bolstering the scientific and technical quality of the application such that it becomes suitable for use in production runs. This may involve fixing verification or validation issues that arose during execution, rerunning the application multiple times to test the sensitivity of key parameters, or to check the propagation of uncertainties in the model. Once the application has been sufficiently optimized, researchers proceed with performing the main runs (Production Step) and analyse its output data (Analysis Step). Lastly, researchers disseminate their work by publishing key results, and/or the software approach that they have developed to obtain these results (Dissemination Step).</p></sec><sec id="s4"><label>4.</label><title>The role of multiscale computing software</title><p>We define MCS as software which adds value during one or more stages of the multiscale application development process, and has an explicitly formulated orientation towards multiscale, multiphysics, multimodel or coupled applications. Arguably, there are six steps in the multiscale application development process where MCS can provide added value: (1) Implementation, (2) Instantiation, (3) Deployment, (4) Execution, (5) Optimization and (6) Production.</p><p>In this work, we investigate the added value of a range of MCS, attempting to include an example of each type that is commonly used. Because the number of MCS packages is very large, our analysis is not exhaustive, but focuses on major examples of each specific type that we are aware of, and that are publicly available. For example, our analysis of the potential added value of the OpenFOAM multiphysics code [<xref rid="RSTA20180147C51" ref-type="bibr">51</xref>] will apply to a large extent to other multiphysics codes, such as Elmer or LAMMPS [<xref rid="RSTA20180147C52" ref-type="bibr">52</xref>]. Likewise, analysis concerning the widely used OASIS-MCT coupler similarly helps to determine the added value of other couplers, such as C-Coupler1 [<xref rid="RSTA20180147C53" ref-type="bibr">53</xref>] or YAC [<xref rid="RSTA20180147C54" ref-type="bibr">54</xref>].</p><sec id="s4a"><title/><sec id="s4a1"><label>(i)</label><title>Scope</title><p>An important aspect of MCS is the intended scope of the software. Here we briefly reflect on a few relevant scopes of applicability for these tools, from more specific to more generic. Software can be instance-specific (e.g. written ad-hoc for a single run or typed into an interactive terminal), problem-specific (e.g. custom-made for a clay-polymer MD simulation), system-specific (e.g. tailored for MD simulations), discipline-specific (e.g. intended for materials science applications) or generic. More generic software tends to have a stronger focus on ease of reuse, serves a larger community and tends to get scrutiny from people with a wider range of academic backgrounds. However, a major drawback is the need to engineer the software for a wider range of possible use cases, which may increase the effort required to develop more generic MCS.</p><p>Reusability may be limited not only to the extent that MCS is generic from a scientific perspective. Other limitations, such as restrictions on supported codes, programming languages, user types, operating systems or resource platforms can further limit both the reusability of MCS, and other aspects such as the maximum attainable size of its user community.</p></sec><sec id="s4a2"><label>(ii)</label><title>Advantages</title><p>Many different kinds of added value can be provided by MCS, but for the purposes of this work we place any added value advertised by these tools within four categories, each of which may apply to the aforementioned six steps in the development process.</p><p>Software may help <italic>Curate</italic> multiscale applications, e.g. by making activities more reproducible, more organized, more transparent and/or easier to scrutinize. Software may help to <italic>Accelerate</italic> multiscale applications by speeding up the progress in a process step, or to <italic>Simplify</italic> by reducing the amount of skills and knowledge needed to perform that step. Lastly, MCS may <italic>Expand</italic> the range of possibilities for the developer by introducing alternative approaches, or by providing more flexible use of existing ones.</p></sec><sec id="s4a3"><label>(iii)</label><title>Drawbacks</title><p>Adopting generic software for multiscale computing provides clear benefits, but choosing more generic tools over more specific ones comes with a range of drawbacks as well. These drawbacks are described in detail in <xref rid="RSTA20180147TB1" ref-type="table">table 1</xref>.
<table-wrap id="RSTA20180147TB1" orientation="portrait" position="float"><label>Table 1.</label><caption><p>Overview of drawbacks when using generic MCS</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">type</th><th align="left" rowspan="1" colspan="1">description of drawback</th><th align="left" rowspan="1" colspan="1">example means of mitigation</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">adoption overhead</td><td rowspan="1" colspan="1">it takes time to understand and set up software which is written by others</td><td rowspan="1" colspan="1">good and simple build systems, clear documentation, tutorials</td></tr><tr><td rowspan="1" colspan="1">application overhead</td><td rowspan="1" colspan="1">it takes time to introduce domain- or problem-specific in a generic setting, and to modify generic code to facilitate an unexpected situation</td><td rowspan="1" colspan="1">make MCS non-intrusive, limit the range of features provided by the MCS, clear documentation, tutorials</td></tr><tr><td rowspan="1" colspan="1">search overhead</td><td rowspan="1" colspan="1">it can take time to find the right software (or it might not exist at all)</td><td rowspan="1" colspan="1">create search directories, pursue good citation practices of directly used and closely related MCS in scientific articles</td></tr><tr><td rowspan="1" colspan="1">increased support requirements</td><td rowspan="1" colspan="1">more support effort is necessary due to a larger community size, leading to less support per user</td><td rowspan="1" colspan="1">establish a self-supporting user community</td></tr><tr><td rowspan="1" colspan="1">lack of control and/or ownership</td><td rowspan="1" colspan="1">development is frequently managed by others, reduced academic credit due to not developing own tools, no control over the software installation in the case of software as a service</td><td rowspan="1" colspan="1">make code open-source, support branching developments and spin-offs, avoid centralized installations, make a clear case against reinventing the wheel</td></tr></tbody></table></table-wrap>
</p><p>We argue that the first four of these five drawbacks apply less frequently when choosing domain- or system-specific MCS, while the fifth drawback applies to any type of externally owned or controlled software. Though a detailed drawback analysis is beyond the scope of this work, we do recommend that application developers consider these possible drawbacks prior to adopting new MCS, and that MCS developers attempt to identify and mitigate the most serious drawbacks in their software.</p></sec></sec></sec><sec id="s5"><label>5.</label><title>Analysis approach</title><p>We have collectively gathered data on a range of MCS, allowing all authors to submit information about specific tools into a database using a Google Form. Each tool was examined by at least two of the authors. An empty example form is provided in the electronic supplementary information as a reference. As a starting point, we investigated a subset of the software presented by Groen <italic>et al</italic>. [<xref rid="RSTA20180147C2" ref-type="bibr">2</xref>], upon which we then manually searched for more recent MCS. We recorded 26 tools in total, and chose to analyse 21 of them. Of the analysed tools, 20 of them are freely available to the public, while 1 tool (HMS) was freely available to the authors, and is expected to be released freely to the public in early 2019. The other five tools were omitted either because we could not access their public website or because they had been superseded with newer tools.</p></sec><sec id="s6"><label>6.</label><title>Results</title><sec id="s6a"><label>(a)</label><title>High-level overview</title><p>We provide a brief overview of the scope and supported platforms and patterns in <xref rid="RSTA20180147TB2" ref-type="table">table 2</xref>. Here, we find that C++ is the most widely supported language, although Python is also quite prevalent. In terms of MCPs, we see a clear segregation of tools, with a large number of tools providing support for one specific MCP. This is interesting, because the MCPs were introduced well after many of these tools were established [<xref rid="RSTA20180147C8" ref-type="bibr">8</xref>].
<table-wrap id="RSTA20180147TB2" orientation="portrait" position="float"><label>Table 2.</label><caption><p>Summary of MCS scope and platforms. The scope is given in the second column, supported programming languages in the third column, and supported multiscale computing patterns (Extreme Scaling (ES), Heterogeneous Multiscale Computing (HMC) or Replica Computing (RC)) in the fourth column.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">name</th><th align="left" rowspan="1" colspan="1">scope</th><th align="left" rowspan="1" colspan="1">supported languages</th><th align="left" rowspan="1" colspan="1">supported patterns</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">ASPA</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">C++</td><td rowspan="1" colspan="1">HMC</td></tr><tr><td rowspan="1" colspan="1">Amuse</td><td rowspan="1" colspan="1">discipline-specific</td><td rowspan="1" colspan="1">Python</td><td rowspan="1" colspan="1">ES,HMC,RC</td></tr><tr><td rowspan="1" colspan="1">Cactus</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">Custom (language of choice)</td><td rowspan="1" colspan="1">HMC</td></tr><tr><td rowspan="1" colspan="1">CoHMM/D2KAS</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">C++</td><td rowspan="1" colspan="1">HMC</td></tr><tr><td rowspan="1" colspan="1">CouPE</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">C++, FORTRAN, Wrappers for C/C++/Fortran modules exist (explains my answer here)</td><td rowspan="1" colspan="1">ES,HMC</td></tr><tr><td rowspan="1" colspan="1">ELMER</td><td rowspan="1" colspan="1">system-specific</td><td rowspan="1" colspan="1">C++, FORTRAN, C</td><td rowspan="1" colspan="1">ES</td></tr><tr><td rowspan="1" colspan="1">ENISI MSM</td><td rowspan="1" colspan="1">discipline-specific</td><td rowspan="1" colspan="1">Java</td><td rowspan="1" colspan="1">ES</td></tr><tr><td rowspan="1" colspan="1">ESMF</td><td rowspan="1" colspan="1">discipline-specific</td><td rowspan="1" colspan="1">C++, FORTRAN</td><td rowspan="1" colspan="1">ES,HMC,RC</td></tr><tr><td rowspan="1" colspan="1">FLASH</td><td rowspan="1" colspan="1">discipline-specific</td><td rowspan="1" colspan="1">FORTRAN</td><td rowspan="1" colspan="1">ES</td></tr><tr><td rowspan="1" colspan="1">FabSim</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">Python</td><td rowspan="1" colspan="1">ES,HMC,RC</td></tr><tr><td rowspan="1" colspan="1">HMS</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">Python, C++, FORTRAN</td><td rowspan="1" colspan="1">RC</td></tr><tr><td rowspan="1" colspan="1">MOOSE</td><td rowspan="1" colspan="1">system-specific</td><td rowspan="1" colspan="1">C++</td><td rowspan="1" colspan="1">ES,HMC</td></tr><tr><td rowspan="1" colspan="1">MPWide</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">Python, C++, C</td><td rowspan="1" colspan="1">ES</td></tr><tr><td rowspan="1" colspan="1">MUI</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">C++</td><td rowspan="1" colspan="1">ES</td></tr><tr><td rowspan="1" colspan="1">MUSCLE2</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">Python, C++, Java, FORTRAN, Ruby, C, Matlab</td><td rowspan="1" colspan="1">ES</td></tr><tr><td rowspan="1" colspan="1">MaMiCo</td><td rowspan="1" colspan="1">system-specific</td><td rowspan="1" colspan="1">C++, command-line (e.g. bash), SCons for compiling</td><td rowspan="1" colspan="1">ES,HMC</td></tr><tr><td rowspan="1" colspan="1">OASIS3-MCT_3.0</td><td rowspan="1" colspan="1">discipline-specific</td><td rowspan="1" colspan="1">FORTRAN, C</td><td rowspan="1" colspan="1">ES</td></tr><tr><td rowspan="1" colspan="1">OMFIT</td><td rowspan="1" colspan="1">discipline-specific</td><td rowspan="1" colspan="1">Python</td><td rowspan="1" colspan="1">ES,HMC,RC</td></tr><tr><td rowspan="1" colspan="1">Parsl</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">Python</td><td rowspan="1" colspan="1">RC</td></tr><tr><td rowspan="1" colspan="1">Swift</td><td rowspan="1" colspan="1">generic</td><td rowspan="1" colspan="1">Domain-specific or bespoke language</td><td rowspan="1" colspan="1">ES,HMC,RC</td></tr><tr><td rowspan="1" colspan="1">TabaSCo</td><td rowspan="1" colspan="1">discipline-specific</td><td rowspan="1" colspan="1">C++, CHARM++</td><td rowspan="1" colspan="1">HMC</td></tr></tbody></table></table-wrap>
</p><p>We provide an overview of the added values from the tools in <xref ref-type="fig" rid="RSTA20180147F2">figure 2</xref>, using the approach we introduced earlier. This list includes 11 generic toolkits, 7 discipline-specific toolkits and 3 system-specific toolkits. In this figure, we can quickly distinguish several things. Firstly, tools that serve more development steps are shown with more filled boxes in the figure. Entries that contain all (or nearly all) filled boxes provide support throughout the development process, while entries with fewer filled boxes are more specific in their purpose. Using more specific tools can mitigate the adoption overhead, as there are fewer development steps that need to be incorporated. Second, the number of arrows inside each box helps indicate the completeness of added values a tool provides in that step. For example, MUSCLE 2 and MPWide both provide added value in the implementation step, but whereas MPWide only expands the range of options in this step, MUSCLE 2 also delivers curation and acceleration benefits due to it providing a more structured framework. This does not necessarily mean that MUSCLE 2 is the better option in all cases; the choice between the two may partially depend on the application need for curation and acceleration in the implementation step.
<fig id="RSTA20180147F2" orientation="portrait" position="float"><label>Figure 2.</label><caption><p>Overview of added value of the software tools. Here, the tools are provided one per row and the number of each relevant development step in each column (respectively (1) Implementation, (2) Instantiation, (3) Deployment, (4) Execution, (5) Optimization and (6) Production). Tools are sorted alphabetically. (Online version in colour.)</p></caption><graphic xlink:href="rsta20180147-g2"/></fig></p><p>We provide summary statistics for the added values in <xref rid="RSTA20180147TB3" ref-type="table">table 3</xref>. Although our review is far from exhaustive, and many tools we examine have counterparts that are somewhat similar (e.g. OpenFOAM to Elmer, AiiDA to FabSim), it does give a general impression of which areas of added value are targeted to which extent. Based on the results, we find that the tools in our study particularly focus on the Implementation step, and less on the Instantiation and Execution steps. In terms of added values, we recognize a strong focus on simplification and curation, with many of the more recently emerged tools particularly targeting the latter.
<table-wrap id="RSTA20180147TB3" orientation="portrait" position="float"><label>Table 3.</label><caption><p>Summation of added values from MCS in each development step</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/><col align="left" span="1"/></colgroup><thead valign="bottom"><tr><th align="left" rowspan="1" colspan="1">step</th><th align="left" rowspan="1" colspan="1">no. curate</th><th align="left" rowspan="1" colspan="1">no. accelerate</th><th align="left" rowspan="1" colspan="1">no. simplify</th><th align="left" rowspan="1" colspan="1">no. expand</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">implementation</td><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">12</td></tr><tr><td rowspan="1" colspan="1">instantiation</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">2</td></tr><tr><td rowspan="1" colspan="1">deployment</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">1</td></tr><tr><td rowspan="1" colspan="1">execution</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">2</td></tr><tr><td rowspan="1" colspan="1">optimization</td><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">1</td></tr><tr><td rowspan="1" colspan="1">production</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">2</td></tr><tr><td rowspan="1" colspan="1">total</td><td rowspan="1" colspan="1">27</td><td rowspan="1" colspan="1">29</td><td rowspan="1" colspan="1">46</td><td rowspan="1" colspan="1">20</td></tr></tbody></table></table-wrap>
</p><p>The table also exposes a range of clear added value gaps in our examined tools. We did not record any added value towards accelerating the optimization step (and relatively little added value overall), and tools provide even fewer features that help users during the production step. The strong focus of tools on earlier phases of the development process, and relative lack of focus on later phases, could be seen as an indicator that multiscale computing as a discipline has not yet fully matured.</p></sec><sec id="s6b"><label>(b)</label><title>Detailed analysis of selected tools</title><sec id="s6b1"><label>(i)</label><title>Adaptive Sampling Proxy Application</title><p>The Adaptive Sampling Proxy Application (ASPA) is a toolkit for automated construction of surrogate models within a multiscale model hierarchy. It allows developers across disciplines to construct kriging surrogate models on-the-fly using data obtained from the evaluation of at-scale model components of a multiscale model. ASPA uses a local kriging strategy to limit the amount of data incorporated in an individual surrogate model and contains a metric tree database to store the collection of surrogate models and allow for their quick retrieval. The adaptive sampling method is intended for use in applications that fit the HMC pattern, specifically for cases where a surrogate model is able to approximate the microscale model well for particular model inputs.</p><p><italic>Implementation</italic>. Expand. Expands the concept of multiscale simulation software. In addition to software consisting solely of coupled at-scale models, ASPA introduces a database to store surrogate models constructed using model output data and allows the surrogate models to be incrementally updated and quickly evaluated, including an error estimate.</p><p><italic>Instantiation, Deployment, Execution and Optimization</italic>. To the best of our knowledge, ASPA does not directly add value on these steps of the development process.</p><p><italic>Production</italic>. Accelerate and Expand. Accelerates evaluation of computationally demanding multiscale models and enables using surrogates in production.</p></sec><sec id="s6b2"><label>(ii)</label><title>MUSCLE 2</title><p>The MUltiScale Coupling Library and Environment 2 establishes couplings between at-scale model components in a systematic and discipline-agnostic manner. It takes a description of the model in terms of components and conduits between them, and executes the simulation accordingly by starting processes and opening TCP connections. Components must be linked with the MUSCLE 2 library, available in a range of languages, to be usable. Although it is not impossible to dynamically instantiate model components separately, MUSCLE 2 provides no support for this, and is mostly geared towards ES applications.</p><p><italic>Implementation</italic>. Curate, Accelerate and Expand. Requires the model structure to be clearly described, takes care of network communications and enables coupling of very diverse models.</p><p><italic>Instantiation</italic>. Curate and Accelerate. Unifies multiscale application definition and parameter values in a single archivable file.</p><p><italic>Execution</italic> Curate, Accelerate, Simplify. Model description includes directions for starting the full application. Can start up all components locally in a single command, automatically establishes network connections, and logs what was done.</p><p><italic>Deployment, Optimization and Production</italic>. To the best of our knowledge, MUSCLE 2 does not directly add value on these steps of the development process.</p></sec><sec id="s6b3"><label>(iii)</label><title>OASIS3-MCT</title><p>OASIS3-MCT is a so-called <italic>coupler</italic> which enables the coupling of models with a focus on climate model components. It originates from the Centre Europ&#x000e9;en de Recherche et Formation Avanc&#x000e9;e en Calcul Scientifique (CERFACS). OASIS3-MCT provides a high level of parallelism, and is particularly optimized for efficient interpolation and regridding as well as data exchange in coupled mesh-based applications.</p><p><italic>Implementation</italic>. Expand. OASIS3-MCT supports one-to-many concurrent couplings, a feature which is relatively rare in other toolkits.</p><p><italic>Deployment</italic>. Simplify. Provides a wrapper which makes deployment of all models easier.</p><p><italic>Execution</italic>. Accelerate. OASIS3-MCT supports parallel coupling channels using MPI, clearly improving performance compared to single MPI channels, or TCP/file I/O communications. The toolkit as a whole is also heavily optimized to be fast.</p><p><italic>Instantiation, Optimization and Production</italic>. To the best of our knowledge, OASIS3-MCT does not directly add value on these steps of the development process.</p></sec><sec id="s6b4"><label>(iv)</label><title>OMFIT</title><p>OMFIT is a model coupling framework which features a GUI, and is used extensively in the Fusion community. Its implementation is generic, and supports the use of parallel codes on HPC resources. It has a large range of supported modules built-in, which provide both physics solvers as well as other functionalities such a integrations with data sources and visualization tools.</p><p><italic>Implementation</italic>. Simplify, Expand. Provides a wide range of modules that can be easily coupled, and a GUI to simplify the process of making couplings.</p><p><italic>Instantiation</italic>. Accelerate, Simplify. Integrates with a range of experimental databases, which makes instantiation simpler and faster in a range of cases.</p><p><italic>Execution</italic>. Simplify. OMFIT allows predefining coupling schemes, and simplify doing test runs in that way.</p><p><italic>Optimization</italic>. Simplify, Expand. Supports a range of analysis and visualization techniques to make this step more flexible and simpler.</p><p><italic>Deployment and Production</italic>. To the best of our knowledge, OMFIT does not directly add value on these steps of the development process.</p></sec><sec id="s6b5"><label>(v)</label><title>Parsl</title><p>Parsl is a Python-based parallel scripting library that supports development and execution of asynchronous and parallel data-oriented workflows (dataflows). These workflows glue together existing executables (called Apps) and Python functions with control logic written in Python. Parsl brings implicit parallel execution to standard Python scripts.</p><p><italic>Implementation</italic>. Curate, Simplify, Expand. Provides a dependency-driven workflow model. Allows creation of complex workflow using any infrastructure (from laptop to supercomputer) through one script. Enables the creation of interactive data-intensive workflows.</p><p><italic>Instantiation</italic>. Simplify. Simplifies the passage of data between models.</p><p><italic>Deployment</italic>. Accelerate, Simplify. Single scripts map directly to a range of resource platforms.</p><p><italic>Execution</italic>. Curate. Provides a range of sophisticated data handling and error management features.</p><p><italic>Optimization and Production</italic>. To the best of our knowledge, Parsl does not directly add value on these steps of the development process.</p></sec><sec id="s6b6"><label>(vi)</label><title>Macro-Micro-Coupling</title><p>The Macro-Micro-Coupling Tool (MaMiCo) [<xref rid="RSTA20180147C40" ref-type="bibr">40</xref>,<xref rid="RSTA20180147C41" ref-type="bibr">41</xref>] attempts to ease the development of and share existing coupling algorithms for particle-mesh, in particular for molecular-continuum, flow simulations and is therefore a system-specific MCS. Separating continuum and molecular dynamics (MD) solvers from the actual coupling algorithm via strict interfacing and also separating coupling steps in a modular way within MaMiCo, arbitrary solvers can be plugged together. The software supports execution on distributed-memory platforms using MPI, is written in C++ and uses SCons for compiling.</p><p><italic>Implementation</italic>. Curate, Accelerate, Simplify and Expand. MaMiCo features well-defined interfaces to support among others debugging and unit/integration testing. After a certain accustomization phase, this also accelerates and simplifies code development. Accordingly, new algorithms to couple MD and continuum solvers can be easily incorporated as demonstrated in [<xref rid="RSTA20180147C40" ref-type="bibr">40</xref>] (expansion).</p><p><italic>Instantiation</italic>. Expand. Once a new coupling algorithm for a particular flow problem has been incorporated, this coupling can be evaluated using any interfaced particle/continuum package immediately.</p><p><italic>Deployment</italic>. None.</p><p><italic>Execution</italic>. Accelerate. Through the multi-instance sampling in MaMiCo [<xref rid="RSTA20180147C40" ref-type="bibr">40</xref>], faster time-to-solution is reached, although at higher compute cost. Incorporation of noise filters is a work in progress and is meant to further accelerate sampling/noise reduction in MD.</p><p><italic>Optimization</italic>. Curate. Standardized coarse-grained output is provided through MaMiCo (csv and vtk formats), allowing to compare results for different couplings.</p><p><italic>Production</italic>. See acceleration aspect for multiscale software execution above.</p></sec><sec id="s6b7"><label>(vii)</label><title>FabSim</title><p>FabSim is an automation environment which is optimized for curating complex multiscale workflows and providing one-liner access to perform simulations on remote machines. Its base implementation is generic, and has been used in disciplines ranging from materials to blood flow and migration. It is designed to be easy to modify, and has resulted in several domain-specific spin-off tools (e.g. FabMD [<xref rid="RSTA20180147C43" ref-type="bibr">43</xref>] and FabFlee [<xref rid="RSTA20180147C55" ref-type="bibr">55</xref>]) over the years.</p><p><italic>Implementation</italic>. Curate and Simplify. Easily combine execution patterns. Curate workflow building blocks.</p><p><italic>Instantiation</italic>. Curate. Curate collections of simulation input.</p><p><italic>Deployment</italic>. Curate and Accelerate. Automate deployment. Reuse working configs from other users.</p><p><italic>Execution</italic>. Curate and Simplify. Curate simulation output and environment. Simplify execution on remote resources.</p><p><italic>Optimization</italic>. Curate and Simplify. Curate output and environment. One-liner commands for parameter explorations.</p><p><italic>Production</italic>. Curate. Curate output and environment. Curate multi-machine workflows in single commands.</p></sec></sec></sec><sec id="s7"><label>7.</label><title>Conclusion</title><p>Several conclusions can be drawn from our analysis. First, the availability of MCS has become considerably broader since 2014 [<xref rid="RSTA20180147C2" ref-type="bibr">2</xref>], with many of the newer tools aiming explicitly to simplify application development. Second, Python has now become one of the leading platforms to help facilitate multiscale applications (e.g. see FabSim, OMFIT and Parsl for recent examples). Third, in terms of generality, we now find generic MCS being applied in all major computational research disciplines. However, the tools remain quite specific in other aspects: most MCS are far from language-agnostic and 16 of the 21 tools are intended for a subset of applications that fit one or two particular MCPs [<xref rid="RSTA20180147C8" ref-type="bibr">8</xref>].</p><p>Until now, the majority of the MCS development has focused on integrating frameworks to combine at-scale models together to form a multiscale model. As the multiscale computing field remains still quite immature, there has been a corresponding lack of development of tools to ease deployment, configuration, debugging, profiling, optimization and visualization of multiscale models. As a consequence, we find in our analysis that relatively few tools provide added value in the later steps in the development process (especially deployment, optimization and production). These steps are both labour-intensive and crucial for the long-term success of multiscale applications, and the introduction of mature MCS there may drive the research impact in the field as a whole.</p><p>Within our work we also briefly reflect on the (frequently under-documented) drawbacks associated with MCS. A systematic analysis of drawbacks, describing the trade-offs expected when adopting the software, does not solely serve the community as a whole. It can also give a much clearer justification to the existence of individual tools, particularly when two tools with similar added values provide these benefits with substantially different kinds of drawbacks.</p><p>Major progress has been made towards providing discipline-agnostic MCS. Now, our next targets should be to address the previously overlooked parts of application development, and to more clearly present and curate the adoption drawbacks and benefits to the users.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><caption><title>Survey form</title></caption><media mimetype="application" mime-subtype="pdf" xlink:href="rsta20180147supp1.pdf" orientation="portrait" id="d35e1239" position="anchor"/></supplementary-material></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD2"><caption><title>Raw survey data</title></caption><media mimetype="application" mime-subtype="csv" xlink:href="rsta20180147supp2.csv" orientation="portrait" id="d35e1247" position="anchor"/></supplementary-material></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD3"><caption><title>Review data</title></caption><media mimetype="application" mime-subtype="csv" xlink:href="rsta20180147supp3.csv" orientation="portrait" id="d35e1255" position="anchor"/></supplementary-material></sec></body><back><ack><title>Acknowledgements</title><p>We are grateful to the organizers and participants of the Lorentz Center workshop &#x02018;Multiscale Computing: From the Desktop to the Exascale&#x02019;, for providing an excellent discussion platform, which substantially helped us in defining the paper concept. We are also grateful to David Coster for providing information on the OMFIT and AiiDA toolkits.</p></ack><sec id="s8"><title>Data accessibility</title><p>This article has no additional data.</p></sec><sec id="s9"><title>Authors' contributions</title><p>D.G. coordinated the project, wrote the main content on the analysis of added values, designed the analysis survey form and developed the scripts to convert the analysis data into figures and tables. K.L. wrote and refined &#x000a7;2, while D.S. helped collect data by performing an independent literature search for multiscale computing tools. L.V. wrote the section on MUSCLE 2, and P.N. wrote the section on MaMiCo. All authors helped collect data for the survey, provided revisions for the manuscript, read and approved the manuscript.</p></sec><sec id="s10" sec-type="COI-statement"><title>Competing interests</title><p>We declare we have no competing interests.</p></sec><sec id="s11"><title>Funding</title><p>This project has received funding from the European Union's Horizon 2020 Research and Innovation Programme under grant agreement nos. 800925 and 671564. P.N. acknowledges financial support through the project &#x02018;Task-based load balancing and auto-tuning in particle simulations&#x02019; (TaLPas), grant no. 01IH16008B.</p></sec><ref-list><title>References</title><ref id="RSTA20180147C1"><label>1</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Babur</surname><given-names>&#x000d6;</given-names></name>, <name name-style="western"><surname>Smilauer</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Verhoeff</surname><given-names>T</given-names></name>, <name name-style="western"><surname>van den Brand</surname><given-names>M</given-names></name></person-group>
<year>2015</year>
<article-title>A survey of open source multiphysics frameworks in engineering</article-title>. <source>Procedia Comput. Sci.</source>
<volume>51</volume>, <fpage>1088</fpage>&#x02013;<lpage>1097</lpage>. (<pub-id pub-id-type="doi">10.1016/j.procs.2015.05.273</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Groen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Zasada</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Coveney</surname><given-names>PV</given-names></name></person-group>
<year>2014</year>
<article-title>Survey of multiscale and multiphysics applications and communities</article-title>. <source>IEEE Comput. Sci. Eng.</source>
<volume>16</volume>, <fpage>34</fpage>&#x02013;<lpage>43</lpage>. (<pub-id pub-id-type="doi">10.1109/MCSE.2013.47</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kevrekidis</surname><given-names>IG</given-names></name>, <name name-style="western"><surname>Samaey</surname><given-names>G</given-names></name></person-group>
<year>2009</year>
<article-title>Equation-free multiscale computation: algorithms and applications</article-title>. <source>Annu. Rev. Phys. Chem.</source>
<volume>60</volume>, <fpage>321</fpage>&#x02013;<lpage>344</lpage>. (<pub-id pub-id-type="doi">10.1146/annurev.physchem.59.032607.093610</pub-id>)<pub-id pub-id-type="pmid">19335220</pub-id></mixed-citation></ref><ref id="RSTA20180147C4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Weinan</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Engquist</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Ren</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Vanden-Eijnden</surname><given-names>E</given-names></name></person-group>
<year>2007</year>
<article-title>Heterogeneous Multiscale Methods: a review</article-title>. <source>Commun. Comput. Phys.</source>
<volume>2</volume>, <fpage>367</fpage>&#x02013;<lpage>450</lpage>.</mixed-citation></ref><ref id="RSTA20180147C5"><label>5</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Ashby</surname><given-names>S</given-names></name></person-group>
<italic>et al.</italic>
<year>2010</year>
<article-title>The opportunities and challenges of exascale computing</article-title>. <source><italic toggle="yes">Summary Report of the Advanced Scientific Computing Advisory Committee (ASCAC) Subcommittee</italic></source>, pp. <fpage>1</fpage>&#x02013;<lpage>77</lpage>.</mixed-citation></ref><ref id="RSTA20180147C6"><label>6</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Hoekstra</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lorenz</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Falcone</surname><given-names>J-L</given-names></name>, <name name-style="western"><surname>Chopard</surname><given-names>B</given-names></name></person-group>
<year>2007</year>
<article-title>Towards a complex automata framework for multi-scale modeling: formalism and the scale separation map</article-title>. In <source><italic toggle="yes">Computational science ICCS 2007</italic></source>, <volume>vol. 4487</volume> (eds <person-group person-group-type="editor"><name name-style="western"><surname>Shi</surname><given-names>Y.</given-names></name>, <name name-style="western"><surname>van Albada</surname><given-names>G.</given-names></name>, <name name-style="western"><surname>Dongarra</surname><given-names>J.</given-names></name> and <name name-style="western"><surname>Sloot</surname><given-names>P.</given-names></name></person-group>). <comment>Lecture Notes in Computer Science</comment>, pp. <fpage>922</fpage>&#x02013;<lpage>930</lpage>. <publisher-loc>Berlin, Germany</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id="RSTA20180147C7"><label>7</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Falcone</surname><given-names>J-L</given-names></name>, <name name-style="western"><surname>Chopard</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hoekstra</surname><given-names>A</given-names></name></person-group>
<year>2010</year>
<article-title>MML: towards a multiscale modeling language</article-title>. <source>Procedia Comput. Sci.</source>
<volume>1</volume>, <fpage>819</fpage>&#x02013;<lpage>826</lpage>. (<pub-id pub-id-type="doi">10.1016/j.procs.2010.04.089</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C8"><label>8</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alowayyed</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Groen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Coveney</surname><given-names>PV</given-names></name>, <name name-style="western"><surname>Hoekstra</surname><given-names>AG</given-names></name></person-group>
<year>2017</year>
<article-title>Multiscale computing in the exascale era</article-title>. <source>J. Comput. Sci.</source>
<volume>22</volume>, <fpage>15</fpage>&#x02013;<lpage>25</lpage>. (<pub-id pub-id-type="doi">10.1016/j.jocs.2017.07.004</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C9"><label>9</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>May</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Ashby</surname><given-names>SF</given-names></name></person-group>
<year>2007</year>
<article-title>Multiphysics simulations and petascale computing</article-title>. In <source><italic toggle="yes">Petascale computing</italic></source> (ed. <person-group person-group-type="editor"><name name-style="western"><surname>Bader</surname><given-names>DA</given-names></name></person-group>), pp. <fpage>96</fpage>&#x02013;<lpage>115</lpage>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>Chapman and Hall</publisher-name>.</mixed-citation></ref><ref id="RSTA20180147C10"><label>10</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Epperly</surname><given-names>TG</given-names></name>, <name name-style="western"><surname>Kumfert</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Dahlgren</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Ebner</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Leek</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Prantl</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kohn</surname><given-names>S</given-names></name></person-group>
<year>2012</year>
<article-title>High-performance language interoperability for scientific computing through Babel</article-title>. <source>Int. J. High Perform. Comput. Appl.</source>
<volume>26</volume>, <fpage>260</fpage>&#x02013;<lpage>274</lpage>. (<pub-id pub-id-type="doi">10.1177/1094342011414036</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C11"><label>11</label><mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Barton</surname><given-names>N</given-names></name></person-group>
<italic>et al.</italic>
<year>2007</year>
<comment>Co-op, version 00. Tech. Rep. UCRL-CODE-232892, Lawrence Livermore National Laboratory</comment>.</mixed-citation></ref><ref id="RSTA20180147C12"><label>12</label><mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Jefferson</surname><given-names>D</given-names></name></person-group>
<year>2006</year>
<comment>Relationship between Co-op and MPI-2. Tech. Rep. UCRL-TR-225783, Lawrence Livermore National Laboratory</comment>.</mixed-citation></ref><ref id="RSTA20180147C13"><label>13</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Barton</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Bernier</surname><given-names>JV</given-names></name>, <name name-style="western"><surname>Knap</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sunwoo</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Cerreta</surname><given-names>EK</given-names></name>, <name name-style="western"><surname>Turner</surname><given-names>TJ</given-names></name></person-group>
<year>2011</year>
<article-title>A call to arms for task parallelism in multi-scale materials modeling</article-title>. <source>Int. J. Numer. Methods Eng.</source>
<volume>86</volume>, <fpage>744</fpage>&#x02013;<lpage>764</lpage>. (<pub-id pub-id-type="doi">10.1002/nme.3071</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Barton</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Knap</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Arsenlis</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hornung</surname><given-names>RD</given-names></name>, <name name-style="western"><surname>Jefferson</surname><given-names>DR</given-names></name></person-group>
<year>2008</year>
<article-title>Embedded polycrystal plasticity and adaptive sampling</article-title>. <source>Int. J. Plast.</source>
<volume>24</volume>, <fpage>242</fpage>&#x02013;<lpage>266</lpage>. (<pub-id pub-id-type="doi">10.1016/j.ijplas.2007.03.004</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C15"><label>15</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Knap</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Barton</surname><given-names>NR</given-names></name>, <name name-style="western"><surname>Hornung</surname><given-names>RD</given-names></name>, <name name-style="western"><surname>Arsenlis</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Jefferson</surname><given-names>DR</given-names></name></person-group>
<year>2008</year>
<article-title>Adaptive sampling in hierarchical simulation</article-title>. <source>Int. J. Numer. Methods Eng.</source>
<volume>76</volume>, <fpage>572</fpage>&#x02013;<lpage>600</lpage>. (<pub-id pub-id-type="doi">10.1002/nme.2339</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C16"><label>16</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Leiter</surname><given-names>KW</given-names></name>, <name name-style="western"><surname>Barnes</surname><given-names>BC</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Knap</surname><given-names>J</given-names></name></person-group>
<year>2018</year>
<article-title>Accelerated scale-bridging through adaptive surrogate model evaluation</article-title>. <source>J. Comput. Sci.</source>
<volume>27</volume>, <fpage>91</fpage>&#x02013;<lpage>106</lpage>. (<pub-id pub-id-type="doi">10.1016/j.jocs.2018.04.010</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C17"><label>17</label><mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Dorr</surname><given-names>MR</given-names></name></person-group>
<year>2012</year>
<comment>ASPA - adaptive sampling proxy application. Tech. Rep. LLNL-SM-595112, Lawrence Livermore National Laboratory</comment>.</mixed-citation></ref><ref id="RSTA20180147C18"><label>18</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Borgdorff</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Mamonski</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bosak</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kurowski</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Ben Belgacem</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Chopard</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Groen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Coveney</surname><given-names>PV</given-names></name>, <name name-style="western"><surname>Hoekstra</surname><given-names>AG</given-names></name></person-group>
<year>2014</year>
<article-title>Distributed multiscale computing with MUSCLE 2, the multiscale coupling library and environment</article-title>. <source>J. Comput. Sci.</source>
<volume>5</volume>, <fpage>719</fpage>&#x02013;<lpage>731</lpage>. (<pub-id pub-id-type="doi">10.1016/j.jocs.2014.04.004</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C19"><label>19</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Hegewald</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Krafczyk</surname><given-names>M</given-names></name>, <name name-style="western"><surname>T&#x000f6;lke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Hoekstra</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Chopard</surname><given-names>B</given-names></name></person-group>
<year>2008</year>
<article-title>An agent-based coupling platform for complex automata</article-title>. In <conf-name>Proc. of the 8th Int. Conf. on computational science, part II, ICCS '08</conf-name>, pp. <fpage>227</fpage>&#x02013;<lpage>233</lpage>. <publisher-loc>Berlin, Germany</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id="RSTA20180147C20"><label>20</label><mixed-citation publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Hoekstra</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Caiazzo</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lorenz</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Falcone</surname><given-names>J-L</given-names></name>, <name name-style="western"><surname>Chopard</surname><given-names>B</given-names></name></person-group>
<year>2010</year>
<source>Complex automata: multi-scale modeling with coupled cellular automata</source>, pp. <fpage>29</fpage>&#x02013;<lpage>57</lpage>. <publisher-loc>Berlin, Germany</publisher-loc>: <publisher-name>Springer</publisher-name>.</mixed-citation></ref><ref id="RSTA20180147C21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hoekstra</surname><given-names>AG</given-names></name>, <name name-style="western"><surname>Lorenz</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Falcone</surname><given-names>J-L</given-names></name>, <name name-style="western"><surname>Chopard</surname><given-names>B</given-names></name></person-group>
<year>2007</year>
<article-title>Toward a complex automata formalism for multiscale modeling</article-title>. <source>Int. J. Multiscale Comput. Eng.</source>
<volume>5</volume>, <fpage>491</fpage>&#x02013;<lpage>502</lpage>. (<pub-id pub-id-type="doi">10.1615/IntJMultCompEng.v5.i6</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Borgdorff</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Falcone</surname><given-names>J-L</given-names></name>, <name name-style="western"><surname>Lorenz</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Bona-Casas</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Chopard</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Hoekstra</surname><given-names>AG</given-names></name></person-group>
<year>2013</year>
<article-title>Foundations of distributed multiscale computing: formalization, specification, and analysis</article-title>. <source>J. Parallel Distrib. Comput.</source>
<volume>73</volume>, <fpage>465</fpage>&#x02013;<lpage>483</lpage>. (<pub-id pub-id-type="doi">10.1016/j.jpdc.2012.12.011</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C23"><label>23</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Viceconti</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bn&#x000e0;</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Tartarini</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sfakianakis</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Grogan</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Walker</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Gamble</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Testi</surname><given-names>D</given-names></name></person-group>
<year>2018</year>
<article-title>Vph-hf: A software framework for the execution of complex subject-specific physiology modelling workflows</article-title>. <source>J. Comput. Sci.</source>
<volume>25</volume>, <fpage>101</fpage>&#x02013;<lpage>114</lpage>. (<pub-id pub-id-type="doi">10.1016/j.jocs.2018.02.009</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Knap</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Spear</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Leiter</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Becker</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Powell</surname><given-names>D</given-names></name></person-group>
<year>2016</year>
<article-title>A computational framework for scale-bridging in multi-scale simulations</article-title>. <source>Int. J. Numer. Methods Eng.</source>
<volume>108</volume>, <fpage>1649</fpage>&#x02013;<lpage>1666</lpage>. (<pub-id pub-id-type="doi">10.1002/nme.5270</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C25"><label>25</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Knap</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Spear</surname><given-names>CE</given-names></name>, <name name-style="western"><surname>Borodin</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Leiter</surname><given-names>KW</given-names></name></person-group>
<year>2015</year>
<article-title>Advancing a distributed multi-scale computing framework for large-scale high-throughput discovery in materials science</article-title>. <source>Nanotechnology</source>
<volume>26</volume>, <elocation-id content-type="artnum">434004</elocation-id> (<pub-id pub-id-type="doi">10.1088/0957-4484/26/43/434004</pub-id>)<pub-id pub-id-type="pmid">26443333</pub-id></mixed-citation></ref><ref id="RSTA20180147C26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pelupessy</surname><given-names>F</given-names></name>, <name name-style="western"><surname>van Elteren</surname><given-names>A</given-names></name>, <name name-style="western"><surname>de Vries</surname><given-names>N</given-names></name>, <name name-style="western"><surname>McMillan</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Drost</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Zwart</surname><given-names>SP</given-names></name></person-group>
<year>2013</year>
<article-title>The astrophysical multipurpose software environment</article-title>. <source>Astron. Astrophys.</source>
<volume>557</volume>, <fpage>A84</fpage> (<pub-id pub-id-type="doi">10.1051/0004-6361/201321252</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C27"><label>27</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Pelupessy</surname><given-names>I</given-names></name>, <name name-style="western"><surname>van Werkhoven</surname><given-names>B</given-names></name>, <name name-style="western"><surname>van Elteren</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Viebahn</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Candy</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Zwart</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>Dijkstra</surname><given-names>H</given-names></name></person-group>
<year>2016</year>
<article-title>OMUSE: Oceanographic multipurpose software environment</article-title>. In <conf-name>2016 IEEE 12th Int. Conf. on e-science (e-science)</conf-name>, pp. <fpage>399</fpage>&#x02013;<lpage>399</lpage>.</mixed-citation></ref><ref id="RSTA20180147C28"><label>28</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hill</surname><given-names>C</given-names></name>, <name name-style="western"><surname>DeLuca</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Balaji Suarez</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Silva</surname><given-names>Ad</given-names></name></person-group>
<year>2004</year>
<article-title>The architecture of the earth system modeling framework</article-title>. <source>Comput. Sci. Eng.</source>
<volume>6</volume>, <fpage>18</fpage>&#x02013;<lpage>28</lpage>. (<pub-id pub-id-type="doi">10.1109/MCISE.2004.1255817</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C29"><label>29</label><mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Germann</surname><given-names>TC</given-names></name>, <name name-style="western"><surname>McPherson</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Belak</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Richards</surname><given-names>DF</given-names></name></person-group>
<year>2013</year>
<comment>Exascale co-design center for materials in extreme environments (ExMatEx) annual report - year 2. Tech. Rep. LLNL-SR-647437, Lawrence Livermore National Laboratory</comment>.</mixed-citation></ref><ref id="RSTA20180147C30"><label>30</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Pavel</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>McPherson</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Germann</surname><given-names>TC</given-names></name>, <name name-style="western"><surname>Junghans</surname><given-names>C</given-names></name></person-group>
<year>2015</year>
<article-title>Database assisted distribution to improve fault tolerance for multiphysics applications</article-title>. In <conf-name>Proc. of the 2nd Int. workshop on hardware-software co-design for high performance computing, Co-HPC '15</conf-name>, pp. <fpage>4:1</fpage>&#x02013;<lpage>4:8</lpage>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>ACM</publisher-name>.</mixed-citation></ref><ref id="RSTA20180147C31"><label>31</label><mixed-citation publication-type="other"><person-group person-group-type="author"><name name-style="western"><surname>Dorr</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Barton</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Keasler</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>F</given-names></name></person-group>
<year>2014</year>
<comment>CoEVP: A co-design embedded viscoplasticity scale-bridging proxy app for ExMatEx. <italic>Lawrence Livermore National Laboratory, Technical Report LLNL-SM-655180</italic></comment>.</mixed-citation></ref><ref id="RSTA20180147C32"><label>32</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Pavel</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Junghans</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Mniszewski</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Germann</surname><given-names>TC</given-names></name></person-group>
<year>2017</year>
<article-title>Using Charm++ to support multiscale multiphysics on the Trinity supercomputer</article-title>. <conf-name>15th Annual Workshop on Charm++ and its Applications</conf-name>.</mixed-citation></ref><ref id="RSTA20180147C33"><label>33</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Roehm</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Pavel</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Barros</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Rouet-Leduc</surname><given-names>B</given-names></name>, <name name-style="western"><surname>McPherson</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Germann</surname><given-names>TC</given-names></name>, <name name-style="western"><surname>Junghans</surname><given-names>C</given-names></name></person-group>
<year>2015</year>
<article-title>Distributed database kriging for adaptive sampling (D<sup>2</sup>KAS)</article-title>. <source>Comput. Phys. Commun.</source>
<volume>192</volume>, <fpage>138</fpage>&#x02013;<lpage>147</lpage>. (<pub-id pub-id-type="doi">10.1016/j.cpc.2015.03.006</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C34"><label>34</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rouet-Leduc</surname><given-names>B</given-names></name></person-group>
<italic>et al.</italic>
<year>2014</year>
<article-title>Spatial adaptive sampling in multiscale simulation</article-title>. <source>Comput. Phys. Commun.</source>
<volume>185</volume>, <fpage>1857</fpage>&#x02013;<lpage>1864</lpage>. (<pub-id pub-id-type="doi">10.1016/j.cpc.2014.03.011</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C35"><label>35</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Mei</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Carbo</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hontecillas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hoops</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Liles</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Lu</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Philipson</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Bassaganya-Riera</surname><given-names>J</given-names></name></person-group>
<year>2014</year>
<article-title>ENISI MSM: A novel multi-scale modeling platform for computational immunology</article-title>. In <conf-name>2014 IEEE Int. Conf. on bioinformatics and biomedicine (BIBM)</conf-name>, pp. <fpage>391</fpage>&#x02013;<lpage>396</lpage>. (<pub-id pub-id-type="doi">10.1109/BIBM.2014.6999190</pub-id>).</mixed-citation></ref><ref id="RSTA20180147C36"><label>36</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Miller</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Tadmor</surname><given-names>EB</given-names></name></person-group>
<year>2009</year>
<article-title>A unified framework and performance benchmark of fourteen multiscale atomistic/continuum coupling methods</article-title>. <source>Modell. Simul. Mater. Sci. Eng.</source>
<volume>17</volume>, <elocation-id content-type="artnum">053001</elocation-id> (<pub-id pub-id-type="doi">10.1088/0965-0393/17/5/053001</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C37"><label>37</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Larson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Jacob</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Ong</surname><given-names>EFall</given-names></name></person-group>
<year>2005</year>
<article-title>The model coupling toolkit: a new Fortran90 toolkit for building multiphysics parallel coupled models</article-title>. <source>Int. J. High Perform. Comput. Appl.</source>
<volume>19</volume>, <fpage>277</fpage>&#x02013;<lpage>292</lpage>. (<pub-id pub-id-type="doi">10.1177/1094342005056115</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C38"><label>38</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tang</surname><given-names>Y-H</given-names></name>, <name name-style="western"><surname>Kudo</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bian</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Karniadakis</surname><given-names>GE</given-names></name></person-group>
<year>2015</year>
<article-title>Multiscale universal interface: A concurrent framework for coupling heterogeneous solvers</article-title>. <source>J. Comput. Phys.</source>
<volume>297</volume>, <fpage>13</fpage>&#x02013;<lpage>31</lpage>. (<pub-id pub-id-type="doi">10.1016/j.jcp.2015.05.004</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C39"><label>39</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Craig</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Valcke</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Coquart</surname><given-names>L</given-names></name></person-group>
<year>2017</year>
<article-title>Development and performance of a new version of the OASIS coupler, OASIS3-MCT_3.0</article-title>. <source>Geosci. Model Dev.</source>
<volume>10</volume>, <fpage>3297</fpage>&#x02013;<lpage>3308</lpage>. (<pub-id pub-id-type="doi">10.5194/gmd-10-3297-2017</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C40"><label>40</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Neumann</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Bian</surname><given-names>X</given-names></name></person-group>
<year>2017</year>
<article-title>MaMiCo: Transient multi-instance molecular-continuum flow simulation on supercomputers</article-title>. <source>Comput. Phys. Commun.</source>
<volume>220</volume>, <fpage>390</fpage>&#x02013;<lpage>402</lpage>. (<pub-id pub-id-type="doi">10.1016/j.cpc.2017.06.026</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C41"><label>41</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Neumann</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Flohr</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Arora</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Jarmatz</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Tchipev</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Bungartz</surname><given-names>H-J</given-names></name></person-group>
<year>2016</year>
<article-title>MaMiCo: Software design for parallel molecular-continuum flow simulations</article-title>. <source>Comput. Phys. Commun.</source>
<volume>200</volume>, <fpage>324</fpage>&#x02013;<lpage>335</lpage>. (<pub-id pub-id-type="doi">10.1016/j.cpc.2015.10.029</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C42"><label>42</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Groen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Bhati</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Suter</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Hetherington</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zasada</surname><given-names>SJ</given-names></name>, <name name-style="western"><surname>Coveney</surname><given-names>PV</given-names></name></person-group>
<year>2016</year>
<article-title>FabSim: facilitating computational research through automation on large-scale and distributed e-infrastructures</article-title>. <source>Comput. Phys. Commun.</source>
<volume>207</volume>, <fpage>375</fpage>&#x02013;<lpage>385</lpage>. (<pub-id pub-id-type="doi">10.1016/j.cpc.2016.05.020</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C43"><label>43</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Suter</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Groen</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Coveney</surname><given-names>PV</given-names></name></person-group>
<year>2015</year>
<article-title>Chemically specific multiscale modeling of clay-polymer nanocomposites reveals intercalation dynamics, tactoid self-assembly and emergent materials properties</article-title>. <source>Adv. Mater.</source>
<volume>27</volume>, <fpage>966</fpage>&#x02013;<lpage>984</lpage>. (<pub-id pub-id-type="doi">10.1002/adma.201403361</pub-id>)<pub-id pub-id-type="pmid">25488829</pub-id></mixed-citation></ref><ref id="RSTA20180147C44"><label>44</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Itani</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Schiller</surname><given-names>UD</given-names></name>, <name name-style="western"><surname>Schmieschek</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Hetherington</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Bernabeu</surname><given-names>MO</given-names></name>, <name name-style="western"><surname>Chandrashekar</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Robertson</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Coveney</surname><given-names>PV</given-names></name>, <name name-style="western"><surname>Groen</surname><given-names>D</given-names></name></person-group>
<year>2015</year>
<article-title>An automated multiscale ensemble simulation approach for vascular blood flow</article-title>. <source>J. Comput. Sci.</source>
<volume>9</volume>, <fpage>150</fpage>&#x02013;<lpage>155</lpage>. (<pub-id pub-id-type="doi">10.1016/j.jocs.2015.04.008</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C45"><label>45</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pizzi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Cepellotti</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sabatini</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Marzari</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Kozinsky</surname><given-names>B</given-names></name></person-group>
<year>2016</year>
<article-title>AiiDA: automated interactive infrastructure and database for computational science</article-title>. <source>Comput. Mater. Sci.</source>
<volume>111</volume>, <fpage>218</fpage>&#x02013;<lpage>230</lpage>. (<pub-id pub-id-type="doi">10.1016/j.commatsci.2015.09.013</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C46"><label>46</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gebbie-Rayet</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Shannon</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Loeffler</surname><given-names>HH</given-names></name>, <name name-style="western"><surname>Laughton</surname><given-names>CA</given-names></name></person-group>
<year>2016</year>
<article-title>Longbow: a lightweight remote job submission tool</article-title>. <source>J. open Res. Software</source>
<volume>4</volume>.</mixed-citation></ref><ref id="RSTA20180147C47"><label>47</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lud&#x000e4;scher</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Altintas</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Berkley</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Higgins</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Jaeger</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>MB</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Tao</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>Y</given-names></name></person-group>
<year>2006</year>
<article-title>Scientific workflow management and the Kepler system</article-title>. <source>Concurr. Comput. Pract. Exp.</source>
<volume>18</volume>, <fpage>1039</fpage>&#x02013;<lpage>1065</lpage>. (<pub-id pub-id-type="doi">10.1002/(ISSN)1532-0634</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C48"><label>48</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Wilde</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hategan</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wozniak</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Clifford</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Katz</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Foster</surname><given-names>I</given-names></name></person-group>
<year>2011</year>
<article-title>Swift: a language for distributed parallel scripting</article-title>. <source>Parallel Comput.</source>
<volume>39</volume>, <fpage>633</fpage>&#x02013;<lpage>652</lpage>. (<pub-id pub-id-type="doi">10.1016/j.parco.2011.05.005</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C49"><label>49</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Treikalis</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Weidner</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Jha</surname><given-names>S</given-names></name></person-group>
<year>2016</year>
<article-title>Ensemble toolkit: Scalable and flexible execution of ensembles of tasks</article-title>. In <conf-name>2016 45th Int. Conf. on parallel processing (ICPP)</conf-name>, <conf-loc>Philadelphia, PA</conf-loc>, <conf-date>16&#x02013;19 August</conf-date>, pp. <fpage>458</fpage>&#x02013;<lpage>463</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref><ref id="RSTA20180147C50"><label>50</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Babuji</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Brizius</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Chard</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Foster</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Katz</surname><given-names>DS</given-names></name>, <name name-style="western"><surname>Wilde</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wozniak</surname><given-names>J</given-names></name></person-group>
<year>2017</year>
<article-title>Introducing parsl: A Python Parallel Scripting Library</article-title>. (<pub-id pub-id-type="doi">10.5281/zenodo.891533</pub-id>).</mixed-citation></ref><ref id="RSTA20180147C51"><label>51</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Jasak</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Jemcov</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Tukovic</surname><given-names>Z</given-names></name></person-group>
<year>2007</year>
<article-title>OpenFOAM: A C++ library for complex physics simulations</article-title>. In <conf-name>Int. workshop on coupled methods in numerical dynamics</conf-name>, <conf-loc>Dubrovnik, Croatia</conf-loc>, <conf-date>19&#x02013;21 September</conf-date>, <volume>vol. 1000</volume>, pp. <fpage>1</fpage>&#x02013;<lpage>20</lpage>. <conf-loc>IUC Dubrovnik, Croatia</conf-loc>
<publisher-loc>Zagreb, Croatia</publisher-loc>: <publisher-name>Faculty of Mechanical Engineering and Naval Architecture, University of Zagreb</publisher-name>.</mixed-citation></ref><ref id="RSTA20180147C52"><label>52</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Plimpton</surname><given-names>SJ</given-names></name></person-group>
<year>1995</year>
<article-title>Fast parallel algorithms for short-range molecular-dynamics</article-title>. <source>J. Comp. Phys.</source>
<volume>117</volume>, <fpage>1</fpage> (<pub-id pub-id-type="doi">10.1006/jcph.1995.1039</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C53"><label>53</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Yang</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Ji</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name></person-group>
<year>2014</year>
<article-title>C-Coupler1: a chinese community coupler for earth system modeling</article-title>. <source>Geosci. Model Dev.</source>
<volume>7</volume>, <fpage>2281</fpage>&#x02013;<lpage>2302</lpage>. (<pub-id pub-id-type="doi">10.5194/gmd-7-2281-2014</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C54"><label>54</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Hanke</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Redler</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Holfeld</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Yastremsky</surname><given-names>M</given-names></name></person-group>
<year>2016</year>
<article-title>YAC 1.2.0: new aspects for coupling software in Earth system modelling</article-title>. <source>Geosci. Model Dev.</source>
<volume>9</volume>, <fpage>2755</fpage>&#x02013;<lpage>2769</lpage>. (<pub-id pub-id-type="doi">10.5194/gmd-9-2755-2016</pub-id>)</mixed-citation></ref><ref id="RSTA20180147C55"><label>55</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><name name-style="western"><surname>Suleimenova</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Bell</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Groen</surname><given-names>D</given-names></name></person-group>
<year>2017</year>
<article-title>Towards an automated framework for agent-based simulation of refugee movements</article-title>. In <conf-name>2017 winter simulation Conf, (WSC)</conf-name>, <conf-loc>Las Vegas, NV</conf-loc>, <conf-date>3&#x02013;6 December</conf-date>, pp. <fpage>1240</fpage>&#x02013;<lpage>1251</lpage>. <publisher-name>IEEE</publisher-name>.</mixed-citation></ref></ref-list></back></article>