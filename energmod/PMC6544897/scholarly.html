<html xmlns="http://www.w3.org/1999/xhtml"><head> <style type="text/css">
         	     		 
         	    a                          {background : #ffffff; }
         	    article                    {border-style : dotted; border-width : 2px; }
         		 	
         		 	div                        {background : #ffffcc;}
         		 	div.abstract-title         {font-weight : bold ; font-size : 16pt;}
         		 	div.ack                    {border-style : solid ; border-color : red; margin
         : 2em; }
         		 	div.article-meta           {border-style : solid; border-width : 1 pt; margin
         1em;}
         		 	div.boxed-text             {margin : 5em; border-style : solid;}
         		 	div.contrib-group          {margin : 1em; }
         		 	div.fig                    {border-style : solid; border-width : 2px; margin :
         2em; }
         		 	div.funding                {font-weight : bold ; font-size : 16pt;}
         		 	div.given-names            {font-style : italic;}
         		 	div.intro                  {border-style : inset; margin : 5px;}
         		 	div.introduction           {border-style : inset; margin : 5px;}
         		 	div.journal-meta           {border-style : solid; border-width : 1 pt; margin
         1em;}
         		 	div.journal-title-group    {background : #ffeeee;}
         		 	div.article-title          {font-weight : bold ; font-size : 18pt;}
         		 	div.kwd                    {font-style : italic}
         		 	div.meta-name              {font-weight : bold ; font-size : 16pt;}
         		 	div.name                   {font-weight : bold;}
         		 	div.alt-title              {font-style : italic; font-size : 12px;}
         		 	
         		 	div.sec                    {border : 2px; margin 5px; padding 2px;}
         		 	div.title                  {font-family : courier; font-weight : bold;
         		 	                            font-size : 16pt; margin : 5px;}
         		 	
         		 	div.materials_methods      {border-style : double; margin : 5px; }
         		 	div.methods                {border-style : double; margin : 5px; }
         		 	
         		 	div.results                {border-style : solid; margin : 5px;}
         		 	div.background             {border-style : dotted; margin : 5px;}
         		 	
         		 	div.discussion             {border-style : groove; margin : 5px;}
         		 	div.conclusion             {border-style : ridge; margin : 5px;}
         		 	div.conclusions             {border-style : ridge; margin : 5px;}
         		 	div.supplementary-material {border-style : inset; margin : 5px;}
         		 	div.abbreviations          {border-style : double; border-color : red; margin
         : 5px;}
         		 	div.competinginterests     {border-style : double; border-color : blue; margin
         : 5px;}
         		 	div.acknowledgements       {border-style : double; border-color : green; margin
         : 5px;}
         		 	div.authors_contributions   {border-style : double; border-color : purple; margin
         : 5px;}
         		 	
         		 	div.publisher              {border-style : outset; margin : 5px;}
         		 	div.fn-type-conflict       {background : #f88; }
         		 	div.fn-type-con            {background : #ddf; }
         		 	div.fn-type-other          {background : #ddd; }
         		 	
         		 	div.unknown                {background : #ffd;
         									 	  border-style : solid;
         									 	  border-width : 1px;
         									 	  padding : 2 px;}
         		 	  
         	    table                      {background : #ffffdd;}
         		 	tr                         {background : #ddddff; padding : 1px;}
         		 	
         		 	span                       {background : #ffcccc;}
         		 	
         		 	span.citation-author       {font-family : helvetica; background : #ffeeee;}
         		 	span.collab                {background : #ddffff; }
         		 	span.comment               {font-family : courier; font-size : 6px; background
         : #ffaaff;}
         		 	span.contrib               {background : #ffffff;}
         		 	span.corresp               {background : #ddffdd; }
         		 	span.doi                   {background : #ffffff;}
         		 	span.email                 {font-family : courier; }
         		 	span.etal                  {font-style : italic;}
         		 	span.fpage                 {font-family : courier;}
         		 	span.given-names           {background : #ffffff;}
         		 	span.iso-abbrev            {background : #ffffff;}
         		 	span.issn-epub             {background : #ffffff;}
         		 	span.issn-ppub             {background : #ffffff;}
         		 	span.journal-title         {background : #ffffff;}
         		 	span.lpage                 {font-family : courier;}
         		 	span.mixed-article-title   {font-style : italic ;}
         		 	span.nlm-ta                {background : #ffffff;}
         		 	span.pmc                   {background : #ffffff;}
         		 	span.pmcid                 {background : #ffffff;}
         		 	span.pmid                  {background : #ffffff;}
         		 	span.publisher             {background : #ffffff;}
         		 	span.publisher-id          {background : #ffffff;}
         		 	span.publisher-name        {background : #ffffff;}
         		 	span.source                {background : #ffffff;}
         		 	span.subject               {background : #ffffff;}
         		 	span.surname               {background : #ffffff;}
         		 	span.volume                {font-family : courier; font-weight : bold;}
         		 	span.year                  {font-family : courier ; font-style : italic;}
         			
      </style> </head> <body> <div class="front" title="front"> <div class="journal-meta" tagx="journal-meta" title="journal-meta"> <span class="nlm-ta" title="nlm-ta">J R Soc Interface</span> <span class="iso-abbrev" title="iso-abbrev">J R Soc Interface</span> <span class="publisher-id" title="publisher-id">RSIF</span> <span class="hwp" title="hwp">royinterface</span> <div class="journal-title-group" tagx="journal-title-group" title="journal-title-group"> <span class="journal-title" tagx="journal-title" title="journal-title">Journal of the Royal Society Interface</span> </div> <span class="issn-ppub" tagx="issn" title="issn-ppub">1742-5689</span> <span class="issn-epub" tagx="issn" title="issn-epub">1742-5662</span> <div class="publisher" tagx="publisher" title="publisher"> <span class="publisher-name" tagx="publisher-name" title="publisher-name">The Royal Society</span> </div> </div> <div class="article-meta" tagx="article-meta" title="article-meta"> <span class="pmcid" title="pmcid"> pmcid: <a href="http://www.ncbi.nlm.nih.gov/pubmed/6544897">6544897</a> </span> <span class="pmid" title="pmid"> pmid: <a href="http://www.ncbi.nlm.nih.gov/pubmed/31039693">31039693</a> </span> <span class="doi" title="doi"> doi: <a href="https://dx.doi.org/10.1098/rsif.2018.0344">10.1098/rsif.2018.0344</a> </span> <span class="publisher-id" title="publisher-id">rsif20180344</span> <div class="article-categories" title="article-categories">
: <span class="subject" title="subject">1004</span> <span class="subject" title="subject">44</span> <span class="subject" title="subject">181</span> <span class="subject" title="subject">22</span>: <span class="subject" title="subject">Life Sciences–Mathematics interface</span>: <span class="subject" title="subject">Research Article</span> </div> <div class="title-group"> <div class="article-title" title="article-title">
Excitatory versus inhibitory feedback in Bayesian formulations of scene construction</div> <div class="alt-title" title="alt-title">
Excitatory versus inhibitory feedback in Bayesian formulations of scene construction</div> </div> <div class="contrib-group" title="contrib-group"> <span class="contrib" title="contrib"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Abadi</span> <span class="given-names" tagx="given-names" title="given-names">Alireza Khatoon</span> </span> <a href="#af1">1</a> </span> <span class="contrib" title="contrib"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Yahya</span> <span class="given-names" tagx="given-names" title="given-names">Keyvan</span> </span> <a href="#af2">2</a> </span> <span class="contrib" title="contrib"> <span class="contrib-id" tagx="contrib-id" title="contrib-id">http://orcid.org/0000-0002-9253-5859</span> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Amini</span> <span class="given-names" tagx="given-names" title="given-names">Massoud</span> </span> <a href="#af1">1</a> </span> <span class="contrib" title="contrib"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">Karl</span> </span> <a href="#af3">3</a> </span> <span class="contrib" title="contrib"> <span class="contrib-id" tagx="contrib-id" title="contrib-id">http://orcid.org/0000-0003-3632-7569</span> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">Dietmar</span> </span> <a href="#af4">4</a> <a href="#cor1" /> </span> </div> <span class="citation_author_institution" id="af1">[1], <span class="institution" title="institution">Department of Mathematics, Faculty of Mathematical Sciences, Tarbiat Modares University</span> <span class="addr-line" title="addr-line">Tehran 14115-134</span> <span class="country" tagx="country" title="country">Iran</span> </span> <span class="citation_author_institution" id="af2">[2], <span class="institution" title="institution">Faculty of Informatics, Chemnitz University of Technology</span> <span class="addr-line" title="addr-line">Straße der Nationen 62, R. B216, 09111 Chemnitz</span> <span class="country" tagx="country" title="country">Germany</span> </span> <span class="citation_author_institution" id="af3">[3], <span class="institution" title="institution">Wellcome Trust Centre for Neuroimaging, Institute of Neurology, University College London </span> <span class="addr-line" title="addr-line">12 Queen Square, London WC1N 3BG</span> <span class="country" tagx="country" title="country">UK</span> </span> <span class="citation_author_institution" id="af4">[4], <span class="institution" title="institution">Centre for Computational Neuroscience and Cognitive Robotics, School of Psychology, University of Birmingham </span> <span class="addr-line" title="addr-line">Edgbaston, Birmingham B15 2TT</span> <span class="country" tagx="country" title="country">UK</span> </span> <div class="author-notes" title="author-notes"> <div class="corresp" title="corresp">
e-mail: <span class="email" tagx="email" title="email">d.g.heinke@bham.ac.uk</span> </div> </div> <span class="pub-date-ppub" title="pub-date-ppub">ppub: <span>2019-5</span> </span> <span class="pub-date-epub" title="pub-date-epub">epub: <span>2019-5-5</span> </span> <span class="pub-date-pmc-release" title="pub-date-pmc-release">pmc-release: <span>2019-5-5</span> </span> <span class="volume" tagx="volume" title="volume">16</span> <span class="issue" tagx="issue" title="issue">154</span> <span class="elocation-id" tagx="elocation-id" title="elocation-id">20180344</span> <span class="history" title="history"> <span class="received" title="received">received: 2018-5-15</span> <span class="accepted" title="accepted">accepted: 2019-4-2</span> </span> <div class="permissions"> <span class="copyright" title="copyright">(C) , <span class="copyright-year" tagx="copyright-year" title="copyright-year">2019</span> </span> <span class="license" title="license"> <span class="license-p" title="license-p">Published by the Royal Society under the terms of the Creative Commons Attribution License <a href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</a>, which permits unrestricted use, provided the original author and source are credited. </span> </span> </div> <a class="self-uri" href="rsif20180344.pdf" title="self-uri">rsif20180344.pdf</a> <div class="abstract" title="abstract"> <div class="abstract-title" title="abstract-title">
Abstract</div> <p>The selective attention for identification model (SAIM) is an established model of selective visual attention. SAIM implements translation-invariant object recognition, in scenes with multiple objects, using the parallel distributed processing (PDP) paradigm. Here, we show that SAIM can be formulated as Bayesian inference. Crucially, SAIM uses excitatory feedback to combine top-down information (i.e. object knowledge) with bottom-up sensory information. By contrast, predictive coding implementations of Bayesian inference use inhibitory feedback. By formulating SAIM as a predictive coding scheme, we created a new version of SAIM that uses inhibitory feedback. Simulation studies showed that both types of architectures can reproduce the response time costs induced by multiple objects—as found in visual search experiments. However, due to the different nature of the feedback, the two SAIM schemes make distinct predictions about the motifs of microcircuits mediating the effects of top-down afferents. We discuss empirical (neuroimaging) methods to test the predictions of the two inference architectures. </p> </div> <div class="kwd-group"> <div class="kwd" title="kwd">
selective visual attention</div> <div class="kwd" title="kwd">
computational modelling</div> <div class="kwd" title="kwd">
active inference</div> <div class="kwd" title="kwd">
parallel distributed processing</div> <div class="kwd" title="kwd">
neuroimaging</div> </div> <div class="funding-group" title="funding-group"> <div class="funding" title="funding">
Funding</div> <div class="award-group" title="award-group"> <div class="funding-source" title="funding-source"> <div class="institution-wrap" title="institution-wrap"> <span class="institution" title="institution">Wellcome Trust</span> <span class="institution-id" title="institution-id">http://dx.doi.org/10.13039/100004440</span> </div> </div> <span class="award-id" tagx="award-id" title="award-id">088130/Z/09/Z</span> </div> </div> <div class="custom-meta-group" title="custom-meta-group"> <meta name="cover-date" value="May, 2019" /> </div> </div> </div> <div class="body" title="body"> <div class="introduction" title="sec"> <span class="label" tagx="label" title="label">1.</span> <div class="title" tagx="title" title="title">
Introduction</div> <p>In 2003, Heinke &amp;amp; Humphreys [ <a href="#RSIF20180344C1">1</a>] introduced the selective attention for identification model (SAIM) to model translation-invariant object identification in multiple object scenes. A foundational assumption of SAIM is that the brain implements a soft constraint satisfaction as implemented by the parallel distributed processing (PDP) paradigm [ <a href="#RSIF20180344C2">2</a>]. This led to a neural network architecture with feedback loops that enable an interaction between top-down information (i.e. knowledge about objects stored in an object identification stage) and bottom-up information (i.e. sensory information). Heinke and Humphreys demonstrated that SAIM could explain a broad range of empirical phenomena typically associated with selective visual attention, such as the effects of spatial cuing, object-based selection and the response time costs of recognizing multiple objects. Furthermore, SAIM could account for deficits in selective visual attention, such as visual neglect, visual extinction and the influence of knowledge on visual neglect. </p> <p>In short, SAIM suggests that many ‘attentional’ phenomena can be explained as an emergent property of object identification (i.e. perceptual inference) in multiple object scenes. As far as we know, this level of success remains unrivalled by any other model. Subsequent work by Heinke and colleagues [ <a href="#RSIF20180344C3">3</a>– <a href="#RSIF20180344C5">5</a>] demonstrated that extensions of SAIM could reproduce findings from visual search experiments, deal with natural colour images [ <a href="#RSIF20180344C6">6</a>] and perceptual grouping [ <a href="#RSIF20180344C7">7</a>]. Finally, by modifying the constraints to reflect action possibilities (i.e. affordances), it was possible to incorporate affordances in multiple object scenes [ <a href="#RSIF20180344C8">8</a>]. It is also worth noting that SAIM's mechanisms are based on nonlinear dynamics that are formally similar to those used in dynamic neural fields (e.g. [ <a href="#RSIF20180344C9">9</a>– <a href="#RSIF20180344C13">13</a>]). The latter reference is particularly relevant in the current context, because it considers the use of lateral interactions to engineer neurodynamic architectures for one-shot learning of visual objects using bottom-up recognition under top-down predictions. The common theme here is a dynamical implementation of a universal prior in object recognition; namely, that only one object (i.e. the winning or selected hypothesis) can cause sensory input at any one time. This fundamental prior is generally mediated by lateral interactions in neuronal schemes. The winner-take-all (WTA) interactions—implicit in SAIM—play the same role as lateral connections in neural field formulations. </p> <p>The aim of this paper is to relate SAIM to a predictive processing framework for modelling action and perception; namely, the free-energy principle of Friston <i>et al</i>. (e.g. [ <a href="#RSIF20180344C14">14</a>– <a href="#RSIF20180344C17">17</a>]; see [ <a href="#RSIF20180344C18">18</a>, <a href="#RSIF20180344C19">19</a>]). A <i>prima facie</i> inspection suggests that Bayesian principles advocate a similar computational architecture to that employed by SAIM: both architectures are hierarchical, and both contain feedback loops. This paper offers a mathematical analysis of how these two architectures are related. In brief, we show that SAIM can be derived from first principles (i.e. the free-energy principle). However, SAIM assumes a different ‘generative model’ compared to those typically used in schemes like predictive coding. A crucial consequence of this difference is that SAIM's feedback loops are excitatory, while predictive coding schemes lead to inhibitory feedback loops (i.e. subtracting predictions from sensory input to form prediction errors). To facilitate a direct comparison between these two architectures, we derived a new version of SAIM—error prediction (EP)-SAIM—which uses the generative model usually adopted in predictive coding. We then present stimulation studies comparing the two models and produce (quantitative) predictions for future (EEG or fMRI) studies. In short, this work develops a formalism to address an important and long-standing systems neuroscience question: does the brain combine sensory information with prior knowledge using excitatory or inhibitory feedback? </p> <p>To clarify the arguments, especially for those unfamiliar with SAIM, we first present a slightly revised version of SAIM. To highlight the contrasting assumptions about the feedback loops, we will call this version excitatory matching (EM)-SAIM. We then replicate a key finding from the foundational paper that introduced SAIM. Using simulations, we illustrate EM-SAIM's ability to perform object identification in multiple object scenes. Moreover, these simulations show that EM-SAIM reproduces the well-known multiple object cost; i.e. the increased time it takes to detect a target object with increasing numbers of non-target objects. This ubiquitous empirical finding is an emergent property of SAIM's WTA mechanism. The evidence for multiple object cost comes from visual search experiments (e.g. [ <a href="#RSIF20180344C20">20</a>]; see [ <a href="#RSIF20180344C21">21</a>] for a review). Here, we reproduce these results using the EM version of SAIM. Having established the validity of this EM scheme, we then reformulated the soft constraints in SAIM as free-energy minimization—to produce a prediction error (PE)-SAIM. We then repeated the simulation studies using the same (synthetic) stimuli to establish its construct validity, in relation to EM-SAIM. Finally, we compare and contrast the simulation results to identify key aspects of belief updating that may enable the two versions to be disambiguated, using empirical measures of neuronal evidence accumulation (e.g. EEG or fMRI). The MatLab code for the simulation studies reported in this paper can be found in the Github repository <span class="uri" title="uri"> <a href="https://github.com/SAIM-models/EMvPE">https://github.com/SAIM-models/EMvPE</a> </span>. </p> <p>This paper does not aim to advance our understanding of selective visual attention <i>per se</i>; e.g. by comparing predictive coding and SAIM formulations of attention (e.g. [ <a href="#RSIF20180344C22">22</a>, <a href="#RSIF20180344C23">23</a>]). Rather, we hope to lay the foundations for empirical work that will disambiguate between these convergent formulations (see General discussion). Finally, we have tried to keep the mathematics accessible for readers without a mathematical background. </p> </div> <div class="theexcitatorymatching(em)-saim" title="sec"> <span class="label" tagx="label" title="label">2.</span> <div class="title" tagx="title" title="title">
The excitatory matching (EM)-SAIM</div> <p>Before presenting the mathematical derivation of EM-SAIM, we provide an overview of the EM-SAIM architecture ( <a href="#RSIF20180344F1">figure 1</a>; for an illustration). After considering the mathematical details, we then highlight how an EM-SAIM differs from the original SAIM. We conclude this section by demonstrating that EM-SAIM can reproduce multiple object costs. </p><div class="fig" title="fig"> <div class="figure" title="figure"> <a href="http://doi.org/"> <span class="label" tagx="label" title="label">Figure 1.</span> </a> </div>   <p>EM-SAIM's architecture. The three networks, Knowledge Network, Contents Network and Selection Network, have different functions: the Knowledge Network identifies the contents of the FOA by activating the best-matching template unit. The Contents Network maps a section of the input image into the FOA. The Selection Network determines the location of this section (see details in the main text). The arrows between the modules indicate the direction of message passing between the networks. (Online version in colour.) </p>   </div> <p /> <div class="overview" title="sec"> <span class="label" tagx="label" title="label">2.1.</span> <div class="title" tagx="title" title="title">
Overview</div> <p>EM-SAIM selects an object by mapping a region in the input image into a ‘focus of attention’ (FOA) ( <a href="#RSIF20180344F1">figure 1</a>). The mapping is implemented through the <i>Contents Network</i> and is translation invariant. This means that no matter where an object appears in the input scene, it can be mapped into the FOA. The <i>Selection Network</i> determines which region in the input image is mapped into the FOA. The <i>Selection Network</i> identifies this region by activating units in a layer that corresponds to locations in the input image ( <a href="#RSIF20180344F1">figure 1</a>). The output of the <i>Contents Network</i> is passed onto the <i>Knowledge Network</i>. The <i>Knowledge Network</i> is equipped with template units that store templates of known (i.e. recognizable) objects. This network compares the templates and the input from the <i>Contents Network</i> with a simple template matching. Given the results of this template matching, the <i>Knowledge Network</i> activates the best-matching template unit. This reflects the identity of the selected object—the object in the <i>Contents Network</i>. </p> <p>In addition to these bottom-up pathways, EM-SAIM also possesses top-down pathways. Note these top-down pathways are mandated by the soft constraint satisfaction approach described below. The top-down pathway from the <i>Knowledge Network</i> to the <i>Contents Network</i> adds a weighted sum of the templates to the activation in the FOA (excitatory feedback). The weighting is determined by the activation of the template units. In other words, the feedback directs the FOA to focus on the content of the <i>Contents Network</i>. The top-down connections from the <i>Contents Network</i> to the <i>Selection Network</i> underwrite a correlation of the <i>Contents Network</i> with the input image. The result of the correlation is feed into the <i>Selection Network</i>. Again—as with the feedback from <i>Knowledge Network <i>to</i> Contents Network— </i>this correlation rests on excitatory feedback. Since the <i>Selection Network</i> implements a WTA mechanism, this input directs the <i>Selection Network's</i> attention to the location in the input image that best matches the content of the <i>Contents Network</i>. </p> <p>It is important to note that EM-SAIM does not achieve object identification instantaneously. Rather, object identification evolves over time. Initially (if we assume that there is no foreknowledge about the objects in the scene), the template units have same activation; the <i>Contents Network</i> is set to an equally weighted summation of template units and the <i>Selection Network</i> has equal activation across all image locations (i.e. no spatial bias). Subsequently, EM-SAIM begins the selection process and identification process in parallel, eventually converging to a point attractor, in which no unit changes its activation. At that point, EM-SAIM is said to have selected and identified an object. </p> </div> <div class="mathematicalderivation" title="sec"> <span class="label" tagx="label" title="label">2.2.</span> <div class="title" tagx="title" title="title">
Mathematical derivation</div> <p>Our implementation of EM-SAIM is based on the energy function minimization scheme introduced by Hopfield &amp;amp; Tank [ <a href="#RSIF20180344C24">24</a>]. In this scheme, the desired outputs of a network are expressed in terms of constraints; e.g. template matching as a constraint on the object identification in the knowledge network. Network dynamics can then be expressed as a gradient descent on an energy function <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mo_UNKNOWN">
)</div> </div> </span> of the output activity <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> </div> </span> of the neurons. The energy function comprises a mixture of distinct energy functions, where the minimum of each component satisfies a particular constraint. This ensures the network dynamics implement a form of soft constraint satisfaction. The general form of EM-SAIM uses the gradient descent described by Hopfield &amp;amp; Tank [ <a href="#RSIF20180344C24">24</a>] </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.1</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
τ</div> <div class="msub_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mover_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mo_UNKNOWN">
˙</div> </div> </div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
−</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="mi_UNKNOWN">
E</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <p /> <p>Here, <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mover_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mo_UNKNOWN">
˙</div> </div> </div> <div class="mi_UNKNOWN">
i</div> </div> </div> </span> is the transmembrane potential of the <i>i</i>th neuron (or neural population), <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> </div> </span> is their firing rate activation and <i>τ</i> is the membrane time constant. The activation and depolarization are linked through a well-known sigmoid (activation) function: <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
=</div> <div class="mi_UNKNOWN">
f</div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
(</div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mn_UNKNOWN">
1</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
/</div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mn_UNKNOWN">
1</div> <div class="mo_UNKNOWN">
+</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
e</div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="mi_UNKNOWN">
m</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mi_UNKNOWN">
s</div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> </span>. </p> <p>To ensure a level of biological plausibility, SAIM's energy function includes an energy component for every neuron or unit </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.2</span> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
mem</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mn_UNKNOWN">
1</div> <div class="mi_UNKNOWN">
τ</div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
N</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mo_UNKNOWN">
∫</div> <div class="mn_UNKNOWN">
0</div> <div class="mrow_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
f</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
z</div> <div class="mi_UNKNOWN">
i</div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
d</div> </div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
z</div> <div class="mi_UNKNOWN">
i</div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <p /> <p>The gradient descent on this term leads to neuronal dynamics that emulate a leaky postsynaptic membrane. <sup> <a href="#FN1">1</a> </sup> Another energy component, that is central to SAIM, is the WTA energy function </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.3</span> <div class="math_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
WTA</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mn_UNKNOWN">
2</div> </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
N</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mn_UNKNOWN">
2</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mi_UNKNOWN">
b</div> <div class="munder_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
I</div> <div class="mi_UNKNOWN">
i</div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <p /> <p>Here, <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
I</div> <div class="mi_UNKNOWN">
i</div> </div> </div> </span> are the inputs to the <i>i</i>th neuron or neuronal population. This WTA energy function produces competition among neurons, in which the neuron with the largest input becomes activated—to nearly one (i.e. the winning unit), while all remaining neurons tend to zero. The first term corresponds to the constraint that the sum of all neuronal activities is equal to one; while the second term (i.e. input term) implies the constraint that the response of the neuron with the greatest input is maximal. The addition of the two ensures a WTA behaviour, where <i>a</i> and <i>b</i> weight the two constraints; allowing either constraint to dominate. The ensuing WTA behaviour is a nice illustration of <i>soft</i> constraint satisfaction. This energy function is important for the <i>Knowledge Network</i>, where the best-matching template is indicated by the highest input—and for <i>Selection Network</i>, as we will see later. It is also important to note that a change of the sign of the input term turns the WTA into a loser-take-all where the neuron with the smallest input wins the competition. This mechanism is important for PE-SAIM. </p> <p>To ensure that EM-SAIM satisfies all constraints imposed by its constituent networks, the energy functions for each network are combined to provide an objective function for the entire network </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.4</span> <div class="math_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
 </div> </div> <div class="mtd_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
mem</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
+</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mo_UNKNOWN">
+</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
+</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> </div> </div> <p /> <p>In other words, each network implements a constraint that is specified in terms of its unique energy function, while every neuron tries to minimize the total energy function: <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> </div> </span>. Here, <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> is the energy function for the <i>Selection Network</i>, <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> </div> </span> is the energy function for the <i>Contents Network</i> and <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> is the energy function for the <i>Knowledge Network</i> (i.e. superscripts SN, CN and KN stand for <i>Selection Network</i>, <i>Contents Network</i> and <i>Knowledge Network,</i> respectively). </p> <p>The arguments of the energy functions, <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> and <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span>, are the outputs of the <i>Selection Network</i> and the <i>Knowledge Network</i>, respectively, and <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> is the output of the <i>Contents Network</i>. The use of <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> </div> </span> here indicates that—in contrast with the <i>Knowledge Network</i> and the <i>Selection Network</i>—we drop the sigmoid function in the <i>Contents Network</i>. This follows because the <i>Contents Network</i> represents continuous valued sensory signals. Also note the use of matrix notation for the <i>Contents Network</i> and the <i>Selection Network</i> outputs, which are two-dimensional matrices. By contrast, the <i>Knowledge Network</i> output is a one-dimensional vector. In the following, we will consider each individual energy function and the constraints it satisfies in detail. </p> <div class="knowledgenetwork" title="sec"> <span class="label" tagx="label" title="label">2.2.1.</span> <div class="title" tagx="title" title="title">
Knowledge network</div> <p>The Knowledge Network implements template-based object identification through a scalar product </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.5</span> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
temp</div> </div> </div> </div> <div class="mo_UNKNOWN">
=</div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
w</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mi_UNKNOWN">
k</div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> <p /> <p>Here, <i>M</i> is the size of the FOA and <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
w</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mi_UNKNOWN">
k</div> </div> </div> </span> is the template of the <i>k</i>th template neuron or unit. The size of each template is the same as the size of the FOA. Examples of templates can be found in the simulations below ( <a href="#RSIF20180344F2">figure 2</a>). The Knowledge Network constraint ensures that the best-matching template unit is activated, while the remaining units are suppressed. The WTA energy function implements this constraint </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.6</span> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
K</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mn_UNKNOWN">
2</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
K</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
temp</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <div class="fig" title="fig"> <div class="figure" title="figure"> <a href="http://doi.org/"> <span class="label" tagx="label" title="label">Figure 2.</span> </a> </div>   <p>Input images and templates. The simulations used three input images and two templates in the Knowledge Network. The three input images were two single-object images (+ and 2) and one two-object image (+/2). The two templates perfectly matched the two objects. </p>   </div> <p /> </div> <div class="contentsnetwork" title="sec"> <span class="label" tagx="label" title="label">2.2.2.</span> <div class="title" tagx="title" title="title">
Contents network</div> <p>The Contents Network receives an input from Sigma-pi units (i.e. modulatory synaptic interactions) which combine the activation in the selection network and the visual field to realize a translation-invariant mapping </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.7</span> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
I</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mi_UNKNOWN">
n</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
=</div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
m</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
j</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
n</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> <p /> <p>Here, <i>N</i> is the size of the input image and <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
l</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> </div> </span> is the input image. Contents Network constraint ensures that the output units of the <i>Contents Network</i> reflect the output of the Sigma-pi units </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.8</span> <div class="math_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
I</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> <p /> </div> <div class="selectionnetwork" title="sec"> <span class="label" tagx="label" title="label">2.2.3.</span> <div class="title" tagx="title" title="title">
Selection network</div> <p>The Selection Network implements one constraint, which ensures that only one location is selected. Here, we used the first term of the WTA energy function </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.9</span> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
l</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
l</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mn_UNKNOWN">
2</div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <p /> <p>This concludes our description of the network-specific energy components that constitute the total energy. </p> <p>To simulate the processing of visual input, the total energy is minimized using a gradient descent scheme with the form of equation (2.1). In detail, we used an Euler approximation, with the addition of biological noise, of the sort implied by drift diffusion models (e.g. [ <a href="#RSIF20180344C25">25</a>]) </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.10</span> <div class="math_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mi_UNKNOWN">
t</div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
t</div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
−</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
t</div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
+</div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
ξ</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
;</div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
ξ</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
=</div> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mn_UNKNOWN">
0</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
σ</div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <p /> <p>Here, <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
ξ</div> <div class="mi_UNKNOWN">
i</div> </div> </div> </span> is the noise term with variance <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
σ</div> </div> </span>. The resulting energy gradients for each network can then be expressed as follows (using direct calculation): </p> <p> <i>Selection Network</i> </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.11</span> <div class="math_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
 </div> </div> </div> <div class="mtd_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
+</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> </div> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> </div> </div> </div> <div class="msubsup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> <div class="mo_UNKNOWN">
 </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
C</div> <div class="mi_UNKNOWN">
N</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="msubsup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
j</div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
V</div> <div class="mi_UNKNOWN">
F</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> </div> </div> <p /> <p> <i>Contents Network</i> </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.12</span> <div class="math_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
=</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
n</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
j</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
K</div> </div> </div> <div class="msubsup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
K</div> <div class="mi_UNKNOWN">
N</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="msubsup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
w</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> </div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <p /> <p> <i>Knowledge Network</i> </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.13</span> <div class="math_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
 </div> </div> </div> <div class="mtd_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
+</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
K</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> </div> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mi_UNKNOWN">
j</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
w</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mi_UNKNOWN">
k</div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> </div> </div> <p /> <p>The terms in bold font (i.e. input terms in equation (2.3)) represent feedback from higher networks to lower networks; i.e. from the Knowledge Network to the Contents Network and from Contents Network to Selection Network. These terms follow from the gradient descent and show that feedback connections are required for soft constraint satisfaction. Crucially, these feedback connections constitute a positive (i.e. excitatory) feedback (see <a href="#RSIF20180344TB1">table 1</a> for the circuit diagram of the implicit message passing and connections). For example, responses in the Contents Network <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mi_UNKNOWN">
n</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> </div> </div> </span> will descend the gradient in equation (2.12), and will therefore increase with the activity of units in the higher Knowledge Network <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span>. Similarly, unit responses in the Selection Network <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> </div> </div> </span> increase with the source of descending projections from the Contents Network <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span>. <div class="table-wrap_UNKNOWN"> <span class="label" tagx="label" title="label">Table 1.</span>  </div></p><p>Graphical illustration of feedback connections. These circuit diagrams illustrate how equations (2.11) and (2.12) for EM-SAIM and equations (3.3) and (3.4) for PE-SAIM map onto neural message passing and circuitry. Circles denote hypothetical neuronal populations, while the arrows correspond to connections. Excitatory connections are shown in black and inhibitory connections are shown in red. The small blue (crossed) circles denote a modulatory synaptic interaction (Sigma-pi units). These graphical illustrations illustrate why EM-SAIM can be seen as being mediated by excitatory feedback while PE-SAIM uses inhibitory feedback to implement a disinhibition via prediction error units. (Online version in colour.) </p>  <table> <div class="colgroup_UNKNOWN"> <div class="col_UNKNOWN" /></div>  <tbody> <tr> <td> <span class="inline-graphic" title="inline-graphic" /> </td> </tr> </tbody> </table>  <p /> </div> </div> <div class="comparingem-saimwiththeoriginalsaim" title="sec"> <span class="label" tagx="label" title="label">2.3.</span> <div class="title" tagx="title" title="title">
Comparing EM-SAIM with the original SAIM</div> <p>EM-SAIM incorporates two changes that lend it a greater biological plausibility than the original implementation. The first is the inclusion of Brownian noise. This not only makes EM-SAIM more biological plausible but enables it to simulate variations in response time commonly found in behavioural experiments. The second change concerns the feedback connections. In the original SAIM, the feedback from the <i>Knowledge Network</i> was conveyed directly to the <i>Selection Network</i>. In EM-SAIM, the <i>Knowledge Network</i> now projects to the <i>Contents Network</i> and the <i>Contents Network</i> projects to the <i>Selection Network</i>. This change creates a more plausible architecture, given that feedback tends to target input brain region (e.g. [ <a href="#RSIF20180344C26">26</a>]). </p> <p>This revised feedback architecture retains the top-down modulation of the selection process, albeit in a more indirect way. To fully understand neurobiological premise of this argument, it is worth noting that SAIM's networks can be related to the <i>what</i>-pathway and the <i>where</i>-pathway (see [ <a href="#RSIF20180344C1">1</a>] for a more detailed discussion). According to this interpretation, the <i>Knowledge Network</i> and the <i>Contents Network</i> correspond to brain regions in the <i>what</i>-pathway (ventral pathway), while the <i>Selection Network</i> corresponds to areas in the <i>where</i>-pathway (dorsal pathway), the posterior parietal cortex. Hence, if the <i>Knowledge Network</i> and the <i>Contents Network</i> are in the ventral pathway, feedback connections between these two networks better reflect known anatomical connections (as opposed to feedback connections to the <i>Selection Network</i> as in the original SAIM). </p> </div> <div class="simulationresults" title="sec"> <span class="label" tagx="label" title="label">2.4.</span> <div class="title" tagx="title" title="title">
Simulation results</div> <p>We first performed validation simulations to ensure EM-SAIM can replicate the simulations of multiple object cost in terms of reaction times, as reported in Study 2 of Heinke &amp;amp; Humphreys [ <a href="#RSIF20180344C1">1</a>]. As in the original study, we used two objects, 2 and + (cross) ( <a href="#RSIF20180344F2">figure 2</a>). These objects also formed the templates in the <i>Knowledge Network</i>. The reaction times were simulated by measuring the number of time steps it takes for a template unit to pass a threshold (see appendix A for parameters). The multiple object cost was simulated by contrasting the reaction times for input images with one object (+ or 2) with input images with two objects, + and 2. In empirical experiments, such as visual search tasks, multiple object costs are demonstrated with more objects (e.g. [ <a href="#RSIF20180344C20">20</a>]; see [ <a href="#RSIF20180344C3">3</a>] for a simulation study). However, for the purpose of this work, a simple set-up is sufficient to establish that EM-SAIM reproduces SAIM's cardinal behaviour. <a href="#RSIF20180344F3">Figure 3</a> shows an example of a typical simulation for three input images: +/2, single 2 and single +. </p><div class="fig" title="fig"> <div class="figure" title="figure"> <a href="http://doi.org/"> <span class="label" tagx="label" title="label">Figure 3.</span> </a> </div>   <p>Three exemplar simulation results for multiple object costs with EM-SAIM. The graphs show the time course of the activation for the FOA and the two template units in the Knowledge Network. The reaction times were measured by determining the number of iterations it takes for a template unit to pass a threshold (0.9). As expected, the results show that EM-SAIM's reaction times were slower for the two-objects image (1013 iterations) than for the two single-object images: + (687 iterations) and 2 (777 iterations). </p>   </div> <p /> <p>These examples show that EM-SAIM can reproduce the multiple object cost. Also, as in the original SAIM, EM-SAIM exhibits a top-down bias towards the +, as the combined templates match better with the+than the 2. We also conducted a study with 20 simulations for each input image, to establish there was a statistically significant difference between the three conditions ( <a href="#RSIF20180344F4">figure 4</a>). We applied a <i>t</i>-test to the simulation results and found a significant difference between +/2 and single + ( <i>t</i> <sub>38</sub> = 11.40; <i>p</i> &amp;lt; 0.001) and between +/2 and single 2 ( <i>t</i> <sub>38</sub> = 5.34; <i>p</i> &amp;lt; 0.001) (and between 2 and single + ( <i>t</i> <sub>38</sub> = −7.85; <i>p</i> &amp;lt; 0.001)). Crucially, the reaction time for +/2 was slower than for single + and single 2. </p><div class="fig" title="fig"> <div class="figure" title="figure"> <a href="http://doi.org/"> <span class="label" tagx="label" title="label">Figure 4.</span> </a> </div>   <p>Results for 20 simulation runs for each input image. There was significant difference between +/2 and single +; and between +/2 and single 2. Hence, EM-SAIM can replicate the findings with the original SAIM (see main text for details). </p>   </div> <p /> <p>In summary, these simulation results suggest that EM-SAIM reproduces the key result from the original SAIM simulations. In addition to the original SAIM simulations, the new (EM) version can also reproduce the natural variation of reaction times found in experiments with humans. Also, despite the addition of neuronal noise, none of the 40 single stimuli simulations showed an error and the +/2 simulations always identified the cross. Note that the exact numerical outcome of the simulations, such as the variation of reaction times, depends on the parameter settings. Nevertheless, a broad range of parameter settings produce the findings present here. We will return to the issue of numerical evaluation of the model in the discussion section of PE-SAIM. </p> </div> <div class="interpretingselectiveattentionforidentificationmodelwithintheactiveinferenceframework" title="sec"> <span class="label" tagx="label" title="label">2.5.</span> <div class="title" tagx="title" title="title">
Interpreting selective attention for identification model within the active inference framework </div> <p>In this section, we consider the links between the above formulation of visual processing within the PDP framework and current formulations based upon predictive coding and the Bayesian brain. In brief, we will see that both SAIM and approximate Bayesian inference can be described in terms of minimizing an energy function. The particular energy function used in Bayesian formulations corresponds to variational free energy (also known as an ‘evidence bound’ in machine learning). Variational free energy is a function of data and a generative model (i.e. a probabilistic model of how data are generated from causes, such as visual objects). In what follows, we show that the energy function used by SAIM can be interpreted as a variational free energy under a particular generative model. This means SAIM can be formulated in terms of Bayesian inference under a particular model of how visual data were generated. Furthermore, it means the computational architecture described in the previous section can be compared in a formal way to the architectures used in Bayesian schemes. </p> <p>Casting SAIM in terms of variational free-energy minimization is much simpler than one might suppose. The free-energy principle considers how the Bayesian brain hypothesis (see [ <a href="#RSIF20180344C27">27</a>] for a review) may be implemented in the brain. According to the free-energy principle (and in line with the Bayesian brain hypothesis), the brain is thought to use a generative model to infer the hidden (i.e. latent) causes of sensory signals. These models are characterized as ‘generative’ in the sense that they describe how the latent causes generate signals. In the course of the inference process, the brain is assumed to update representations (as encoded by a posterior probability density) of the latent causes via a minimization of ‘free energy’. This belief updating, evidence accumulation or inference process can be illustrated using SAIM's object identification. </p> <p>Let us assume the generative model of object identification comprised the templates used in SAIM. Hence, for each physical object (e.g. two, crosses, etc.), the templates represent the latent causes of sensory signals in the input image. Given these sensory signals, the minimization of the free energy produces a posterior probability density for each template—reflecting the probability that the sensory signals are caused by the corresponding object. On this view, the templates correspond to prior beliefs about the latent causes of sensory signals that are recovered from sensory data through Bayesian belief updating. This belief updating can be expressed as a gradient descent on variational free energy. </p> <p>An important point to note here is that the free energy minimized during inference is a single quantity (i.e. a functional of the posterior probability density and sensory input) that is specified by the generative model. In other words, the free energy is a global objective function analogous to SAIM's total energy function—and in both approaches, the energy has to be minimized. Hence, SAIM is, in effect, an instantiation of the free-energy principle. Moreover, a gradient descent on the free-energy functional implements the inference by optimizing the posterior distribution (e.g. [ <a href="#RSIF20180344C16">16</a>]). In short, SAIM's gradient descent is formally consistent with the free-energy principle. In addition, one can regard SAIM's soft constraint satisfaction as equivalent to probabilistic inference under certain prior beliefs (i.e. constraints on the way visual data are generated). </p> <p>Note that SAIM's inference process does not yield a representation of uncertainty, but simply a point estimate of the posterior. In Bayesian terms, this corresponds to a <i>maximum a posteriori</i> estimate. In terms of the free-energy principle, SAIM inverts a hierarchical Bayesian model, where the <i>Contents Network</i>, <i>Selection Network</i> and <i>Knowledge Network</i> encode the posterior expectations and hierarchical (also known as empirical) priors. Interestingly, the WTA constraints in SAIM can be regarded as implementing the prior belief that only one object can be in one place at a time. </p> <p>Having noted a formal equivalence between SAIM's energy minimization approach and the free-energy principle, one can now ask: what is SAIM's underlying generative model? In the free-energy approach, the probabilistic generative model is linked and energy through a Gibbs measure </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.14</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mo_UNKNOWN">
⁡</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
μ</div> <div class="mo_UNKNOWN">
|</div> <div class="mi_UNKNOWN">
m</div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
−</div> <div class="mi_UNKNOWN">
E</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
μ</div> <div class="mo_UNKNOWN">
|</div> <div class="mi_UNKNOWN">
m</div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
,</div> </div> </div>where <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> </div> </span> denotes sensory signals and <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
μ</div> </div> </span> are the expected causes of sensory signals under a generative model <i>m</i>. To reverse engineer the probabilistic representation in EM-SAIM, consider the energy function of EM-SAIM <div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.15</span> <div class="math_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mo_UNKNOWN">
⁡</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> </div> <div class="mtd_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
−</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> </div> </div> <p /> <p>This equation can be separated into network-specific components, which correspond to the empirical and full priors of the generative model <sup> <a href="#FN2">2</a> </sup> </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.16</span> <div class="math_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
p</div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mspace_UNKNOWN" /> <div class="mo_UNKNOWN">
=</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
|</div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
|</div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
,</div> </div> </div> </div> </div> </div> </div>with the likelihood and prior from the <i>Selection Network</i> becoming <div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.17</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mo_UNKNOWN">
⁡</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
|</div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mi_UNKNOWN">
n</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mi_UNKNOWN">
n</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
m</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
j</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
n</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> </div> </div>and <div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.18</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mo_UNKNOWN">
⁡</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
−</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mn_UNKNOWN">
2</div> </div> <div class="mo_UNKNOWN">
,</div> </div> </div> </div>and the empirical prior from the <i>Content Network</i> becoming <div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.19</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mo_UNKNOWN">
⁡</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
|</div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
K</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
w</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
 </div> </div> <div class="mi_UNKNOWN">
k</div> </div> </div> </div>and <div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">2.20</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
p</div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
−</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
K</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mn_UNKNOWN">
2</div> </div> <div class="mo_UNKNOWN">
,</div> </div> </div> </div>where the prior from the <i>Knowledge Network</i> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
p</div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> </span> is a full prior. <p /> <p>These equations show that SAIM's generative model is formally distinct from those used in predictive coding, which uses Gaussian priors to ensure the priors are conjugate with the approximate (Gaussian) posterior (this is known as the Laplace assumption in Bayesian statistics). Under Gaussian assumptions, the likelihood and empirical priors above would have quadratic forms. However, it is immediately evident that the generative model implicit in SAIM has a much richer form. For example, the full priors in equations (2.18) and (2.20) show that EM-SAIM's model assumes a sparse probability density over the causes in the <i>Selection</i> and <i>Knowledge Networks</i>. This follows because these prior energies are minimized when one of the latent (non-negative) causes are one and the rest are zero. This sort of non-Gaussian prior is commonly employed in LASSO (least absolute shrinkage and selection operator) regression analyses (see Discussion). We will now look more closely at this form and elaborate a variant of SAIM whose empirical priors can be expressed in terms of squared prediction errors. </p> </div> </div> <div class="thepe-saim" title="sec"> <span class="label" tagx="label" title="label">3.</span> <div class="title" tagx="title" title="title">
The PE-SAIM</div> <p>In the previous section, we formulated SAIM in terms of free-energy minimization under a particular generative model that entails non-Gaussian empirical priors, in contrast with predictive coding models that usually assume Gaussian forms. In this section, we modify EM-SAIM by adopting Gaussian assumptions in the generative model (called PE-SAIM) and examine whether this new version can replicate the multiple object cost findings above. Under Gaussian assumptions, the free-energy components can be expressed as squared <i>prediction errors</i>. In SAIM, this applies to two levels: the <i>Contents Network</i>, which predicts the activation in the input image modulated by the <i>Selection Network</i> via Sigma-pi units </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">3.1</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mo_UNKNOWN">
⁡</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
|</div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
−</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> </div> </div> <div class="disp-formula" title="disp-formula"> <div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
and</div> </div> <div class="mspace_UNKNOWN" /> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
=</div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="mo_UNKNOWN">
(</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
n</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
j</div> <div class="mo_UNKNOWN">
+</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
−</div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> </div> </div>and the <i>Knowledge Network</i> which predicts the content of the FOA <div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">3.2</span> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ln</div> <div class="mo_UNKNOWN">
⁡</div> <div class="mi_UNKNOWN">
p</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
|</div> </div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
−</div> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
K</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mn_UNKNOWN">
2</div> </div> </div> </div> </div> <div class="disp-formula" title="disp-formula"> <div class="math_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
and</div> </div> <div class="mspace_UNKNOWN" /> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
=</div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
w</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mi_UNKNOWN">
k</div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> <p /> <p>As noted earlier, the use of <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> (rather than <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span>) reflects the fact that the <i>Contents Network</i> uses a linear output function. Finally, note that in PE-SAIM, the two WTA priors (i.e. softmax) becomes a loser-take-all (i.e. softmin)—as the <i>Selection Network</i> and <i>Knowledge Network</i> need to select the best predictors; i.e. minimize prediction error. To minimize free energy, we again used an Euler scheme for gradient descent, retaining biological noise as in EM-SAIM. The requisite gradients for each network or hierarchical level can be derived by direct calculation from the above expressions: </p> <p> <i>Selection Network</i> </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">3.3</span> <div class="math_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> </div> </div> <div class="mtd_UNKNOWN"> <div class="mo_UNKNOWN">
=</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
+</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> </div> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mspace_UNKNOWN" /> <div class="mo_UNKNOWN">
+</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
M</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
M</div> </div> </div> <div class="msubsup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
C</div> <div class="mi_UNKNOWN">
N</div> </div> </div> </div> <div class="msubsup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
 </div> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mo_UNKNOWN">
 </div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
j</div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
V</div> <div class="mi_UNKNOWN">
F</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> </div> </div> <p /> <p> <i>Contents Network</i> </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">3.4</span> <div class="math_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
=</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
+</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
K</div> </div> <div class="msubsup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
K</div> <div class="mi_UNKNOWN">
N</div> </div> </div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> <p /> <p> <i>Knowledge Network</i> </p><div class="disp-formula" title="disp-formula"> <span class="label" tagx="label" title="label">3.5</span> <div class="math_UNKNOWN"> <div class="mtable_UNKNOWN"> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN"> <div class="mstyle_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mfrac_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
E</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
total</div> </div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
VF</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
Y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
X</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
,</div> <div class="msup_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
∂</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </div> </div> </div> </div> <div class="mtd_UNKNOWN"> <div class="mo_UNKNOWN">
=</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
k</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
+</div> <div class="mo_UNKNOWN">
 </div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="munder_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mi_UNKNOWN">
i</div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> <div class="mo_UNKNOWN">
)</div> </div> </div> </div> <div class="mtr_UNKNOWN"> <div class="mtd_UNKNOWN" /> <div class="mtd_UNKNOWN"> <div class="mspace_UNKNOWN" /> <div class="mo_UNKNOWN">
+</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> <div class="munderover_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
∑</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
N</div> <div class="mo_UNKNOWN">
,</div> <div class="mi_UNKNOWN">
N</div> </div> </div> <div class="mo_UNKNOWN">
⁡</div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> <div class="mo_UNKNOWN">
)</div> <div class="mo_UNKNOWN">
 </div> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
w</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
i</div> <div class="mi_UNKNOWN">
j</div> </div> <div class="mi_UNKNOWN">
k</div> </div> <div class="mo_UNKNOWN">
.</div> </div> </div> </div> </div> </div>These equations map onto a neural architecture as illustrated in <a href="#RSIF20180344TB1">table 1</a>. The summaries of neuronal message passing in <a href="#RSIF20180344TB1">table 1</a> illustrate why EM-SAIM can be seen as being mediated by excitatory feedback, while PE-SAIM uses inhibitory feedback to implement a disinhibition via prediction error units. For example, the influence of <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> <div class="mo_UNKNOWN">
 </div> </div> </span> on <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> is mediated by two inhibitory connections (via <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span>); namely, an inhibition of inhibition. As in the equations for EM-SAIM, we used bold to indicate the feedback terms between networks. However, in contrast with EM-SAIM, the feedback terms are mediated by prediction errors (i.e. the <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> </div> </span> terms in equations (3.1) and (3.2)) that implement an <i>inhibitory</i> (i.e. negative) influence of higher levels on the low levels. This inhibitory feedback is mandated by the formation of prediction errors. For example, the gradient descent implied by equation (3.4) means that units in the content network <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> increase when prediction errors <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msubsup_UNKNOWN"> <div class="mi_UNKNOWN">
ϵ</div> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
k</div> <div class="mi_UNKNOWN">
n</div> <div class="mi_UNKNOWN">
m</div> </div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> decrease. In short, by introducing prediction errors, we effectively reverse the sign of the coupling between successive levels in the hierarchy. <p /> <p>This architecture is consistent with generic predictive coding schemes, in which the prediction errors at any level in a predictive coding hierarchy are formed by subtracting predictions to create a prediction error or mismatch. Before considering the implications for neuronal message passing in the brain, we need to first establish the construct validity of the PE-SAIM in relation to the multiple object cost. </p> <div class="simulationresultsanddiscussion" title="sec"> <span class="label" tagx="label" title="label">3.1.</span> <div class="title" tagx="title" title="title">
Simulation results and discussion</div> <p>Figures <a href="#RSIF20180344F5">5</a> and <a href="#RSIF20180344F6">6</a> show simulation results that demonstrate PE-SAIM can also replicate the two-object cost. The <i>t</i>-test confirmed a significant difference between +/2 and single + ( <i>t</i> <sub>38</sub> = 17.09; <i>p</i> &amp;lt; 0.001) and between +/2 and single 2 ( <i>t</i> <sub>38</sub> = 16.52; <i>p</i> &amp;lt; 0.001) (and between 2 and single + ( <i>t</i> <sub>38</sub> = −4.00; <i>p</i> &amp;lt; 0.001)). Furthermore, none of the 40 single stimuli simulations showed an error and the +/2 simulations always selected the cross. Hence, both variants of SAIM can reproduce the qualitative multiple object costs. This is pleasing in the sense that it establishes a construct validity of the two schemes. In other words, both EM-SAIM and PE-SAIM can reproduce the finer (psychophysical) details of perceptual synthesis in recognizing multiple objects in visual scenes in a biologically plausible fashion. However, this presents an interesting challenge if we wanted to establish which offers the best account of neuronal message passing in real visual hierarchies. Recall from above that a key architectural difference between the two schemes is the use of top-down predictions to select the most likely explanation for sensory input in fundamentally different ways. The EM scheme uses <i>excitatory</i> feedback to ensure top-down constraints are satisfied in lower levels, while the PE scheme employs top-down predictions to form prediction errors using <i>inhibitory</i> feedback. </p><div class="fig" title="fig"> <div class="figure" title="figure"> <a href="http://doi.org/"> <span class="label" tagx="label" title="label">Figure 5.</span> </a> </div>   <p>Three exemplar simulation results for the multiple object costs with PE-SAIM. The graphs show the time course of the activation for the FOA and the two template units in the Knowledge Network. The reaction times were measured by determining the number of iterations it takes for a template unit to pass a set threshold (0.56). As expected, the results show that PE-SAIM's reaction times were slower for the two-objects image (1159 iterations) than for the two single-object images:+(271 iterations) and 2 (267 iterations). </p>   </div> <div class="fig" title="fig"> <div class="figure" title="figure"> <a href="http://doi.org/"> <span class="label" tagx="label" title="label">Figure 6.</span> </a> </div>   <p>Simulation results for PE-SAIM from 20 runs for stimulus. There was significant difference between +/2 and single +; and between +/2 and single 2. Hence, PE-SAIM can produce the same results as EM-SAIM (see main text for details). </p>   </div> <p /> </div> </div> <div class="comparingpe-saimwithem-saim" title="sec"> <span class="label" tagx="label" title="label">4.</span> <div class="title" tagx="title" title="title">
Comparing PE-SAIM with EM-SAIM</div> <p>It is important to note that these particular simulation results depend on our particular choice of parameters. <sup> <a href="#FN3">3</a> </sup> For both networks, the parameters were chosen to ensure significant reaction time cost effects in the absence of recognition errors. On the other hand, it would have been possible to generate simulation results where reaction costs are paired with recognition errors. Even though this observation is not crucial to make the point that, in principle, both models can replicate the two-object cost, it suggests the choice of parameters can modify the performance of object recognition in a measurable way. In turn, this affords the opportunity to compare the ability of the two schemes to explain empirical (e.g. psychophysical) data. This sort of comparison usually uses Bayesian model comparison. Bayesian model comparison has been used to disambiguate different models of choice behaviour and generally rests upon computing Bayes factors that score the evidence for one model over another, given the same data [ <a href="#RSIF20180344C28">28</a>] (see [ <a href="#RSIF20180344C29">29</a>] for a review). In brief, the Bayes factor assesses which model is better at generating a given dataset, considering all plausible parameter settings (under some generally uninformative prior over the parameters). </p> <p>For the purpose of evaluating the two implementations of SAIM, Bayesian model comparison could leverage trade-offs between recognition accuracy and reaction time costs (similar to the effects observed in our simulations) by varying the number of objects and the discriminability of the stimuli. In this setting, it might be possible to use the two models to fit behavioural accuracy and response times, by optimizing model parameters. In principle, it would then be possible to compare the evidence for both schemes in empirical response data. </p> <p>The simulations also illustrate an interesting point about the representation of the selected object in FOA. Despite the fact that there are no perfect representations of the selected object, both SAIMs can make correct decisions. This is the case because the ‘two’ can be easily discriminated from the ‘cross’. Note a perfect representation is not necessary as the task does not require it. Moreover, EM-SAIM's representation is less accurate than PE-SAIM's representation. This difference has the potential to distinguish between the two models. For instance, in an empirical study, participants could be required not only to find a certain object, but also to identify specific features of that object. Our simulations predict that inference under EM-SAIM would produce more errors than PE-SAIM. However, as noted above, this may depend the parameter settings, which would have to be optimized for any given choice behaviour, thereby enabling Bayesian model comparison to ascertain which model is the best account of empirical data. </p> <p>Apart from these behavioural assessments, PE-SAIM and EM-SAIM can also generate neuronal responses of the sort measured by EEG or fMRI. Most current methods of measuring neuronal activity are indirect and depend on which physiological process (e.g. dendrite depolarization, axonal firing, haemodynamics, etc.) the respective method (EEG, fMRI, etc.) can measure. To simulate neuronal responses, we omitted the <i>Contents Network</i>—as its activation depends on ‘pixilated inputs’. We summed the output activation and the input activation (as defined by equations (2.11), (2.13), (3.3) and (3.5)) for the <i>Selection Network</i> and the <i>Knowledge Network</i>. We excluded the activation from the softmax/softmin equations in these calculations. The resulting neuronal response reflects activation in dendritic trees and axons, while ignoring activation of inhibitory interneurons. </p> <p> <a href="#RSIF20180344F7">Figure 7</a> shows the resulting time courses of activations for both models. They suggest that it may be possible to distinguish between the two models: for EM-SAIM, the results suggest a reduction in activity in both areas, while for PE-SAIM, they evince an increase. These results may come as a surprise for some readers: given that PE-SAIM tries to minimize prediction error, a reduction in activity might have been expected; while for EM-SAIM, the opposite effect might have been expected. The counterintuitive results with EM-SAIM can be explained relatively easily. The initial state of EM-SAIM uses a weighted combination of templates in the <i>Knowledge</i> <i>Network <i>and</i> Contents Network </i>. This combined template matches with the two objects in the input image (but the match is better for ‘cross’ than for ‘two’). As the selection process proceeds, this match declines as only the ‘cross’ in the input is matched—and the ‘two’ template in the <i>Knowledge Network</i> ceases to match. The increase in activation in PE-SAIM needs some more detailed unpacking. Initially, the combined template produces a top-down prediction that generates a better match for the ‘cross’ than the ‘two’. The <i>Selection Network</i> starts to bias the FOA towards the ‘cross’. Subsequently, this bias leads to a mismatch with the top-down prediction leading to an increased activation (i.e. prediction error). As the <i>Knowledge Network</i> starts generating the improved prediction—by selecting the cross—the increase in the prediction error declines in the input of the <i>Knowledge Network</i>. However, as the ‘two’ template produces a non-matching prediction, the overall error does not fall back to zero. A similar effect can be observed for the <i>Selection Network</i>. Even though the FOA generates a prediction matching the ‘cross’ in the input, the mismatch with the ‘two’ leads to higher activation. These results highlight the complicated nature of evoked responses when both prediction error and attentional selection are in play (see [ <a href="#RSIF20180344C30">30</a>– <a href="#RSIF20180344C32">32</a>] for empirical examples in fMRI and EEG). </p><div class="fig" title="fig"> <div class="figure" title="figure"> <a href="http://doi.org/"> <span class="label" tagx="label" title="label">Figure 7.</span> </a> </div>   <p>Sum of input and output activation. These results show that the two models predict a qualitatively different time course of neuronal activation (see main text for details). </p>   </div> <p /> <p>Other neuroimaging methods to exploit these sorts of simulations empirically could focus on disambiguating between excitatory and disinhibitory responses to top-down afferents. There are a number of candidates that one could consider. First, one could use the laminar specificity of forward and backward (bottom-up and top-down) connections in conjunction with laminar-specific fMRI to make predictions about the neuronal correlates of attentional effects [ <a href="#RSIF20180344C33">33</a>]. Another approach would be to use frequency tagging to measure attentional effects on steady-state electrophysiological responses (e.g. [ <a href="#RSIF20180344C34">34</a>]). There are also several examples in the literature that use <i>dynamic causal modelling</i> to disambiguate between inhibitory and excitatory connections in cortical hierarchies [ <a href="#RSIF20180344C35">35</a>– <a href="#RSIF20180344C41">41</a>]. In brief, dynamic causal modelling entails fitting empirical (usually EEG—but see [ <a href="#RSIF20180344C42">42</a>], for example, using fMRI) data—in the form of evoked responses—using a neural mass model with lamina-specific coupling [ <a href="#RSIF20180344C35">35</a>, <a href="#RSIF20180344C43">43</a>]. One can then evaluate the evidence for competing architectures by specifying different patterns of connectivity within and between the neural masses that constitute electromagnetic sources (i.e. equivalent current dipoles). After the models have been fitted, the model evidence (i.e. the probability of the empirical data under each model) can be evaluated and used to adjudicate among different architectures. In principle, one could use exactly the same technology to test models that had different time constants—as well and different inhibitory or excitatory effects (e.g. [ <a href="#RSIF20180344C35">35</a>]). This would involve comparing equivalent models with different priors over the synaptic time constants or effective connectivity in question (i.e. the influence of descending or feedback afferents to a primary visual source). In this setting, dynamic causal modelling will also have to consider that PE-SAIM assumes not only feedback loops between regions but also within layers (see the error terms in equations (3.4) and (3.5)). Recent invasive data, addressing the alternative architectures for predictive coding, also offer the intriguing possibility of testing the alternative predictions about the nature of feedback (see [ <a href="#RSIF20180344C44">44</a>] for an example). </p> </div> <div class="generaldiscussion" title="sec"> <span class="label" tagx="label" title="label">5.</span> <div class="title" tagx="title" title="title">
General discussion</div> <p>The aim of the paper was to examine how SAIM's soft constraint satisfaction—using energy minimization—relates to the free-energy minimization of approximate Bayesian inference. To facilitate this comparison, we first created a new version of SAIM: EM-SAIM includes slightly more biologically plausible features than the original SAIM but crucially, for the purpose of this paper, is based on the same architecture and a formally similar energy function. We then ensured that EM-SAIM can reproduce the multiple object cost. Subsequently, we showed that SAIM's energy minimization can be interpreted in terms of Bayesian inference to a point estimator (i.e. maximum <i>a posteriori</i> estimate). We also noted that the ensuing probabilistic inference implements a soft constraint satisfaction, whereby empirical and full priors furnish the requisite constraints. By reverse engineering EM-SAIM's energy function, we showed that EM-SAIM's generative model uses a sparse prior of the sort commonly found in sparse regression models. It is worth noting that this type of prior is employed in methods such as the LASSO regression (e.g. [ <a href="#RSIF20180344C45">45</a>]) and independent component analysis (e.g. [ <a href="#RSIF20180344C46">46</a>]). The upshot of using this sort of prior is that it favours sparse representations of data. Furthermore, in EM-SAIM, the WTA forces the representation to become a local representation. Crucially, this generative model differs from the generative models used in predictive coding and related Bayesian filtering formulations of visual processing. These formulations normally employ a generative model based on Gaussian assumptions. Therefore, we replaced the empirical priors in EM-SAIM's architecture with a Gaussian form (i.e. log probabilities that are proportional to squared prediction errors) to show that PE-SAIM is also able to simulate the multiple object cost. </p> <p>Our simulations suggest that EM-SAIM and PE-SAIM are quantitatively indistinguishable, in terms of their predictions of behavioural (psychophysical) responses. However, with suitable experimental designs, the two models can be used to model empirical data quantitatively. If this is feasible, Bayesian model comparison should be able to disambiguate the two schemes using recognition accuracy and reaction times (e.g. [ <a href="#RSIF20180344C28">28</a>, <a href="#RSIF20180344C29">29</a>]). We further observed that EM-SAIM and PE-SAIM make quite different predictions about neuronal responses in terms of belief updating. EM-SAIM suggests that excitatory feedback loops mediate the behavioural effects we have illustrated, while PE-SAIM implies inhibitory feedback loops. Hence, these models seem to make distinct predictions about the physiology of feedback connections. </p> <p>At first glance, EM-SAIM appears to be more consistent with the well-known physiology of excitatory (glutamatergic) feedback connections in the cortex (e.g. [ <a href="#RSIF20180344C47">47</a>]). However, these feedback connections target inhibitory interneurons. Hence, it is possible that feedback connections can also mediate the construction of prediction error (see [ <a href="#RSIF20180344C16">16</a>, <a href="#RSIF20180344C43">43</a>, <a href="#RSIF20180344C48">48</a>, <a href="#RSIF20180344C49">49</a>] for detailed arguments). Therefore, our current knowledge of physiology does not definitively disambiguate the two architectures. On the other hand—and as discussed above—it may be possible to distinguish between the two architectures empirically; leveraging the fact that the two models make different predictions for excitatory or inhibitory nature of top-down afferents. The two types of feedback motifs may generate different dynamics (with different time constants). It is therefore conceivable that laminar-specific fMRI, dynamic causal modelling or frequency-tagged EEG, in conjunction with Bayesian model comparison, might allow us to disambiguate the two architectures using non-invasive techniques in humans (see [ <a href="#RSIF20180344C50">50</a>] for a contemporary discussion of empirical predictions for invasive studies). Finally, it is worth noting that both models make different predictions in terms of their preference for familiar versus novel stimuli. <sup> <a href="#FN4">4</a> </sup> EM-SAIM would prefer familiar stimuli, while PE-SAIM would prefer novel stimuli (that elicit greater prediction errors). Interestingly, a recent study by Park <i>et al</i>. [ <a href="#RSIF20180344C51">51</a>] found a category-specific (i.e. faces versus natural scenes) preference that could provide an interesting paradigm within which to test the two models. </p> <p>The microcircuits for predictive coding motifs in <a href="#RSIF20180344TB1">table 1</a> speak to disinhibition as the physiological mechanism for the effect of descending or backward connections (indicated by the double red lines in <a href="#RSIF20180344TB1">table 1</a>). There is growing interest and evidence for disinhibitory mechanisms of this sort (reviewed in [ <a href="#RSIF20180344C32">32</a>, <a href="#RSIF20180344C48">48</a>, <a href="#RSIF20180344C50">50</a>]). This evidence comes in part from recent invasive studies using optogenetic characterizations of inhibitory interneurons. Microcircuit motifs that use disinhibition have been found in several cortical regions [ <a href="#RSIF20180344C52">52</a>]: in brief, vasoactive intestinal peptide positive (VIP+) interneurons are thought to provide disinhibitory control, by targeting parvalbumin positive (PV+) and somatostatin positive (SOM+) interneurons that otherwise inhibit target excitatory neurons [ <a href="#RSIF20180344C53">53</a>]. This synaptic architecture is supported by evidence from rodent studies, showing that optogenetic inhibition of SOM+ and PV+ interneurons reduces the inhibitory effect of descending projections to V1 from cingulate cortex. Conversely, optogenetic inhibition of VIP+ interneurons enhances the effect of projections from cingulate cortex [ <a href="#RSIF20180344C54">54</a>]. In humans, disinhibitory effects can be observed when neocortical GABA is reduced using brain stimulation, both physiologically and functionally [ <a href="#RSIF20180344C55">55</a>]. In short, the balance of empirical evidence points to the disinhibitory motifs that implied by a PE-SAIM like architecture. </p> <p>The dialectic between excitatory and inhibitory feedback has been discussed in the literature at length (see [ <a href="#RSIF20180344C56">56</a>– <a href="#RSIF20180344C58">58</a>]). For example, Kersten <i>et al.</i> [ <a href="#RSIF20180344C57">57</a>] have formulated the dichotomy in terms of the ‘shut up’ versus ‘stop gossiping’ interpretations of Bayesian object perception. Intuitively, the shut up version corresponds to inhibitory top-down influences that ‘explain away’ any representations at lower levels to reduce the level of prediction error activity. Conversely, the suppression of activity in lower levels when something can be predicted may be better explained by top-down augmentation of the best representation that suppresses all competing expectations. Sometimes, the dichotomy is motivated by contrasting predictive coding with Grossberg adaptive resonance theory (ART) (e.g. [ <a href="#RSIF20180344C59">59</a>]; see also Kay &amp;amp; Phillips's [ <a href="#RSIF20180344C60">60</a>] coherence INFOMAX for a similar point; or Bowman <i>et al</i>.’s [ <a href="#RSIF20180344C61">61</a>] salience detector). According to ART, the excitatory feedback loop is particularly important in the induction of strong ‘resonance’ to foster learning. Hence, the ART resembles EM-SAIM's architecture in terms of excitatory feedback. </p> <p>Having established how SAIM is related to hierarchical Bayesian inference under the free-energy principle, it is worth returning to SAIM's domain of enquiry, modelling phenomena typically associated with selective visual attention. Predictive coding like formulations of attention introduce an additional variable that has to be optimized; namely, the amplitude of random fluctuations in sensory input—or its inverse called ‘precision’. This is a key quantity in engineering formulations of predictive coding (e.g. Kalman filtering). In this context, precision corresponds to the Kalman gain; namely, the gain or weight afforded prediction errors during belief updating. Crucially, the precision itself can be predicted. According to Feldman &amp;amp; Friston [ <a href="#RSIF20180344C22">22</a>] and Kanai <i>et al</i>. [ <a href="#RSIF20180344C23">23</a>], attention is realized as optimizing precision. In brief, top-down predictions of precision can select which prediction errors are effectively boosted, such that they have a greater influence on belief updating at higher levels of the hierarchy. This is thought to be the computational homologue of attention in predictive coding. Crucially, the top-down predictions of precision have an excitatory effect—in contrast with the inhibitory top-down feedback used to form prediction errors <i>per se</i>. When one considers predictions of precision, in the context of predictive coding formulations of attention, one has to consider both excitatory and inhibitory top-down feedback. Crucially, the excitatory top-down influences that mediate precision are modulatory or nonlinear in nature—in virtue of the fact that they modulate prediction errors. Interestingly, this speaks to the nonlinearities inherent in PE-SAIM. </p> <p>In conclusion, attention is intricately linked with perceptual inference. Interestingly, this assumption is strikingly similar to the influence of SAIM's <i>Selection Network</i> using Sigma-pi units. Hence, it should be relatively straightforward to modify PE-SAIM and let the <i>Selection Network</i> modulate prediction error rather than the sensory information. We cannot foresee any problems in terms of functionality of this new PE-SAIM and anticipate it should behave in a similar way to the PE-SAIM described above. We will consider the formal relationship between precision and the role of the <i>Selection Network</i> in SAIM in a subsequent paper—and pursue the implications for the functional anatomy of visual attention. </p> </div> </div> <div class="back" title="back"> <div class="ack" title="ack"> <div class="title" tagx="title" title="title">
Acknowledgements</div> <p>The authors would like to thank Howard Bowman, University of Kent and Ulrik Beierholm, University of Durham for the insightful discussions during the preparation of this paper. We would also like to thank the reviewers for invaluable help with several conceptual and technical issues. </p> </div> <div class="fn-group" title="fn-group"> <div class="title" tagx="title" title="title">
Endnotes</div> <div class="fn-type-" title=""> <span class="label" tagx="label" title="label">1</span> <p>An intuitive explanation of this component is that its partial derivative ‘removes’ the integral leaving only the term <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
f</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="mn_UNKNOWN">
1</div> </div> </div> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
y</div> <div class="mi_UNKNOWN">
i</div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> </span>. The ensuing link between <i>x</i> and <i>y</i> turns this term into a leak term: <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="mo_UNKNOWN">
(</div> <div class="mrow_UNKNOWN"> <div class="mo_UNKNOWN">
−</div> <div class="msub_UNKNOWN"> <div class="mi_UNKNOWN">
x</div> <div class="mi_UNKNOWN">
i</div> </div> </div> <div class="mo_UNKNOWN">
)</div> </div> </span>. </p> </div> <div class="fn-type-" title=""> <span class="label" tagx="label" title="label">2</span> <p>Empirical priors are priors that are themselves parametrized by random variables. Empirical priors are part of any hierarchical generative model, with full priors at the highest level. </p> </div> <div class="fn-type-" title=""> <span class="label" tagx="label" title="label">3</span> <p>This is also true for the fact that EM-SAIM exhibits lower levels of noise than PE-SAIM.</p> </div> <div class="fn-type-" title=""> <span class="label" tagx="label" title="label">4</span> <p>We would like to thank the second reviewer for this idea.</p> </div> </div> <div class="dataaccessibility" title="sec"> <div class="title" tagx="title" title="title">
Data accessibility</div> <p>The MatLab scripts for the publication can found on Github: <span class="uri" title="uri"> <a href="https://github.com/saim-models/EMvPE.git">https://github.com/saim-models/EMvPE.git</a> </span>. </p> </div> <div class="authors'contributions" title="sec"> <div class="title" tagx="title" title="title">
Authors' contributions</div> <p>A.K.A. and M.A. helped with the mathematics and commented on drafts. K.Y. and D.H. conducted the simulation studies. K.F. and D.H. conceived the study and drafted the manuscript. All authors gave final approval for publication. </p> </div> <div class="COI-statement" title="COI-statement"> <div class="title" tagx="title" title="title">
Competing interests</div> <p>We declare we have no competing interests.</p> </div> <div class="funding" title="sec"> <div class="title" tagx="title" title="title">
Funding</div> <p>K.F. is funded by a Wellcome Trust Principal Research Fellowship (no. 088130/Z/09/Z).</p> </div> <div class="app-group" title="app-group"> <div class="app" title="app"> <div class="title" tagx="title" title="title">
Appendix A. Parameter values</div> <p> <div class="table-wrap_UNKNOWN">  </div></p><p>EM-SAIM</p>  <table> <div class="colgroup_UNKNOWN"> <div class="col_UNKNOWN" /></div> <div class="colgroup_UNKNOWN"><div class="col_UNKNOWN" /></div> <div class="colgroup_UNKNOWN"><div class="col_UNKNOWN" /></div>  <thead> <tr> <th>network</th> <th>parameter name</th> <th>value</th> </tr> </thead> <tbody> <tr> <td /> <td>threshold for reaction time</td> <td>0.7</td> </tr> <tr> <td>maximal duration of simulation</td> <td>1500</td> </tr> <tr> <td> <i>Knowledge Network</i> </td> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
τ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>1000</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>10</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>0.1</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
s</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>3.0</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>30</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
σ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>6 × 10 <sup>−4</sup> </td> </tr> <tr> <td> <i>Contents Network</i> </td> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
τ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> </td> <td>600</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> </td> <td>0.5</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
σ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> </td> <td>8 × 10 <sup>−4</sup> </td> </tr> <tr> <td> <i>Selection Network</i> </td> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
τ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>200</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>15</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
s</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>0</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>5</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
σ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>0.0014</td> </tr> </tbody> </table>  <div class="table-wrap_UNKNOWN">  <p>PE-SAIM</p>  <table> <div class="colgroup_UNKNOWN"> <div class="col_UNKNOWN" /></div> <div class="colgroup_UNKNOWN"><div class="col_UNKNOWN" /></div> <div class="colgroup_UNKNOWN"><div class="col_UNKNOWN" /></div>  <thead> <tr> <th>network</th> <th>parameter name</th> <th>value</th> </tr> </thead> <tbody> <tr> <td /> <td>threshold for reaction time</td> <td>0.56</td> </tr> <tr> <td>maximal duration of simulation</td> <td>2300</td> </tr> <tr> <td> <i>Knowledge Network</i> </td> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
τ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>2000</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>20</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>1.5</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
s</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>8</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>50</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
σ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
KN</div> </div> </div> </div> </div> </span> </td> <td>7 × 10 <sup>−4</sup> </td> </tr> <tr> <td> <i>Contents Network</i> </td> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
τ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> </td> <td>500</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
b</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> </td> <td>4</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
σ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
CN</div> </div> </div> </div> </div> </span> </td> <td>5 × 10 <sup>−4</sup> </td> </tr> <tr> <td> <i>Selection Network</i> </td> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
τ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>5000</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
a</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>100</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
s</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>5</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
m</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>100</td> </tr> <tr> <td> <span class="inline-formula" title="inline-formula"> <div class="math_UNKNOWN"> <div class="msup_UNKNOWN"> <div class="mi_UNKNOWN">
σ</div> <div class="mrow_UNKNOWN"> <div class="mrow_UNKNOWN"> <div class="mi_UNKNOWN">
SN</div> </div> </div> </div> </div> </span> </td> <td>2.86 × 10 <sup>−4</sup> </td> </tr> </tbody> </table> </div> <p /> </div> </div> <div class="references">
References</div> <div tag="ref-list"> <ul> <div class="title" tagx="title" title="title">
References</div> <li tag="ref"> <a name="RSIF20180344C1" /> <span class="label" tagx="label" title="label">1</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Humphreys</span> <span class="given-names" tagx="given-names" title="given-names">GW</span> </span> </span> <span class="year" tagx="year" title="year">2003</span> <span class="mixed-article-title" title="mixed-article-title">Computational models of visual selective attention: a review</span>. In <span class="source" tagx="source" title="source">Connectionist models in cognitive psychology (studies in cognition)</span> (ed. <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Houghton</span> <span class="given-names" tagx="given-names" title="given-names">G</span> </span> </span>). <span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">New York, NY</span>: <span class="publisher-name" tagx="publisher-name" title="publisher-name">Psychology Press</span>. </span> </li> <li tag="ref"> <a name="RSIF20180344C2" /> <span class="label" tagx="label" title="label">2</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Rumelhart</span> <span class="given-names" tagx="given-names" title="given-names">DE</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">McClelland</span> <span class="given-names" tagx="given-names" title="given-names">JL</span> </span> </span> <span class="year" tagx="year" title="year">1988</span> <span class="source" tagx="source" title="source">Parallel distributed processing: explorations in the microstructure of cognition, Vol. 1 foundations </span>. <span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Cambridge, MA</span>: <span class="publisher-name" tagx="publisher-name" title="publisher-name">MIT Press</span>. </span> </li> <li tag="ref"> <a name="RSIF20180344C3" /> <span class="label" tagx="label" title="label">3</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Backhaus</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span> </span> <span class="year" tagx="year" title="year">2011</span> <span class="mixed-article-title" title="mixed-article-title">Modelling visual search with the selective attention for identification model (VS-SAIM): a novel explanation for visual search asymmetries </span>. <span class="source" tagx="source" title="source">Cogn. Comput.</span> <span class="volume" tagx="volume" title="volume">1</span>, <span class="fpage" tagx="fpage" title="fpage">185</span>– <span class="lpage" tagx="lpage" title="lpage">205</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1007/s12559-010-9076-x">10.1007/s12559-010-9076-x</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C4" /> <span class="label" tagx="label" title="label">4</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Mavritsaki</span> <span class="given-names" tagx="given-names" title="given-names">E</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Allen</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Deco</span> <span class="given-names" tagx="given-names" title="given-names">G</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Humphreys</span> <span class="given-names" tagx="given-names" title="given-names">GW</span> </span> </span> <span class="year" tagx="year" title="year">2011</span> <span class="mixed-article-title" title="mixed-article-title">Bridging the gap between physiology and behavior: evidence from the sSoTS model of human visual attention </span>. <span class="source" tagx="source" title="source">Psychol. Rev.</span> <span class="volume" tagx="volume" title="volume">118</span>, <span class="fpage" tagx="fpage" title="fpage">3</span>– <span class="lpage" tagx="lpage" title="lpage">41</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1037/a0021868">10.1037/a0021868</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/21244184">21244184</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C5" /> <span class="label" tagx="label" title="label">5</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Narbutas</span> <span class="given-names" tagx="given-names" title="given-names">V</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Lin</span> <span class="given-names" tagx="given-names" title="given-names">Y-S</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kristan</span> <span class="given-names" tagx="given-names" title="given-names">M</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span> </span> <span class="year" tagx="year" title="year">2017</span> <span class="mixed-article-title" title="mixed-article-title">Serial versus parallel search: a model comparison approach based on reaction time distributions </span>. <span class="source" tagx="source" title="source">Vis. Cogn.</span> <span class="volume" tagx="volume" title="volume">25</span>, <span class="fpage" tagx="fpage" title="fpage">306</span>– <span class="lpage" tagx="lpage" title="lpage">325</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1080/13506285.2017.1352055">10.1080/13506285.2017.1352055</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C6" /> <span class="label" tagx="label" title="label">6</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Backhaus</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Sun</span> <span class="given-names" tagx="given-names" title="given-names">Y</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Humphreys</span> <span class="given-names" tagx="given-names" title="given-names">GW</span> </span> </span> <span class="year" tagx="year" title="year">2007</span> <span class="mixed-article-title" title="mixed-article-title">The selective attention for identification model (SAIM): simulating visual search in natural colour images </span>. In <span class="source" tagx="source" title="source">Attention in cognitive systems. Theories and systems from an interdisciplinary viewpoint</span> (eds <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Paletta</span> <span class="given-names" tagx="given-names" title="given-names">L</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Rome</span> <span class="given-names" tagx="given-names" title="given-names">E</span> </span> </span>). <span class="comment">Lecture Notes in Computer Science, vol. 4840, pp. 141–154.</span> <span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Berlin, Germany</span>: <span class="publisher-name" tagx="publisher-name" title="publisher-name">Springer</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.1007/978-3-540-77343-6_9">10.1007/978-3-540-77343-6_9</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C7" /> <span class="label" tagx="label" title="label">7</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Sun</span> <span class="given-names" tagx="given-names" title="given-names">Y</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Humphreys</span> <span class="given-names" tagx="given-names" title="given-names">GW</span> </span> </span> <span class="year" tagx="year" title="year">2004</span> <span class="mixed-article-title" title="mixed-article-title">Modelling grouping through interactions between top-down and bottom-up processes: the grouping and selective attention for identification model (G-SAIM) </span>. In <span class="comment"> <i>Attention and performance in computational vision</i> (eds L Paletta, JK Tsotsos, E Rome). Lecture Notes in Computer Science, vol. 3368, pp. 148–158. Berlin, Germany: Springer. </span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.1007/978-3-540-30572-9_11">10.1007/978-3-540-30572-9_11</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C8" /> <span class="label" tagx="label" title="label">8</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Böhme</span> <span class="given-names" tagx="given-names" title="given-names">C</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span> </span> <span class="year" tagx="year" title="year">2009</span> <span class="mixed-article-title" title="mixed-article-title">Modeling visual affordances: the selective attention for action model (SAAM)</span>. In <span class="source" tagx="source" title="source">Connectionist models of behaviour and cognition II</span> (eds <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Mayor</span> <span class="given-names" tagx="given-names" title="given-names">J</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Ruh</span> <span class="given-names" tagx="given-names" title="given-names">N</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Plunkett</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span> </span>), pp. <span class="fpage" tagx="fpage" title="fpage">325</span>– <span class="lpage" tagx="lpage" title="lpage">336</span>. <span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Singapore</span>: <span class="publisher-name" tagx="publisher-name" title="publisher-name">World Scientific</span>. </span> </li> <li tag="ref"> <a name="RSIF20180344C9" /> <span class="label" tagx="label" title="label">9</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Zibner</span> <span class="given-names" tagx="given-names" title="given-names">SKU</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Faubel</span> <span class="given-names" tagx="given-names" title="given-names">C</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Iossifidis</span> <span class="given-names" tagx="given-names" title="given-names">I</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Schöner</span> <span class="given-names" tagx="given-names" title="given-names">G</span> </span> </span> <span class="year" tagx="year" title="year">2011</span> <span class="mixed-article-title" title="mixed-article-title">Dynamic neural fields as building blocks of a cortex-inspired architecture for robotic scene representation </span>. <span class="source" tagx="source" title="source">IEEE Trans. Auton. Ment. Dev.</span> <span class="volume" tagx="volume" title="volume">3</span>, <span class="fpage" tagx="fpage" title="fpage">74</span>– <span class="lpage" tagx="lpage" title="lpage">91</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1109/TAMD.2011.2109714">10.1109/TAMD.2011.2109714</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C10" /> <span class="label" tagx="label" title="label">10</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Sandamirskaya</span> <span class="given-names" tagx="given-names" title="given-names">Y</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Zibner</span> <span class="given-names" tagx="given-names" title="given-names">SK</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Schneegans</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Schöner</span> <span class="given-names" tagx="given-names" title="given-names">G</span> </span> </span> <span class="year" tagx="year" title="year">2013</span> <span class="mixed-article-title" title="mixed-article-title">Using dynamic field theory to extend the embodiment stance toward higher cognition</span>. <span class="source" tagx="source" title="source">New Ideas Psychol.</span> <span class="volume" tagx="volume" title="volume">31</span>, <span class="fpage" tagx="fpage" title="fpage">322</span>– <span class="lpage" tagx="lpage" title="lpage">339</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.newideapsych.2013.01.002">10.1016/j.newideapsych.2013.01.002</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C11" /> <span class="label" tagx="label" title="label">11</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Strauss</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Woodgate</span> <span class="given-names" tagx="given-names" title="given-names">PJW</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Sami</span> <span class="given-names" tagx="given-names" title="given-names">SA</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">Choice reaching with a LEGO arm robot (CoRLEGO): the motor system guides visual attention to movement-relevant information </span>. <span class="source" tagx="source" title="source">Neural Netw.</span> <span class="volume" tagx="volume" title="volume">72</span>, <span class="fpage" tagx="fpage" title="fpage">3</span>– <span class="lpage" tagx="lpage" title="lpage">12</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neunet.2015.10.005">10.1016/j.neunet.2015.10.005</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/26667353">26667353</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C12" /> <span class="label" tagx="label" title="label">12</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Faubel</span> <span class="given-names" tagx="given-names" title="given-names">C</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Schöner</span> <span class="given-names" tagx="given-names" title="given-names">G</span> </span> </span> <span class="year" tagx="year" title="year">2008</span> <span class="mixed-article-title" title="mixed-article-title">Learning to recognise objects on the fly: a neurally based dynamic field approach</span>. <span class="source" tagx="source" title="source">Neural Netw.</span> <span class="volume" tagx="volume" title="volume">21</span>, <span class="fpage" tagx="fpage" title="fpage">562</span>– <span class="lpage" tagx="lpage" title="lpage">576</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neunet.2008.03.007">10.1016/j.neunet.2008.03.007</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/18501555">18501555</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C13" /> <span class="label" tagx="label" title="label">13</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Faubel</span> <span class="given-names" tagx="given-names" title="given-names">C</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Schöner</span> <span class="given-names" tagx="given-names" title="given-names">G</span> </span> </span> <span class="year" tagx="year" title="year">2009</span> <span class="mixed-article-title" title="mixed-article-title">A neuro-dynamic architecture for one shot learning of objects that uses both bottom-up recognition and top-down prediction </span>. In <span class="conf-name" tagx="conf-name" title="conf-name">2009 IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, St Louis, MO, USA, 10–15 October 2009 </span>, pp. <span class="fpage" tagx="fpage" title="fpage">3162</span>– <span class="lpage" tagx="lpage" title="lpage">3169</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1109/IROS.2009.5354380">10.1109/IROS.2009.5354380</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C14" /> <span class="label" tagx="label" title="label">14</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Mattout</span> <span class="given-names" tagx="given-names" title="given-names">J</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Trujillo-Barreto</span> <span class="given-names" tagx="given-names" title="given-names">N</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Ashburner</span> <span class="given-names" tagx="given-names" title="given-names">J</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Penny</span> <span class="given-names" tagx="given-names" title="given-names">W</span> </span> </span> <span class="year" tagx="year" title="year">2007</span> <span class="mixed-article-title" title="mixed-article-title">Variational free energy and the Laplace approximation</span>. <span class="source" tagx="source" title="source">Neuroimage</span> <span class="volume" tagx="volume" title="volume">34</span>, <span class="fpage" tagx="fpage" title="fpage">220</span>– <span class="lpage" tagx="lpage" title="lpage">234</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuroimage.2006.08.035">10.1016/j.neuroimage.2006.08.035</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/17055746">17055746</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C15" /> <span class="label" tagx="label" title="label">15</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kilner</span> <span class="given-names" tagx="given-names" title="given-names">J</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Harrison</span> <span class="given-names" tagx="given-names" title="given-names">L</span> </span> </span> <span class="year" tagx="year" title="year">2006</span> <span class="mixed-article-title" title="mixed-article-title">A free energy principle for the brain</span>. <span class="source" tagx="source" title="source">J. Physiol. Paris</span> <span class="volume" tagx="volume" title="volume">100</span>, <span class="fpage" tagx="fpage" title="fpage">70</span>– <span class="lpage" tagx="lpage" title="lpage">87</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.jphysparis.2006.10.001">10.1016/j.jphysparis.2006.10.001</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/17097864">17097864</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C16" /> <span class="label" tagx="label" title="label">16</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span> </span> <span class="year" tagx="year" title="year">2008</span> <span class="mixed-article-title" title="mixed-article-title">Hierarchical models in the brain</span>. <span class="source" tagx="source" title="source">PLoS Comput. Biol.</span> <span class="volume" tagx="volume" title="volume">4</span>, <span class="fpage" tagx="fpage" title="fpage">e1000211</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.1371/journal.pcbi.1000211">10.1371/journal.pcbi.1000211</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/18989391">18989391</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C17" /> <span class="label" tagx="label" title="label">17</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span> </span> <span class="year" tagx="year" title="year">2010</span> <span class="mixed-article-title" title="mixed-article-title">The free-energy principle: a unified brain theory?</span> <span class="source" tagx="source" title="source">Nat. Rev. Neurosci.</span> <span class="volume" tagx="volume" title="volume">11</span>, <span class="fpage" tagx="fpage" title="fpage">127</span>– <span class="lpage" tagx="lpage" title="lpage">138</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1038/nrn2787">10.1038/nrn2787</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/20068583">20068583</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C18" /> <span class="label" tagx="label" title="label">18</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Clark</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span> </span> <span class="year" tagx="year" title="year">2013</span> <span class="mixed-article-title" title="mixed-article-title">Whatever next? Predictive brains, situated agents, and the future of cognitive science</span>. <span class="source" tagx="source" title="source">Behav. Brain Sci.</span> <span class="volume" tagx="volume" title="volume">36</span>, <span class="fpage" tagx="fpage" title="fpage">181</span>– <span class="lpage" tagx="lpage" title="lpage">204</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1017/S0140525X12000477">10.1017/S0140525X12000477</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/23663408">23663408</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C19" /> <span class="label" tagx="label" title="label">19</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Hohwy</span> <span class="given-names" tagx="given-names" title="given-names">J</span> </span> </span> <span class="year" tagx="year" title="year">2013</span> <span class="source" tagx="source" title="source">The predictive mind</span>. <span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">Oxford, UK</span>: <span class="publisher-name" tagx="publisher-name" title="publisher-name">Oxford University Press</span>. </span> </li> <li tag="ref"> <a name="RSIF20180344C20" /> <span class="label" tagx="label" title="label">20</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Lin</span> <span class="given-names" tagx="given-names" title="given-names">Y</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Heinke</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Humphreys</span> <span class="given-names" tagx="given-names" title="given-names">GW</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">Modeling visual search using three-parameter probability functions in a hierarchical Bayesian framework </span>. <span class="source" tagx="source" title="source">Attent. Percept. Psychophys.</span> <span class="volume" tagx="volume" title="volume">77</span>, <span class="fpage" tagx="fpage" title="fpage">985</span>– <span class="lpage" tagx="lpage" title="lpage">1010</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.3758/s13414-014-0825-x">10.3758/s13414-014-0825-x</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C21" /> <span class="label" tagx="label" title="label">21</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Eckstein</span> <span class="given-names" tagx="given-names" title="given-names">MP</span> </span> </span> <span class="year" tagx="year" title="year">2011</span> <span class="mixed-article-title" title="mixed-article-title">Visual search: a retrospective</span>. <span class="source" tagx="source" title="source">J. Vis.</span> <span class="volume" tagx="volume" title="volume">11</span>, <span class="fpage" tagx="fpage" title="fpage">1</span>– <span class="lpage" tagx="lpage" title="lpage">36</span>. </span> </li> <li tag="ref"> <a name="RSIF20180344C22" /> <span class="label" tagx="label" title="label">22</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Feldman</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span> </span> <span class="year" tagx="year" title="year">2010</span> <span class="mixed-article-title" title="mixed-article-title">Attention, uncertainty, and free-energy</span>. <span class="source" tagx="source" title="source">Front. Hum. Neurosci.</span> <span class="volume" tagx="volume" title="volume">4</span>, <span class="fpage" tagx="fpage" title="fpage">215</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.3389/fnhum.2010.00215">10.3389/fnhum.2010.00215</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/21160551">21160551</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C23" /> <span class="label" tagx="label" title="label">23</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kanai</span> <span class="given-names" tagx="given-names" title="given-names">R</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Komura</span> <span class="given-names" tagx="given-names" title="given-names">Y</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Shipp</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">Cerebral hierarchies: predictive processing, precision and the pulvinar</span>. <span class="source" tagx="source" title="source">Phil. Trans. R. Soc. B</span> <span class="volume" tagx="volume" title="volume">370</span>, <span class="fpage" tagx="fpage" title="fpage">20140169</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.1098/rstb.2014.0169">10.1098/rstb.2014.0169</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/25823866">25823866</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C24" /> <span class="label" tagx="label" title="label">24</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Hopfield</span> <span class="given-names" tagx="given-names" title="given-names">JJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Tank</span> <span class="given-names" tagx="given-names" title="given-names">DW</span> </span> </span> <span class="year" tagx="year" title="year">1986</span> <span class="mixed-article-title" title="mixed-article-title">Computing with neural circuits: a model</span>. <span class="source" tagx="source" title="source">Science</span> <span class="volume" tagx="volume" title="volume">233</span>, <span class="fpage" tagx="fpage" title="fpage">625</span>– <span class="lpage" tagx="lpage" title="lpage">633</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1126/science.3755256">10.1126/science.3755256</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/3755256">3755256</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C25" /> <span class="label" tagx="label" title="label">25</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Ratcliff</span> <span class="given-names" tagx="given-names" title="given-names">R</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">McKoon</span> <span class="given-names" tagx="given-names" title="given-names">G</span> </span> </span> <span class="year" tagx="year" title="year">2008</span> <span class="mixed-article-title" title="mixed-article-title">The diffusion decision model: theory and data for two-choice decision tasks</span>. <span class="source" tagx="source" title="source">Neural Comput.</span> <span class="volume" tagx="volume" title="volume">20</span>, <span class="fpage" tagx="fpage" title="fpage">873</span>– <span class="lpage" tagx="lpage" title="lpage">922</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1162/neco.2008.12-06-420">10.1162/neco.2008.12-06-420</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/18085991">18085991</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C26" /> <span class="label" tagx="label" title="label">26</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Lamme</span> <span class="given-names" tagx="given-names" title="given-names">VAF</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Supèr</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Spekreijse</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span> </span> <span class="year" tagx="year" title="year">1998</span> <span class="mixed-article-title" title="mixed-article-title">Feedforward, horizontal, and feedback processing in the visual cortex</span>. <span class="source" tagx="source" title="source">Curr. Opin. Neurobiol.</span> <span class="volume" tagx="volume" title="volume">8</span>, <span class="fpage" tagx="fpage" title="fpage">529</span>– <span class="lpage" tagx="lpage" title="lpage">535</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/S0959-4388(98)80042-1">10.1016/S0959-4388(98)80042-1</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/9751656">9751656</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C27" /> <span class="label" tagx="label" title="label">27</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Knill</span> <span class="given-names" tagx="given-names" title="given-names">DC</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Pouget</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span> </span> <span class="year" tagx="year" title="year">2004</span> <span class="mixed-article-title" title="mixed-article-title">The Bayesian brain: the role of uncertainty in neural coding and computation</span>. <span class="source" tagx="source" title="source">Trends Neurosci.</span> <span class="volume" tagx="volume" title="volume">27</span>, <span class="fpage" tagx="fpage" title="fpage">712</span>– <span class="lpage" tagx="lpage" title="lpage">719</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.tins.2004.10.007">10.1016/j.tins.2004.10.007</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/15541511">15541511</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C28" /> <span class="label" tagx="label" title="label">28</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kass</span> <span class="given-names" tagx="given-names" title="given-names">RE</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Raftery</span> <span class="given-names" tagx="given-names" title="given-names">AE</span> </span> </span> <span class="year" tagx="year" title="year">1995</span> <span class="mixed-article-title" title="mixed-article-title">Bayes factors</span>. <span class="source" tagx="source" title="source">J. Am. Stat. Assoc.</span> <span class="volume" tagx="volume" title="volume">90</span>, <span class="fpage" tagx="fpage" title="fpage">773</span>– <span class="lpage" tagx="lpage" title="lpage">795</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1080/01621459.1995.10476572">10.1080/01621459.1995.10476572</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C29" /> <span class="label" tagx="label" title="label">29</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Bishop</span> <span class="given-names" tagx="given-names" title="given-names">CM</span> </span> </span> <span class="year" tagx="year" title="year">2006</span> <span class="source" tagx="source" title="source">Pattern recognition and machine learning</span>. <span class="publisher-loc" tagx="publisher-loc" title="publisher-loc">New York, NY</span>: <span class="publisher-name" tagx="publisher-name" title="publisher-name">Springer</span>. </span> </li> <li tag="ref"> <a name="RSIF20180344C30" /> <span class="label" tagx="label" title="label">30</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kok</span> <span class="given-names" tagx="given-names" title="given-names">P</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Rahnev</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Jehee</span> <span class="given-names" tagx="given-names" title="given-names">JFM</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Lau</span> <span class="given-names" tagx="given-names" title="given-names">HC</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">de Lange</span> <span class="given-names" tagx="given-names" title="given-names">FP</span> </span> </span> <span class="year" tagx="year" title="year">2012</span> <span class="mixed-article-title" title="mixed-article-title">Attention reverses the effect of prediction in silencing sensory signals</span>. <span class="source" tagx="source" title="source">Cereb. Cortex</span> <span class="volume" tagx="volume" title="volume">22</span>, <span class="fpage" tagx="fpage" title="fpage">2197</span>– <span class="lpage" tagx="lpage" title="lpage">2206</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1093/cercor/bhr310">10.1093/cercor/bhr310</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/22047964">22047964</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C31" /> <span class="label" tagx="label" title="label">31</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kok</span> <span class="given-names" tagx="given-names" title="given-names">P</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Jehee</span> <span class="given-names" tagx="given-names" title="given-names">JFM</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">de Lange</span> <span class="given-names" tagx="given-names" title="given-names">FP</span> </span> </span> <span class="year" tagx="year" title="year">2012</span> <span class="mixed-article-title" title="mixed-article-title">Less is more: expectation sharpens representations in the primary visual cortex</span>. <span class="source" tagx="source" title="source">Neuron</span> <span class="volume" tagx="volume" title="volume">75</span>, <span class="fpage" tagx="fpage" title="fpage">265</span>– <span class="lpage" tagx="lpage" title="lpage">270</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuron.2012.04.034">10.1016/j.neuron.2012.04.034</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/22841311">22841311</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C32" /> <span class="label" tagx="label" title="label">32</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Auksztulewicz</span> <span class="given-names" tagx="given-names" title="given-names">R</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">Attentional enhancement of auditory mismatch responses: a DCM/MEG study</span>. <span class="source" tagx="source" title="source">Cereb. Cortex</span> <span class="volume" tagx="volume" title="volume">25</span>, <span class="fpage" tagx="fpage" title="fpage">4273</span>– <span class="lpage" tagx="lpage" title="lpage">4283</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1093/cercor/bhu323">10.1093/cercor/bhu323</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/25596591">25596591</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C33" /> <span class="label" tagx="label" title="label">33</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Lawrence</span> <span class="given-names" tagx="given-names" title="given-names">SJD</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Formisano</span> <span class="given-names" tagx="given-names" title="given-names">E</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Muckli</span> <span class="given-names" tagx="given-names" title="given-names">L</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">de Lange</span> <span class="given-names" tagx="given-names" title="given-names">FP</span> </span> </span> <span class="comment">In press.</span> <span class="mixed-article-title" title="mixed-article-title">Laminar fMRI: applications for cognitive neuroscience</span>. <span class="source" tagx="source" title="source">Neuroimage</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuroimage.2017.07.004">10.1016/j.neuroimage.2017.07.004</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C34" /> <span class="label" tagx="label" title="label">34</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Colon</span> <span class="given-names" tagx="given-names" title="given-names">E</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Legrain</span> <span class="given-names" tagx="given-names" title="given-names">V</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Mouraux</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span> </span> <span class="year" tagx="year" title="year">2014</span> <span class="mixed-article-title" title="mixed-article-title">EEG frequency-tagging to dissociate the cortical responses to nociceptive and non-nociceptive stimuli </span>. <span class="source" tagx="source" title="source">J. Cogn. Neurosci.</span> <span class="volume" tagx="volume" title="volume">26</span>, <span class="fpage" tagx="fpage" title="fpage">2262</span>– <span class="lpage" tagx="lpage" title="lpage">2274</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1162/jocn_a_00648">10.1162/jocn_a_00648</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/24738772">24738772</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C35" /> <span class="label" tagx="label" title="label">35</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Bastos</span> <span class="given-names" tagx="given-names" title="given-names">AM</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Litvak</span> <span class="given-names" tagx="given-names" title="given-names">V</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Moran</span> <span class="given-names" tagx="given-names" title="given-names">R</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Bosman</span> <span class="given-names" tagx="given-names" title="given-names">CA</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Fries</span> <span class="given-names" tagx="given-names" title="given-names">P</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">A DCM study of spectral asymmetries in feedforward and feedback connections between visual areas V1 and V4 in the monkey </span>. <span class="source" tagx="source" title="source">Neuroimage</span> <span class="volume" tagx="volume" title="volume">108</span>, <span class="fpage" tagx="fpage" title="fpage">460</span>– <span class="lpage" tagx="lpage" title="lpage">475</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuroimage.2014.12.081">10.1016/j.neuroimage.2014.12.081</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/25585017">25585017</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C36" /> <span class="label" tagx="label" title="label">36</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Boly</span> <span class="given-names" tagx="given-names" title="given-names">M</span> </span> <span class="etal" title="etal"> <i>et al.</i> </span> </span> <span class="year" tagx="year" title="year">2011</span> <span class="mixed-article-title" title="mixed-article-title">Preserved feedforward but impaired top-down processes in the vegetative state</span>. <span class="source" tagx="source" title="source">Science</span> <span class="volume" tagx="volume" title="volume">332</span>, <span class="fpage" tagx="fpage" title="fpage">858</span>– <span class="lpage" tagx="lpage" title="lpage">862</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1126/science.1202043">10.1126/science.1202043</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/21566197">21566197</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C37" /> <span class="label" tagx="label" title="label">37</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Brown</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span> </span> <span class="year" tagx="year" title="year">2012</span> <span class="mixed-article-title" title="mixed-article-title">Dynamic causal modelling of precision and synaptic gain in visual perception—an EEG study </span>. <span class="source" tagx="source" title="source">Neuroimage</span> <span class="volume" tagx="volume" title="volume">63</span>, <span class="fpage" tagx="fpage" title="fpage">223</span>– <span class="lpage" tagx="lpage" title="lpage">231</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuroimage.2012.06.044">10.1016/j.neuroimage.2012.06.044</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/22750569">22750569</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C38" /> <span class="label" tagx="label" title="label">38</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Brown</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span> </span> <span class="year" tagx="year" title="year">2012</span> <span class="mixed-article-title" title="mixed-article-title">Free-energy and illusions: the cornsweet effect</span>. <span class="source" tagx="source" title="source">Front. Psychol.</span> <span class="volume" tagx="volume" title="volume">3</span>, <span class="fpage" tagx="fpage" title="fpage">43</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.3389/fpsyg.2012.00043">10.3389/fpsyg.2012.00043</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/22393327">22393327</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C39" /> <span class="label" tagx="label" title="label">39</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Fogelson</span> <span class="given-names" tagx="given-names" title="given-names">N</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Litvak</span> <span class="given-names" tagx="given-names" title="given-names">V</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Peled</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Fernandez-del-Olmo</span> <span class="given-names" tagx="given-names" title="given-names">M</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span> </span> <span class="year" tagx="year" title="year">2014</span> <span class="mixed-article-title" title="mixed-article-title">The functional anatomy of schizophrenia: a dynamic causal modeling study of predictive coding </span>. <span class="source" tagx="source" title="source">Schizophrenia Res.</span> <span class="volume" tagx="volume" title="volume">158</span>, <span class="fpage" tagx="fpage" title="fpage">204</span>– <span class="lpage" tagx="lpage" title="lpage">212</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.schres.2014.06.011">10.1016/j.schres.2014.06.011</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C40" /> <span class="label" tagx="label" title="label">40</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Moran</span> <span class="given-names" tagx="given-names" title="given-names">RJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Jones</span> <span class="given-names" tagx="given-names" title="given-names">MW</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Blockeel</span> <span class="given-names" tagx="given-names" title="given-names">AJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Adams</span> <span class="given-names" tagx="given-names" title="given-names">RA</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Stephan</span> <span class="given-names" tagx="given-names" title="given-names">KE</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">Losing control under ketamine: suppressed cortico-hippocampal drive following acute ketamine in rats </span>. <span class="source" tagx="source" title="source">Neuropsychopharmacology</span> <span class="volume" tagx="volume" title="volume">40</span>, <span class="fpage" tagx="fpage" title="fpage">268</span>– <span class="lpage" tagx="lpage" title="lpage">277</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1038/npp.2014.184">10.1038/npp.2014.184</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/25053181">25053181</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C41" /> <span class="label" tagx="label" title="label">41</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Pinotsis</span> <span class="given-names" tagx="given-names" title="given-names">DA</span> </span> <span class="etal" title="etal"> <i>et al.</i> </span> </span> <span class="year" tagx="year" title="year">2014</span> <span class="mixed-article-title" title="mixed-article-title">Contrast gain control and horizontal interactions in V1: a DCM study</span>. <span class="source" tagx="source" title="source">Neuroimage</span> <span class="volume" tagx="volume" title="volume">92</span>, <span class="fpage" tagx="fpage" title="fpage">143</span>– <span class="lpage" tagx="lpage" title="lpage">155</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuroimage.2014.01.047">10.1016/j.neuroimage.2014.01.047</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/24495812">24495812</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C42" /> <span class="label" tagx="label" title="label">42</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Li</span> <span class="given-names" tagx="given-names" title="given-names">B</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Daunizeau</span> <span class="given-names" tagx="given-names" title="given-names">J</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Stephan</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span> </span> <span class="year" tagx="year" title="year">2011</span> <span class="mixed-article-title" title="mixed-article-title">Network discovery with DCM</span>. <span class="source" tagx="source" title="source">Neuroimage</span> <span class="volume" tagx="volume" title="volume">56</span>, <span class="fpage" tagx="fpage" title="fpage">1202</span>– <span class="lpage" tagx="lpage" title="lpage">1221</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuroimage.2010.12.039">10.1016/j.neuroimage.2010.12.039</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/21182971">21182971</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C43" /> <span class="label" tagx="label" title="label">43</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Bastos</span> <span class="given-names" tagx="given-names" title="given-names">AM</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Usrey</span> <span class="given-names" tagx="given-names" title="given-names">WM</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Adams</span> <span class="given-names" tagx="given-names" title="given-names">RA</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Mangun</span> <span class="given-names" tagx="given-names" title="given-names">GR</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Fries</span> <span class="given-names" tagx="given-names" title="given-names">P</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span> </span> <span class="year" tagx="year" title="year">2012</span> <span class="mixed-article-title" title="mixed-article-title">Canonical microcircuits for predictive coding</span>. <span class="source" tagx="source" title="source">Neuron</span> <span class="volume" tagx="volume" title="volume">76</span>, <span class="fpage" tagx="fpage" title="fpage">695</span>– <span class="lpage" tagx="lpage" title="lpage">711</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuron.2012.10.038">10.1016/j.neuron.2012.10.038</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/23177956">23177956</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C44" /> <span class="label" tagx="label" title="label">44</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Schwiedrzik</span> <span class="given-names" tagx="given-names" title="given-names">CM</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Freiwald</span> <span class="given-names" tagx="given-names" title="given-names">WA</span> </span> </span> <span class="year" tagx="year" title="year">2017</span> <span class="mixed-article-title" title="mixed-article-title">High-level prediction signals in a low-level area of the macaque face-processing hierarchy</span>. <span class="source" tagx="source" title="source">Neuron</span> <span class="volume" tagx="volume" title="volume">96</span>, <span class="fpage" tagx="fpage" title="fpage">89</span>– <span class="lpage" tagx="lpage" title="lpage">97</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuron.2017.09.007">10.1016/j.neuron.2017.09.007</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/28957679">28957679</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C45" /> <span class="label" tagx="label" title="label">45</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Tibshirani</span> <span class="given-names" tagx="given-names" title="given-names">R</span> </span> </span> <span class="year" tagx="year" title="year">1996</span> <span class="mixed-article-title" title="mixed-article-title">Regression shrinkage and selection via the lasso</span>. <span class="source" tagx="source" title="source">J. R. Stat. Soc. Ser. B</span> <span class="volume" tagx="volume" title="volume">58</span>, <span class="fpage" tagx="fpage" title="fpage">267</span>– <span class="lpage" tagx="lpage" title="lpage">288</span>. </span> </li> <li tag="ref"> <a name="RSIF20180344C46" /> <span class="label" tagx="label" title="label">46</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Bell</span> <span class="given-names" tagx="given-names" title="given-names">AJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Sejnowski</span> <span class="given-names" tagx="given-names" title="given-names">TJ</span> </span> </span> <span class="year" tagx="year" title="year">1995</span> <span class="mixed-article-title" title="mixed-article-title">An information maximisation approach to blind separation and blind de-convolution</span>. <span class="source" tagx="source" title="source">Neural Comput.</span> <span class="volume" tagx="volume" title="volume">7</span>, <span class="fpage" tagx="fpage" title="fpage">1129</span>– <span class="lpage" tagx="lpage" title="lpage">1159</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1162/neco.1995.7.6.1129">10.1162/neco.1995.7.6.1129</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/7584893">7584893</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C47" /> <span class="label" tagx="label" title="label">47</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Sherman</span> <span class="given-names" tagx="given-names" title="given-names">SM</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Guillery</span> <span class="given-names" tagx="given-names" title="given-names">RW</span> </span> </span> <span class="year" tagx="year" title="year">1998</span> <span class="mixed-article-title" title="mixed-article-title">On the actions that one nerve cell can have on another: distinguishing ‘drivers’ from ‘modulators’ </span>. <span class="source" tagx="source" title="source">Proc. Natl Acad. Sci. USA</span> <span class="volume" tagx="volume" title="volume">95</span>, <span class="fpage" tagx="fpage" title="fpage">7121</span>– <span class="lpage" tagx="lpage" title="lpage">7126</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1073/pnas.95.12.7121">10.1073/pnas.95.12.7121</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/9618549">9618549</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C48" /> <span class="label" tagx="label" title="label">48</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Shipp</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span> </span> <span class="year" tagx="year" title="year">2016</span> <span class="mixed-article-title" title="mixed-article-title">Neural elements for predictive coding</span>. <span class="source" tagx="source" title="source">Front. Psychol.</span> <span class="volume" tagx="volume" title="volume">7</span>, <span class="fpage" tagx="fpage" title="fpage">1792</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.3389/fpsyg.2016.01792">10.3389/fpsyg.2016.01792</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/27917138">27917138</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C49" /> <span class="label" tagx="label" title="label">49</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Shipp</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Adams</span> <span class="given-names" tagx="given-names" title="given-names">RA</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Friston</span> <span class="given-names" tagx="given-names" title="given-names">KJ</span> </span> </span> <span class="year" tagx="year" title="year">2013</span> <span class="mixed-article-title" title="mixed-article-title">Reflections on agranular architecture: predictive coding in the motor cortex</span>. <span class="source" tagx="source" title="source">Trends Neurosci.</span> <span class="volume" tagx="volume" title="volume">36</span>, <span class="fpage" tagx="fpage" title="fpage">706</span>– <span class="lpage" tagx="lpage" title="lpage">716</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.tins.2013.09.004">10.1016/j.tins.2013.09.004</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/24157198">24157198</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C50" /> <span class="label" tagx="label" title="label">50</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Keller</span> <span class="given-names" tagx="given-names" title="given-names">GB</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Mrsic-Flogel</span> <span class="given-names" tagx="given-names" title="given-names">TD</span> </span> </span> <span class="year" tagx="year" title="year">2018</span> <span class="mixed-article-title" title="mixed-article-title">Predictive processing: a canonical cortical computation</span>. <span class="source" tagx="source" title="source">Neuron</span> <span class="volume" tagx="volume" title="volume">100</span>, <span class="fpage" tagx="fpage" title="fpage">424</span>– <span class="lpage" tagx="lpage" title="lpage">435</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuron.2018.10.003">10.1016/j.neuron.2018.10.003</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/30359606">30359606</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C51" /> <span class="label" tagx="label" title="label">51</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Park</span> <span class="given-names" tagx="given-names" title="given-names">J</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Shimojo</span> <span class="given-names" tagx="given-names" title="given-names">E</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Shimojo</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span> </span> <span class="year" tagx="year" title="year">2010</span> <span class="mixed-article-title" title="mixed-article-title">Roles of familiarity and novelty in visual preference judgments are segregated across object categories </span>. <span class="source" tagx="source" title="source">Proc. Natl Acad. Sci. USA</span> <span class="volume" tagx="volume" title="volume">107</span>, <span class="fpage" tagx="fpage" title="fpage">14 552</span>– <span class="lpage" tagx="lpage" title="lpage">14 555</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1073/pnas.1004374107">10.1073/pnas.1004374107</a> </span>) </span> </li> <li tag="ref"> <a name="RSIF20180344C52" /> <span class="label" tagx="label" title="label">52</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Letzkus</span> <span class="given-names" tagx="given-names" title="given-names">JJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Wolff</span> <span class="given-names" tagx="given-names" title="given-names">SB</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Luthi</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">Disinhibition, a circuit mechanism for associative learning and memory</span>. <span class="source" tagx="source" title="source">Neuron</span> <span class="volume" tagx="volume" title="volume">88</span>, <span class="fpage" tagx="fpage" title="fpage">264</span>– <span class="lpage" tagx="lpage" title="lpage">276</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuron.2015.09.024">10.1016/j.neuron.2015.09.024</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/26494276">26494276</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C53" /> <span class="label" tagx="label" title="label">53</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Pi</span> <span class="given-names" tagx="given-names" title="given-names">HJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Hangya</span> <span class="given-names" tagx="given-names" title="given-names">B</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kvitsiani</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Sanders</span> <span class="given-names" tagx="given-names" title="given-names">JI</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Huang</span> <span class="given-names" tagx="given-names" title="given-names">ZJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kepecs</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span> </span> <span class="year" tagx="year" title="year">2013</span> <span class="mixed-article-title" title="mixed-article-title">Cortical interneurons that specialize in disinhibitory control</span>. <span class="source" tagx="source" title="source">Nature</span> <span class="volume" tagx="volume" title="volume">503</span>, <span class="fpage" tagx="fpage" title="fpage">521</span>– <span class="lpage" tagx="lpage" title="lpage">524</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1038/nature12676">10.1038/nature12676</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/24097352">24097352</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C54" /> <span class="label" tagx="label" title="label">54</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Zhang</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Xu</span> <span class="given-names" tagx="given-names" title="given-names">M</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kamigaki</span> <span class="given-names" tagx="given-names" title="given-names">T</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Hoang Do</span> <span class="given-names" tagx="given-names" title="given-names">JP</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Chang</span> <span class="given-names" tagx="given-names" title="given-names">WC</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Jenvay</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Miyamichi</span> <span class="given-names" tagx="given-names" title="given-names">K</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Luo</span> <span class="given-names" tagx="given-names" title="given-names">L</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Dan</span> <span class="given-names" tagx="given-names" title="given-names">Y</span> </span> </span> <span class="year" tagx="year" title="year">2014</span> <span class="mixed-article-title" title="mixed-article-title">Selective attention. Long-range and local circuits for top-down modulation of visual cortex processing </span>. <span class="source" tagx="source" title="source">Science</span> <span class="volume" tagx="volume" title="volume">345</span>, <span class="fpage" tagx="fpage" title="fpage">660</span>– <span class="lpage" tagx="lpage" title="lpage">665</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1126/science.1254126">10.1126/science.1254126</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/25104383">25104383</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C55" /> <span class="label" tagx="label" title="label">55</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Koolschijn</span> <span class="given-names" tagx="given-names" title="given-names">RS</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Emir</span> <span class="given-names" tagx="given-names" title="given-names">UE</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Pantelides</span> <span class="given-names" tagx="given-names" title="given-names">AC</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Nili</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Behrens</span> <span class="given-names" tagx="given-names" title="given-names">TEJ</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Barron</span> <span class="given-names" tagx="given-names" title="given-names">HC</span> </span> </span> <span class="year" tagx="year" title="year">2019</span> <span class="mixed-article-title" title="mixed-article-title">The hippocampus and neocortical inhibitory engrams protect against memory interference</span>. <span class="source" tagx="source" title="source">Neuron</span> <span class="volume" tagx="volume" title="volume">101</span>, <span class="fpage" tagx="fpage" title="fpage">528</span>– <span class="lpage" tagx="lpage" title="lpage">541</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neuron.2018.11.042">10.1016/j.neuron.2018.11.042</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/30581011">30581011</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C56" /> <span class="label" tagx="label" title="label">56</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Petro</span> <span class="given-names" tagx="given-names" title="given-names">LS</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Muckli</span> <span class="given-names" tagx="given-names" title="given-names">L</span> </span> </span> <span class="year" tagx="year" title="year">2017</span> <span class="mixed-article-title" title="mixed-article-title">The laminar integration of sensory inputs with feedback signals in human cortex</span>. <span class="source" tagx="source" title="source">Brain Cogn.</span> <span class="volume" tagx="volume" title="volume">112</span>, <span class="fpage" tagx="fpage" title="fpage">54</span>– <span class="lpage" tagx="lpage" title="lpage">57</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.bandc.2016.06.007">10.1016/j.bandc.2016.06.007</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/27814926">27814926</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C57" /> <span class="label" tagx="label" title="label">57</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kersten</span> <span class="given-names" tagx="given-names" title="given-names">D</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Mamassian</span> <span class="given-names" tagx="given-names" title="given-names">P</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Yuille</span> <span class="given-names" tagx="given-names" title="given-names">A</span> </span> </span> <span class="year" tagx="year" title="year">2004</span> <span class="mixed-article-title" title="mixed-article-title">Object perception as Bayesian inference</span>. <span class="source" tagx="source" title="source">Annu. Rev. Psychol.</span> <span class="volume" tagx="volume" title="volume">55</span>, <span class="fpage" tagx="fpage" title="fpage">271</span>– <span class="lpage" tagx="lpage" title="lpage">304</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1146/annurev.psych.55.090902.142005">10.1146/annurev.psych.55.090902.142005</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/14744217">14744217</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C58" /> <span class="label" tagx="label" title="label">58</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kogo</span> <span class="given-names" tagx="given-names" title="given-names">N</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Trengove</span> <span class="given-names" tagx="given-names" title="given-names">C</span> </span> </span> <span class="year" tagx="year" title="year">2015</span> <span class="mixed-article-title" title="mixed-article-title">Is predictive coding theory articulated enough to be testable?</span> <span class="source" tagx="source" title="source">Front. Comput. Neurosci.</span> <span class="volume" tagx="volume" title="volume">9</span>, <span class="fpage" tagx="fpage" title="fpage">111</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.3389/fncom.2015.00111">10.3389/fncom.2015.00111</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/26441621">26441621</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C59" /> <span class="label" tagx="label" title="label">59</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Grossberg</span> <span class="given-names" tagx="given-names" title="given-names">S</span> </span> </span> <span class="year" tagx="year" title="year">2013</span> <span class="mixed-article-title" title="mixed-article-title">Adaptive resonance theory: how a brain learns to consciously attend, learn, and recognize a changing world </span>. <span class="source" tagx="source" title="source">Neural Netw.</span> <span class="volume" tagx="volume" title="volume">37</span>, <span class="fpage" tagx="fpage" title="fpage">1</span>– <span class="lpage" tagx="lpage" title="lpage">47</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1016/j.neunet.2012.09.017">10.1016/j.neunet.2012.09.017</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/23149242">23149242</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C60" /> <span class="label" tagx="label" title="label">60</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Kay</span> <span class="given-names" tagx="given-names" title="given-names">JW</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Phillips</span> <span class="given-names" tagx="given-names" title="given-names">WA</span> </span> </span> <span class="year" tagx="year" title="year">2011</span> <span class="mixed-article-title" title="mixed-article-title">Coherent infomax as a computational goal for neural systems</span>. <span class="source" tagx="source" title="source">Bull. Math. Biol.</span> <span class="volume" tagx="volume" title="volume">73</span>, <span class="fpage" tagx="fpage" title="fpage">344</span> ( <span class="pub-id"> <a href="https://dx.doi.org/10.1007/s11538-010-9564-x">10.1007/s11538-010-9564-x</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/20821064">20821064</a> </span> </span> </li> <li tag="ref"> <a name="RSIF20180344C61" /> <span class="label" tagx="label" title="label">61</span> <span class="mixed-citation" tagx="mixed-citation" title="mixed-citation"> <span class="person-group'"> <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Bowman</span> <span class="given-names" tagx="given-names" title="given-names">H</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Filetti</span> <span class="given-names" tagx="given-names" title="given-names">M</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Wyble</span> <span class="given-names" tagx="given-names" title="given-names">B</span> </span>, <span class="name" tagx="name" title="name"> <span class="surname" tagx="surname" title="surname">Olivers</span> <span class="given-names" tagx="given-names" title="given-names">C</span> </span> </span> <span class="year" tagx="year" title="year">2013</span> <span class="mixed-article-title" title="mixed-article-title">Attention is more than prediction precision</span>. <span class="source" tagx="source" title="source">Behav. Brain Sci.</span> <span class="volume" tagx="volume" title="volume">36</span>, <span class="fpage" tagx="fpage" title="fpage">206</span>– <span class="lpage" tagx="lpage" title="lpage">208</span>. ( <span class="pub-id"> <a href="https://dx.doi.org/10.1017/S0140525X12002324">10.1017/S0140525X12002324</a> </span>) <span class="pub-id"> <a href="http://www.ncbi.nlm.nih.gov/pubmed/23663435">23663435</a> </span> </span> </li> </ul> </div> </div>  </body></html>