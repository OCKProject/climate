<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6350984</article-id><article-id pub-id-type="publisher-id">PONE-D-18-17613</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0211215</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Endocrine System</subject><subj-group><subject>Thyroid</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Endocrine System</subject><subj-group><subject>Thyroid</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Diagnostic Medicine</subject><subj-group><subject>Diagnostic Radiology</subject><subj-group><subject>Ultrasound Imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Diagnostic Radiology</subject><subj-group><subject>Ultrasound Imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Radiology and Imaging</subject><subj-group><subject>Diagnostic Radiology</subject><subj-group><subject>Ultrasound Imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Image Analysis</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Data Acquisition</subject></subj-group></subj-group></article-categories><title-group><article-title>Parametrical modelling for texture characterization&#x02014;A novel approach applied to ultrasound thyroid segmentation</article-title><alt-title alt-title-type="running-head">Parametrical modelling for ultrasound texture characterization</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0118-0483</contrib-id><name><surname>Illanes</surname><given-names>Alfredo</given-names></name><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9741-9788</contrib-id><name><surname>Esmaeili</surname><given-names>Nazila</given-names></name><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Poudel</surname><given-names>Prabal</given-names></name><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Balakrishnan</surname><given-names>Sathish</given-names></name><role content-type="http://credit.casrai.org/">Investigation</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8624-0800</contrib-id><name><surname>Friebe</surname><given-names>Michael</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Funding acquisition</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib></contrib-group><aff id="aff001">
<addr-line>INKA, Institute of Medical Technology, Otto-von-Guericke-Universit&#x000e4;t Magdeburg, Magdeburg, Germany</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Speier</surname><given-names>William</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>University of California Los Angeles, UNITED STATES</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>alfredo.illanes@ovgu.de</email></corresp></author-notes><pub-date pub-type="collection"><year>2019</year></pub-date><pub-date pub-type="epub"><day>29</day><month>1</month><year>2019</year></pub-date><volume>14</volume><issue>1</issue><elocation-id>e0211215</elocation-id><history><date date-type="received"><day>12</day><month>6</month><year>2018</year></date><date date-type="accepted"><day>9</day><month>1</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2019 Illanes et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Illanes et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0211215.pdf"/><abstract><p>Texture analysis is an important topic in Ultrasound (US) image analysis for structure segmentation and tissue classification. In this work a novel approach for US image texture feature extraction is presented. It is mainly based on parametrical modelling of a signal version of the US image in order to process it as data resulting from a dynamical process. Because of the predictive characteristics of such a model representation, good estimations of texture features can be obtained with less data than generally used methods require, allowing higher robustness to low Signal-to-Noise ratio and a more localized US image analysis. The usability of the proposed approach was demonstrated by extracting texture features for segmenting the thyroid in US images. The obtained results showed that features corresponding to energy ratios between different modelled texture frequency bands allowed to clearly distinguish between thyroid and non-thyroid texture. A simple k-means clustering algorithm has been used for separating US image patches as belonging to thyroid or not. Segmentation of thyroid was performed in two different datasets obtaining Dice coefficients over 85%.</p></abstract><funding-group><award-group id="award001"><funding-source><institution>Bundesministerium f&#x000fc;r Bildung und Forschung (Federal Ministry of Education and Research)</institution></funding-source><award-id>03IPT7100X</award-id></award-group><funding-statement>This work was supported by Bundesministerium f&#x000fc;r Bildung und Forschung (Federal Ministry of Education and Research) - 03IPT7100X.</funding-statement></funding-group><counts><fig-count count="10"/><table-count count="3"/><page-count count="17"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>Data used in this paper are open access and can be download it in <ext-link ext-link-type="uri" xlink:href="http://opencas.webarchiv.kit.edu/?q=node/29">http://opencas.webarchiv.kit.edu/?q=node/29</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>Data used in this paper are open access and can be download it in <ext-link ext-link-type="uri" xlink:href="http://opencas.webarchiv.kit.edu/?q=node/29">http://opencas.webarchiv.kit.edu/?q=node/29</ext-link>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Texture analysis is the term used for methods developed to quantify image texture through description of image properties by textural features. In general, these features aim to measure smoothness, coarseness, and regularity of pixels, which form an image [<xref rid="pone.0211215.ref001" ref-type="bibr">1</xref>, <xref rid="pone.0211215.ref002" ref-type="bibr">2</xref>]. Feature extraction methods are usually followed by classification or clustering and can be applied for image segmentation, image characterization, and for estimation of image similarity metrics [<xref rid="pone.0211215.ref003" ref-type="bibr">3</xref>].</p><p>Generally used approaches for computing texture features are based on statistical and frequency domain techniques. Statistical approaches compute histograms, entropy, homogeneity, mean and variance values for estimating features from the texture. Frequency domain techniques or spectral techniques collect a distribution of filter responses to extract different aspects from the texture [<xref rid="pone.0211215.ref001" ref-type="bibr">1</xref>]. Gabor filters and Wavelet decomposition are examples of this type of approach.</p><p>The main drawback of these approaches is that they are mainly data-driven, meaning that the computation of texture characteristics is performed directly from the pixel values. With that the estimation of texture characteristics is limited by the amount of data and the Signal to Noise Ratio (SNR) of the image.</p><p>In medical imaging, texture describes internal structures of human tissues or organs or pathological changes. Different modalities such as Magnetic Resonance, Computer Tomography and Ultrasound (US) require texture analysis and characterization for applications such as segmentation, registration ans lesion classification [<xref rid="pone.0211215.ref003" ref-type="bibr">3</xref>]. From all these modalities, US is known to be the most challenging because of the presence of characteristic artifacts such as speckles and shadows as well as due to the low SNR and resolution.</p><p>In this work, a novel approach for image texture feature extraction in US images is presented mainly based on parametrical modelling. The main idea behind this approach is to analyze the texture as data resulting from a dynamical process and to estimate the different dynamics involved in the texture in order to use mathematical operations between these dynamics as possible texture features. For that a signal version of the image is first computed, where the independent variable is the space, then the signal is decomposed in different frequency bands using Wavelet Transformation and finally an Autoregressive (AR) parametrical model of the decomposed signals provides spectral characteristics used for features computation.</p><p>The main advantage of this approach is that good estimations of texture characteristics can be obtained with less data due to the predictive characteristics of the model representation. Moreover, using an appropriate model order noise can be optimally handled and a better estimation of the dynamical properties of the texture can be obtained, even under really complex SNR characteristics as usually seen in US data.</p><p>The usability of the proposed approach was demonstrated with US data for segmenting thyroid texture. The obtained results showed that features corresponding to energy ratios between different modelled texture frequency bands allow to clearly distinguish between thyroid and non-thyroid texture regions.</p><p>The thyroid is one of the largest endocrine glands in the human body and it is involved in several significant body mechanisms. Diseases of the thyroid gland are among the most frequent endocrine disorders and changes of the thyroid volume are often the symptom of these common pathological conditions. For this reason, it is essential to track and monitor changes on thyroid volume over time and segmentation of the thyroid is one of the main steps for this purpose.</p><p>Many approaches have been presented in the literature for extracting features in US thyroid image analysis, mainly for thyroid segmentation and nodule characterization and classification. Recent surveys demonstrate that these two topics for thyroid analysis are highly active research fields [<xref rid="pone.0211215.ref004" ref-type="bibr">4</xref>&#x02013;<xref rid="pone.0211215.ref007" ref-type="bibr">7</xref>]. Following this trend, many new methods have been proposed in the last years. Concerning thyroid segmentation in [<xref rid="pone.0211215.ref008" ref-type="bibr">8</xref>] three semi-automatic algorithms based on general segmentation approaches such as active contours, graph cut and pixel based classifier were evaluated and compared with two machine learning approaches based on Convolutional Neural Networks and Random Forest (RF). In [<xref rid="pone.0211215.ref009" ref-type="bibr">9</xref>] the segmentation of the thyroid is made by taking into account apriori information based on the physics of the US imaging process and by applying Iterative Random Walks and RF based techniques. Furthermore, several type of features have been proposed for tissue characterization in order to classify nodules or lesions in thyroid US images. Among the most used features are statistical features [<xref rid="pone.0211215.ref010" ref-type="bibr">10</xref>&#x02013;<xref rid="pone.0211215.ref012" ref-type="bibr">12</xref>], Spectral-based features [<xref rid="pone.0211215.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0211215.ref014" ref-type="bibr">14</xref>], higher order statistics based features [<xref rid="pone.0211215.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0211215.ref016" ref-type="bibr">16</xref>], Wavelet-based features [<xref rid="pone.0211215.ref002" ref-type="bibr">2</xref>, <xref rid="pone.0211215.ref017" ref-type="bibr">17</xref>, <xref rid="pone.0211215.ref018" ref-type="bibr">18</xref>] and Fractal-based features [<xref rid="pone.0211215.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0211215.ref019" ref-type="bibr">19</xref>]. Additionally other works have proposed machine learning algorithms [<xref rid="pone.0211215.ref020" ref-type="bibr">20</xref>, <xref rid="pone.0211215.ref021" ref-type="bibr">21</xref>] and neutrosophic clustering for thyroid tissue characterization.</p><p>As in the general literature for US feature extraction, the main drawback in thyroid US feature computation is that most of the proposed approaches are data driven operating directly from the pixel values of the image. We propose a completely different approach where the preprocessing or image aspects decomposition is made over a signal and not an image and where the features are computed not from the pixels values but from a parametrical model of each estimated image aspect. We believe that the predictive characteristics of such parametrical approach will be able to better deal with the low SNR of thyroid US images and will also allow to obtain better estimation of features with lower quantity of data than direct pixel feature computation.</p><p>The main purpose of this paper is not to propose a new thyroid segmentation algorithm but to show how features computed with a completely novel approach can be valuable for US texture characterization. However, to assess the performance of the proposed approach the algorithm was evaluated using two thyroid datasets obtaining Dice coefficients higher than 85% in both databases. Additionally, the results were compared with the ones obtained by other approaches proposed in the literature.</p></sec><sec sec-type="materials|methods" id="sec002"><title>Methods</title><p>As mentioned above, one of the major issues with US imaging is the quality of the data, which particularly affects segmentation applications or texture characterization that are strongly influenced by the relatively low quality of clinical US images, causing that tissue echogenic characteristics and boundaries are often drowned in noise. Decomposition and parametrization of each characteristic <italic>aspect</italic> of the data could reduce the noise and enhance the valuable information. These <italic>aspects</italic> could correspond to different type of noises or artifacts or to different levels of irregularity or granularity in the US image.</p><p>The core idea presented in this paper is to treat an US image as texture that can be represented as data resulting from a dynamical process, which depends on space as an independent variable and whose dynamical patterns can then characterize such a texture. These dynamics can be modelled using a parametrical approach and the estimated parameters can be taken as a mathematical representation of the texture that are used to compute valuable features that characterize the US texture at a given location.</p><p>
<xref ref-type="fig" rid="pone.0211215.g001">Fig 1</xref> illustrates the basic idea. A thyroid ultrasound image is shown and a sub-image or patch (red box) is selected in such a way that it contains thyroid (Texture 1 in the figure) and non-thyroid textures (Texture 2 in the figure). The boundary between the two textures (thyroid and non-thyroid) is not evident but in the mesh representation of the sub-image on the top right of <xref ref-type="fig" rid="pone.0211215.g001">Fig 1</xref> it is possible to visualize the different texture characteristics of the two tissue types. If we extract a line profile passing through both textures (red dashed line in the US image) then it is possible to verify that the texture signals (inside the dashed rectangle over the line profile plot) involve different frequency components or more general, different signal dynamics that are characteristics of each texture.</p><fig id="pone.0211215.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g001</object-id><label>Fig 1</label><caption><title>Illustration of the main principle behind the proposed US texture characterization approach.</title></caption><graphic xlink:href="pone.0211215.g001"/></fig><p>The idea is now to model these texture dynamics using a parametrical approach to perform features computation not by operating the matrix data itself, but by operating the parameters of the modelled texture that represent the information that the image contains in terms of dynamical distribution. By using an optimal model order such an approach can be highly robust to the typical speckle noise of US images as well as to low trend intensity inhomogeneity. Additionally, because of the predictive characteristics of such a model representation, good estimations of characteristics of a texture can be obtained with less data than with standard methods.</p><p>The block diagram of <xref ref-type="fig" rid="pone.0211215.g002">Fig 2</xref> displays the main steps for feature computation of a US image patch in order to characterize its texture. First, the image patch gray-level matrix is converted into four texture signals using two different image to signal conversion procedures. Then, each of the texture signals is decomposed in four signal bands using Continuous Wavelet Transformation (CWT). The 16 resulting narrow-band texture signals are then modelled using an Autoregressive (AR) parametrical model to finally compute features from ratios between different energy bands of the decomposed signals. In the following, each step of the algorithm will be detailed.</p><fig id="pone.0211215.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g002</object-id><label>Fig 2</label><caption><title>Main steps of the general concept of the signal processing algorithm for texture modelling and feature extraction in US images.</title></caption><graphic xlink:href="pone.0211215.g002"/></fig><sec id="sec003"><title>Image to signal conversion</title><p>In order to track dynamical texture characteristics of an US image resulting from a dynamical process, the matrix data is first converted into a signal. For that we use ZigZag (following the rows direction) and spiral conversion of the US matrix image and of their 90 degrees rotation matrix versions (see <xref ref-type="fig" rid="pone.0211215.g003">Fig 3</xref>. The output of this first step results in four texture signals, one per each conversion (ZigZag, spiral and their 90 degrees conversions).</p><fig id="pone.0211215.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g003</object-id><label>Fig 3</label><caption><title>Conversion of a matrix by traversing the matrix and its transposed in ZigZag and in spiral.</title></caption><graphic xlink:href="pone.0211215.g003"/></fig></sec><sec id="sec004"><title>Continuous wavelet texture frequency band decomposition</title><p>The second step decomposes each one of the four texture signals in several frequency bands, each containing one different aspect of the texture. We assume that an image texture is composed of several dynamics representing irregularity characteristics of the texture such as smoothness or roughness. Therefore the signals can be decomposed into several dynamics that can represent levels of irregularities presented in the image/texture. Each signal is separated in different frequency components or scales and we then reconstruct several narrow band signals that should contain information of different levels of texture irregularity.</p><p>Since the four signals resulting from the image to signal conversion step can contain components that are not necessarily oscillatory, they are decomposed using scale decomposition instead of frequency Fourier- based decomposition. For that the CWT was applied to decompose the signal in different scales and then reconstructing new signals using scales equivalent to three frequency bands representing low, middle and high frequency components (LF, MF and HF) using a Daubechies mother wavelet. Additionally a fourth frequency band called Total Band (TB) was computed using the full frequency band of the signals but erasing the Very Low Frequency components Wavelet scales, which correspond to low trend image intensity inhomogeneity.</p><p>In summary this step results in 16 texture narrowband signals, four per texture signal. They are denoted in the sequel as <inline-formula id="pone.0211215.e001"><alternatives><graphic xlink:href="pone.0211215.e001.jpg" id="pone.0211215.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>n</italic> represent the discrete index (independent variable), <italic>i</italic> = 1, 2, 3, 4 denotes the signal conversion type (1, 2 for ZigZag and its rotated version, 3, 4 for spiral and its rotated version) and <italic>B</italic> denotes the type narrowband signal LF, MF, HF or TB.</p><p>
<xref ref-type="fig" rid="pone.0211215.g004">Fig 4</xref> shows an example of CWT decomposition of three texture signals (ZigZag non rotated conversion versions) at different positions in the US image denoted <italic>I</italic><sub><italic>US</italic>1</sub>, <italic>I</italic><sub><italic>US</italic>2</sub> and <italic>I</italic><sub><italic>US</italic>3</sub> in the figure. Two patches, <italic>I</italic><sub><italic>US</italic>1</sub> and <italic>I</italic><sub><italic>US</italic>2</sub>, were taken from inside the thyroid and the patch <italic>I</italic><sub><italic>US</italic>3</sub> was taken outside the thyroid, but in a region with similar texture characteristics as thyroid. At the right side of <xref ref-type="fig" rid="pone.0211215.g004">Fig 4</xref> the CWT spectrum concatenated for the three patches is displayed. It is possible to visualize in the spectrum the scale frequency bands that were taken for constructing the narrow-band texture signals HF, MF and LF.</p><fig id="pone.0211215.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g004</object-id><label>Fig 4</label><caption><title>Example of a CWT decomposition of a thyroid US image when three image patches are taken from different locations of the US image.</title></caption><graphic xlink:href="pone.0211215.g004"/></fig><p>The TB, HF, MF and LF bands for the ZigZag signal version for each patch are shown also at the right of <xref ref-type="fig" rid="pone.0211215.g004">Fig 4</xref> by concatenating the resulting signals in order to observe the dynamical difference between textures at different image locations. It is possible to observe that for <italic>I</italic><sub><italic>US</italic>1</sub> and <italic>I</italic><sub><italic>US</italic>2</sub>, belonging both to patches located inside the thyroid, the dynamics of the decomposed signals are similar in MF, HF and TB, while the dynamics resulting from <italic>I</italic><sub><italic>US</italic>3</sub> are clearly different. Particularly in HF it is evident that the frequency components and the amplitude are different inside compared to outside the thyroid. In LF even if the difference is low we can observe tiny changes in amplitude when we compare inside and outside thyroid patches. Given this analysis, what we want is to quantify these dynamical differences between image textures inside and outside the thyroid, and as explained in the next section, this will be done using a parametrical model of the different extracted texture signals.</p></sec><sec id="sec005"><title>Ultrasound texture parametrical modelling</title><p>The size of a patch should be small enough in order to perform highly localized texture feature characterization. This requirement results in two characteristics of the data that a texture characterization method must deal with: the small quantity of dynamical changes (texture variability involving limited number of oscillations or damped oscillations) and the under-sampled characteristics of the data due not only to the size of the patch, but also to the resolution of the US image modality. Moreover, a texture characterization method should also be able to deal with the low SNR characteristics of US imaging. Under these conditions, classical methods for feature extraction, such as spectral or statistical based ones and in general data-driven approaches, no longer can obtain a good estimation of texture characteristics. This is why we propose in this work to use parametrical modelling of the resulting 16 texture signals from the CWT decomposition. These signals present narrow-band characteristics that are well suited to be modelled with an autoregressive (AR) approach. Our approach consist of a parametric representation of signal dynamics, which can deal with the drawbacks of the generally used current methods.</p><p>AR modelling is a well-known and well published technique for parametrical spectral estimation that has shown advantages over non-parametrical based methods (for detailed information about AR modelling we suggest [<xref rid="pone.0211215.ref022" ref-type="bibr">22</xref>]). The advantages of the AR representation is that it is possible to obtain good estimation of the spectrum and higher spectral resolution using less data than classical methods and that it provides a parametric way to analyze the data.</p><p>The AR model for each one of the sixteen <inline-formula id="pone.0211215.e002"><alternatives><graphic xlink:href="pone.0211215.e002.jpg" id="pone.0211215.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> texture signals consists of a linear combination of past samples of the respective signal and a white zero mean noise <italic>e</italic>[<italic>n</italic>] of variance <italic>&#x003c3;</italic><sup>2</sup>:
<disp-formula id="pone.0211215.e003"><alternatives><graphic xlink:href="pone.0211215.e003.jpg" id="pone.0211215.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:munderover><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>k</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
where <inline-formula id="pone.0211215.e004"><alternatives><graphic xlink:href="pone.0211215.e004.jpg" id="pone.0211215.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> are the estimated AR parameters for the narrowband signal <inline-formula id="pone.0211215.e005"><alternatives><graphic xlink:href="pone.0211215.e005.jpg" id="pone.0211215.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. In this work the model order <italic>p</italic><sub><italic>B</italic></sub> is dependent on the band <italic>B</italic> and was set on 100, 50, 30 and 80 respectively for <italic>B</italic> = <italic>LF</italic>, <italic>B</italic> = <italic>MF</italic>, <italic>B</italic> = <italic>HF</italic> and <italic>B</italic> = <italic>TB</italic>. The AR parameters were estimated using the <italic>Yule-Walker</italic> method [<xref rid="pone.0211215.ref022" ref-type="bibr">22</xref>].</p></sec><sec id="sec006"><title>Feature extraction and selection procedure</title><p>From <xref ref-type="disp-formula" rid="pone.0211215.e003">Eq (1)</xref> power spectral densities can be computed for each one of the 16 narrowband signals. Since the textural dynamics should be different from one type of tissue to another, the main estimated components of the spectrum should vary between different tissues. Additionally, the different degrees of texture irregularities in a given tissue should be manifested by different contributions on energy of the frequency bands characterizing the texture signal. Therefore features related to spectral energy of the 16 texture signals (resulting after CWT decomposition) are used in this work.</p><p>To compute spectral energy features the Power Spectral Densities <inline-formula id="pone.0211215.e006"><alternatives><graphic xlink:href="pone.0211215.e006.jpg" id="pone.0211215.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for each one of the 16 narrowband signals have to be first computed from the AR parameters. For that the Z-transform can be applied to <xref ref-type="disp-formula" rid="pone.0211215.e003">Eq (1)</xref> and then the AR spectrum can be computed from the resulting transfer function:
<disp-formula id="pone.0211215.e007"><alternatives><graphic xlink:href="pone.0211215.e007.jpg" id="pone.0211215.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:munderover></mml:mstyle><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula></p><p>
<xref ref-type="fig" rid="pone.0211215.g005">Fig 5</xref> shows an example of the information that the AR spectrum can provide for characterizing tissue. The AR spectra of patches <italic>I</italic><sub><italic>US</italic>1</sub>, <italic>I</italic><sub><italic>US</italic>2</sub> and <italic>I</italic><sub><italic>US</italic>3</sub> for LF, MF, HF and TB signals of <xref ref-type="fig" rid="pone.0211215.g004">Fig 4</xref> are displayed. It is possible to observe that for both patches located inside the thyroid (<italic>I</italic><sub><italic>US</italic>1</sub> and <italic>I</italic><sub><italic>US</italic>2</sub>) the AR spectra (in blue and red lines respectively) main components are similar for the four narrowband texture signals. For the patch located outside the thyroid (<italic>I</italic><sub><italic>US</italic>3</sub>) the AR spectral characteristics are completely different in terms of main frequency components and spectral energy.</p><fig id="pone.0211215.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g005</object-id><label>Fig 5</label><caption><title>AR spectra for the patches <italic>I</italic><sub><italic>US</italic>1</sub>, <italic>I</italic><sub><italic>US</italic>2</sub> and <italic>I</italic><sub><italic>US</italic>3</sub> (in blue, red and black lines respectively) for the four narrowband signals belonging to the ZigZag matrix to signal conversion.</title></caption><graphic xlink:href="pone.0211215.g005"/></fig><p>These parametrical characteristics can be exploited using the spectral energy of the estimated spectra. Therefore, the features computed in this novel approach are based on band energy ratios computed between the different frequency bands of the AR spectra. These type of AR features have already been used for Heart Rate Variability analysis for extraction of dynamical relationships between sympathetic and parasympathetic activities of the Autonomous Nervous System [<xref rid="pone.0211215.ref023" ref-type="bibr">23</xref>]. Analog to that, we assume that in one US texture the relationship between its different levels of irregularity can provide information for classifying tissue echogenicity.</p><p>Taking into account the number of spectra from the different texture signals belonging to the different conversions, the number of possible spectral energy ratios to be used as potential features is 256. Therefore a procedure of features selection has been performed using an analytic test. First, inconsistent energy ratios were eliminated from the analysis. Then different US images were selected from a US thyroid image dataset (Dataset 1, which will be introduced in the next section). For each image 100 patches (20 &#x000d7; 20 pixels) were selected manually, 50 patches belonging to thyroid and the other 50 belonging to non-thyroid regions. In order to evaluate the ability of a feature to distinguish between thyroid and non-thyroid texture, the patches belonging to regions outside the thyroid were divided in three classes according to the visual level of texture similarity that a non-thyroid region has with respect to thyroid texture: similar, semi-similar and dissimilar. The set of energy ratio features were computed for all the selected patches and the results were plotted using a color-map matrix as shown in <xref ref-type="fig" rid="pone.0211215.g006">Fig 6</xref>. Each column of this matrix correspond to an energy ratio feature and allows to visually analyze the ability of an energy ratio feature to distinguish between thyroid and non-thyroid tissues for different levels of similarity degrees.</p><fig id="pone.0211215.g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g006</object-id><label>Fig 6</label><caption><title>Color-map of the computed features in patches belonging to thyroid and three classes of non-thyroid regions.</title></caption><graphic xlink:href="pone.0211215.g006"/></fig><p>Following the analysis of the matrix of <xref ref-type="fig" rid="pone.0211215.g006">Fig 6</xref>, 30 energy ratios were selected from the previous analysis. According to their characteristics, they can be divided into two types of energy ratios (ER). 4 ERs are computed as the energy of the maximal spectral peak divided by the total spectral energy in a same frequency band and 26 ERs are computed as ratios between total energy of different frequency bands:
<disp-formula id="pone.0211215.e008"><alternatives><graphic xlink:href="pone.0211215.e008.jpg" id="pone.0211215.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>E</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>U</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle><mml:mspace width="3.33333pt"/><mml:mspace width="3.33333pt"/><mml:mspace width="3.33333pt"/><mml:mspace width="3.33333pt"/><mml:mspace width="3.33333pt"/><mml:mspace width="3.33333pt"/><mml:mi>E</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mn>5</mml:mn><mml:mo>-</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>N</mml:mi><mml:mi>U</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:munderover></mml:mstyle><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
where <italic>f</italic><sub>1</sub> and <italic>f</italic><sub>2</sub> are the frequency onset and offset respectively of the main peak and <italic>S</italic><sub><italic>NUM</italic></sub> and <italic>S</italic><sub><italic>DEN</italic></sub> are the AR spectra used in the numerator and denominator of <xref ref-type="disp-formula" rid="pone.0211215.e008">Eq (3)</xref> and are shown in <xref rid="pone.0211215.t001" ref-type="table">Table 1</xref> for each of the 30 ERs.</p><table-wrap id="pone.0211215.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.t001</object-id><label>Table 1</label><caption><title>Spectra used in the numerator (<italic>NUM</italic>) and denominator (<italic>DEN</italic>) of <xref ref-type="disp-formula" rid="pone.0211215.e008">Eq (3)</xref> for computing the 30 energy ratio features.</title></caption><alternatives><graphic id="pone.0211215.t001g" xlink:href="pone.0211215.t001"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1"><italic>Features</italic><sub>1&#x02212;15</sub></th><th align="center" rowspan="1" colspan="1"><italic>NUM</italic></th><th align="center" style="border-right:thick" rowspan="1" colspan="1"><italic>DEN</italic></th><th align="center" rowspan="1" colspan="1"><italic>Features</italic><sub>16&#x02212;30</sub></th><th align="center" rowspan="1" colspan="1"><italic>NUM</italic></th><th align="center" rowspan="1" colspan="1"><italic>DEN</italic></th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>1</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e009"><alternatives><graphic id="pone.0211215.e009g" xlink:href="pone.0211215.e009"/><mml:math id="M9"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e010"><alternatives><graphic id="pone.0211215.e010g" xlink:href="pone.0211215.e010"/><mml:math id="M10"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>16</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e011"><alternatives><graphic id="pone.0211215.e011g" xlink:href="pone.0211215.e011"/><mml:math id="M11"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e012"><alternatives><graphic id="pone.0211215.e012g" xlink:href="pone.0211215.e012"/><mml:math id="M12"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>2</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e013"><alternatives><graphic id="pone.0211215.e013g" xlink:href="pone.0211215.e013"/><mml:math id="M13"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e014"><alternatives><graphic id="pone.0211215.e014g" xlink:href="pone.0211215.e014"/><mml:math id="M14"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>17</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e015"><alternatives><graphic id="pone.0211215.e015g" xlink:href="pone.0211215.e015"/><mml:math id="M15"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e016"><alternatives><graphic id="pone.0211215.e016g" xlink:href="pone.0211215.e016"/><mml:math id="M16"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>3</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e017"><alternatives><graphic id="pone.0211215.e017g" xlink:href="pone.0211215.e017"/><mml:math id="M17"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e018"><alternatives><graphic id="pone.0211215.e018g" xlink:href="pone.0211215.e018"/><mml:math id="M18"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>18</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e019"><alternatives><graphic id="pone.0211215.e019g" xlink:href="pone.0211215.e019"/><mml:math id="M19"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e020"><alternatives><graphic id="pone.0211215.e020g" xlink:href="pone.0211215.e020"/><mml:math id="M20"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>4</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e021"><alternatives><graphic id="pone.0211215.e021g" xlink:href="pone.0211215.e021"/><mml:math id="M21"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e022"><alternatives><graphic id="pone.0211215.e022g" xlink:href="pone.0211215.e022"/><mml:math id="M22"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>19</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e023"><alternatives><graphic id="pone.0211215.e023g" xlink:href="pone.0211215.e023"/><mml:math id="M23"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e024"><alternatives><graphic id="pone.0211215.e024g" xlink:href="pone.0211215.e024"/><mml:math id="M24"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>5</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e025"><alternatives><graphic id="pone.0211215.e025g" xlink:href="pone.0211215.e025"/><mml:math id="M25"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e026"><alternatives><graphic id="pone.0211215.e026g" xlink:href="pone.0211215.e026"/><mml:math id="M26"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>20</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e027"><alternatives><graphic id="pone.0211215.e027g" xlink:href="pone.0211215.e027"/><mml:math id="M27"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e028"><alternatives><graphic id="pone.0211215.e028g" xlink:href="pone.0211215.e028"/><mml:math id="M28"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>6</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e029"><alternatives><graphic id="pone.0211215.e029g" xlink:href="pone.0211215.e029"/><mml:math id="M29"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e030"><alternatives><graphic id="pone.0211215.e030g" xlink:href="pone.0211215.e030"/><mml:math id="M30"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>21</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e031"><alternatives><graphic id="pone.0211215.e031g" xlink:href="pone.0211215.e031"/><mml:math id="M31"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e032"><alternatives><graphic id="pone.0211215.e032g" xlink:href="pone.0211215.e032"/><mml:math id="M32"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>7</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e033"><alternatives><graphic id="pone.0211215.e033g" xlink:href="pone.0211215.e033"/><mml:math id="M33"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e034"><alternatives><graphic id="pone.0211215.e034g" xlink:href="pone.0211215.e034"/><mml:math id="M34"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>22</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e035"><alternatives><graphic id="pone.0211215.e035g" xlink:href="pone.0211215.e035"/><mml:math id="M35"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e036"><alternatives><graphic id="pone.0211215.e036g" xlink:href="pone.0211215.e036"/><mml:math id="M36"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>8</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e037"><alternatives><graphic id="pone.0211215.e037g" xlink:href="pone.0211215.e037"/><mml:math id="M37"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e038"><alternatives><graphic id="pone.0211215.e038g" xlink:href="pone.0211215.e038"/><mml:math id="M38"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>23</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e039"><alternatives><graphic id="pone.0211215.e039g" xlink:href="pone.0211215.e039"/><mml:math id="M39"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e040"><alternatives><graphic id="pone.0211215.e040g" xlink:href="pone.0211215.e040"/><mml:math id="M40"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>9</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e041"><alternatives><graphic id="pone.0211215.e041g" xlink:href="pone.0211215.e041"/><mml:math id="M41"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e042"><alternatives><graphic id="pone.0211215.e042g" xlink:href="pone.0211215.e042"/><mml:math id="M42"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>24</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e043"><alternatives><graphic id="pone.0211215.e043g" xlink:href="pone.0211215.e043"/><mml:math id="M43"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e044"><alternatives><graphic id="pone.0211215.e044g" xlink:href="pone.0211215.e044"/><mml:math id="M44"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>10</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e045"><alternatives><graphic id="pone.0211215.e045g" xlink:href="pone.0211215.e045"/><mml:math id="M45"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e046"><alternatives><graphic id="pone.0211215.e046g" xlink:href="pone.0211215.e046"/><mml:math id="M46"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>25</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e047"><alternatives><graphic id="pone.0211215.e047g" xlink:href="pone.0211215.e047"/><mml:math id="M47"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e048"><alternatives><graphic id="pone.0211215.e048g" xlink:href="pone.0211215.e048"/><mml:math id="M48"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>11</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e049"><alternatives><graphic id="pone.0211215.e049g" xlink:href="pone.0211215.e049"/><mml:math id="M49"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e050"><alternatives><graphic id="pone.0211215.e050g" xlink:href="pone.0211215.e050"/><mml:math id="M50"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>T</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>26</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e051"><alternatives><graphic id="pone.0211215.e051g" xlink:href="pone.0211215.e051"/><mml:math id="M51"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e052"><alternatives><graphic id="pone.0211215.e052g" xlink:href="pone.0211215.e052"/><mml:math id="M52"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>12</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e053"><alternatives><graphic id="pone.0211215.e053g" xlink:href="pone.0211215.e053"/><mml:math id="M53"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e054"><alternatives><graphic id="pone.0211215.e054g" xlink:href="pone.0211215.e054"/><mml:math id="M54"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>27</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e055"><alternatives><graphic id="pone.0211215.e055g" xlink:href="pone.0211215.e055"/><mml:math id="M55"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e056"><alternatives><graphic id="pone.0211215.e056g" xlink:href="pone.0211215.e056"/><mml:math id="M56"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>13</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e057"><alternatives><graphic id="pone.0211215.e057g" xlink:href="pone.0211215.e057"/><mml:math id="M57"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e058"><alternatives><graphic id="pone.0211215.e058g" xlink:href="pone.0211215.e058"/><mml:math id="M58"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>28</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e059"><alternatives><graphic id="pone.0211215.e059g" xlink:href="pone.0211215.e059"/><mml:math id="M59"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e060"><alternatives><graphic id="pone.0211215.e060g" xlink:href="pone.0211215.e060"/><mml:math id="M60"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>14</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e061"><alternatives><graphic id="pone.0211215.e061g" xlink:href="pone.0211215.e061"/><mml:math id="M61"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e062"><alternatives><graphic id="pone.0211215.e062g" xlink:href="pone.0211215.e062"/><mml:math id="M62"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>29</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e063"><alternatives><graphic id="pone.0211215.e063g" xlink:href="pone.0211215.e063"/><mml:math id="M63"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e064"><alternatives><graphic id="pone.0211215.e064g" xlink:href="pone.0211215.e064"/><mml:math id="M64"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>3</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr><tr><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>15</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e065"><alternatives><graphic id="pone.0211215.e065g" xlink:href="pone.0211215.e065"/><mml:math id="M65"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>L</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" style="border-right:thick" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e066"><alternatives><graphic id="pone.0211215.e066g" xlink:href="pone.0211215.e066"/><mml:math id="M66"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1"><italic>ER</italic><sub>30</sub></td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e067"><alternatives><graphic id="pone.0211215.e067g" xlink:href="pone.0211215.e067"/><mml:math id="M67"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mi>M</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td><td align="center" rowspan="1" colspan="1">
<inline-formula id="pone.0211215.e068"><alternatives><graphic id="pone.0211215.e068g" xlink:href="pone.0211215.e068"/><mml:math id="M68"><mml:msubsup><mml:mi>S</mml:mi><mml:mn>4</mml:mn><mml:mrow><mml:mi>H</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>
</td></tr></tbody></table></alternatives></table-wrap><p>The feature extraction algorithm was fully implemented in Matlab R2015b and executed on a PC with a CPU operating at 2.60 GHz resulting in an execution time of 0.06 seconds for computing the 30 features in one patch.</p></sec></sec><sec sec-type="results" id="sec007"><title>Results</title><p>This section shows the usability of the proposed approach for US feature extraction. 2D US data from thyroid is used in order to analyze the capabilities of the 30 extracted ER features to differentiate between thyroid and non-thyroid tissue in order to use them for segmenting thyroid.</p><sec id="sec008"><title>Thyroid US data description</title><p>Two different real US image datasets have been used to evaluate the proposed approach. The first dataset (in the sequel Dataset 1) has been introduced in [<xref rid="pone.0211215.ref024" ref-type="bibr">24</xref>] and involves six healthy human subjects freehand US images acquired using a Logiq E9 US device with a linear probe and equipped with an electromagnetic tracking system. This database has a total of 675 2D US slices with a 760 &#x000d7; 500 pixels with between 53 and 189 US slices per subject. The second dataset (in the sequel Dataset 2) has been presented in [<xref rid="pone.0211215.ref025" ref-type="bibr">25</xref>] and can be downloaded in <ext-link ext-link-type="uri" xlink:href="http://opencas.webarchiv.kit.edu/?q=node/29">http://opencas.webarchiv.kit.edu/?q=node/29</ext-link>. It involves freehand US images of 16 healthy subjects, each acquired also with a GE Logiq E9 system but operated by a different clinician in a different hospital than in the Database 1 case. From this dataset, a total of 1600 slices belonging to the 16 subjects (100 slices per subject) were used with a size of 760 &#x000d7; 1020 pixels per 2D US slice.</p><p>For each 2D slice the thyroid was manually segmented by an expert clinician (ground truth) and was then divided into patches of 20 &#x000d7; 20 pixels labelled as thyroid or non-thyroid according to the ground truth. It is important to notice that in both datasets the number of patches belonging to thyroid are less that the ones belonging to non-thyroid. This is because the ground truth was used for the automatic patch labelling and usually in a US image the region of thyroid is smaller than the non-thyroid one.</p></sec><sec id="sec009"><title>Average value differences between thyroid and non-thyroid patches for the selected features</title><p>In order to observe the capacity and suitability of the selected features for distinguishing between thyroid and non-thyroid texture, the average and standard deviation (STD) of the feature values were computed for the six subjects belonging to Dataset 1 (see Figs <xref ref-type="fig" rid="pone.0211215.g007">7</xref> and <xref ref-type="fig" rid="pone.0211215.g008">8</xref>). It is possible to visualize that for the whole set of selected ER features, the average values are clearly different between thyroid (red) and non-thyroid (blue) tissues. Moreover, in most of the ER features the thyroid and non-thyroid average values do not strongly change from one subject to another one. Concerning the STD, it is possible to observe that some ER features works better than others. This is the case for example of features <italic>ER</italic><sub>3</sub> and <italic>ER</italic><sub>6</sub> where the STDs inside the thyroid are much smaller than outside the thyroid, what is consistent to the homogeneity of texture inside one healthy organ.</p><fig id="pone.0211215.g007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g007</object-id><label>Fig 7</label><caption><title>Mean and standard deviation of values of ERs features 1 to 15 of thyroid and non-thyroid patches for the 6 subjects of the Dataset 1.</title></caption><graphic xlink:href="pone.0211215.g007"/></fig><fig id="pone.0211215.g008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g008</object-id><label>Fig 8</label><caption><title>Mean and standard deviation of values of ERs features 16 to 30 of thyroid and non-thyroid patches for the 6 subjects of the Dataset 1.</title></caption><graphic xlink:href="pone.0211215.g008"/></fig></sec><sec id="sec010"><title>Features evaluation for thyroid segmentation</title><p>The proposed approach have been tested on the 359712 patches of Dataset 1 and on the 1791397 patches of Dataset 2. For each patch, the 30 ERs of <xref ref-type="disp-formula" rid="pone.0211215.e008">Eq (3)</xref> were computed and analyzed to see their suitability to distinguish between thyroid and non-thyroid tissues.</p><p>In <xref ref-type="fig" rid="pone.0211215.g009">Fig 9</xref> 3D scatters are displayed for 12 ERs (in groups of three features) computed from Dataset 1 clearly showing the differences of these ratio values for thyroid (in red) and non-thyroid (in blue). This confirms that the AR characterization of US texture is well suited to obtain features that are able to be used for classification of thyroid tissue.</p><fig id="pone.0211215.g009" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g009</object-id><label>Fig 9</label><caption><title>Example of obtained AR spectral energy ratios when the approach is applied to the full set of patches extracted from the thyroid US Dataset 1.</title></caption><graphic xlink:href="pone.0211215.g009"/></fig><p>To evaluate the performances of our approach, the computed ER features were used to segment the thyroid. Because our goal is to show the usability of the extracted AR features for texture characterization in US images, complex classification procedures were avoided. Therefore only a simple K-Means algorithm for clustering the patches as thyroid or non-thyroid using the 30 features computed in both datasets was used in this work. As an unsupervised classification for thyroid segmentation, this automatic labelling was then used in each US image to separate the patches belonging to that image as thyroid and non-thyroid.</p><p>
<xref ref-type="fig" rid="pone.0211215.g010">Fig 10</xref> shows some example results of the thyroid segmentation for eight slices: four examples for correct segmentation (first row) and four involving some false positives (second row). In solid red line the ground truth is displayed and the green squares correspond to the 20 &#x000d7; 20 patches that were classified as thyroid by applying our approach to each one of the US images. We displayed US images belonging to different subjects and also to different positions of the 2D slices with respect to the thyroid volume.</p><fig id="pone.0211215.g010" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.g010</object-id><label>Fig 10</label><caption><title>Examples of thyroid segmentation using the proposed approach and comparison with the ground truth.</title></caption><graphic xlink:href="pone.0211215.g010"/></fig><p>In order to globally evaluate our approach with both datasets, the Dice coefficient (DC) is computed from all the 2D segmentations for each Dataset. Additionally, the sensitivity (SE) and specificity (SP) are also computed. The approach obtains a DC of 89.66% with a SE of 0.95 and a SP of 0.70 for the Dataset 1 and a DC of 86.89% with a SE of 0.89 and a SP of 0.62 for the Dataset 2.</p><p>In order to analyze the significance of our results, the proposed approach was compared with other thyroid segmentation methods proposed in the literature. For that the comparison results reported in [<xref rid="pone.0211215.ref008" ref-type="bibr">8</xref>] and in [<xref rid="pone.0211215.ref009" ref-type="bibr">9</xref>] are used.</p><p>In [<xref rid="pone.0211215.ref008" ref-type="bibr">8</xref>] five thyroid segmentation algorithms are compared using ten subjects, where six of them are taken from Dataset 1 used in this work. The algorithms that this work compares in terms of Dice Coefficient are Active Contour Without Edges (ACWE), Graph Cut (GC), Pixel-Based Classifier (PBC), Random Forest Classifier (RFC) and Convolutional Neural Network (CNN). The first three are semi-automatic requiring different levels of interaction with the operator and the other two are automatic. The results of this comparison are displayed in <xref rid="pone.0211215.t002" ref-type="table">Table 2</xref> showing that our approach outperforms the other five algorithms.</p><table-wrap id="pone.0211215.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.t002</object-id><label>Table 2</label><caption><title>Comparison of the proposed approach in terms of Dice Coefficient using the Dataset 1 with algorithms compared in [<xref rid="pone.0211215.ref008" ref-type="bibr">8</xref>].</title></caption><alternatives><graphic id="pone.0211215.t002g" xlink:href="pone.0211215.t002"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">ACWE</th><th align="center" rowspan="1" colspan="1">GC</th><th align="center" rowspan="1" colspan="1">PBC</th><th align="center" rowspan="1" colspan="1">RFC</th><th align="center" rowspan="1" colspan="1">CNN</th><th align="center" rowspan="1" colspan="1">this work</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">80.53%</td><td align="center" rowspan="1" colspan="1">74.52%</td><td align="center" rowspan="1" colspan="1">66.68%</td><td align="center" rowspan="1" colspan="1">85.53%</td><td align="center" rowspan="1" colspan="1">87.22%</td><td align="center" rowspan="1" colspan="1"><bold>89.66%</bold></td></tr></tbody></table></alternatives></table-wrap><p>In [<xref rid="pone.0211215.ref009" ref-type="bibr">9</xref>] an algorithm based on Iterative Random Walks and Random Forest (IRWRF) was evaluated with the Dataset 2 used in this work. They have compared their approach with four other algorithms presented in the literature: Echogenicity-based Quantization (EBQ), Joint Classification-Regression (JCR), RBF Neural Network (RBF), and Feedforward Neural Network (FNN). However the reported results for the other algorithms do not use the same dataset. Despite this fact, we display the results of this comparison in <xref rid="pone.0211215.t003" ref-type="table">Table 3</xref>. The algorithm were compared in terms of DC, SE and SP.</p><table-wrap id="pone.0211215.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211215.t003</object-id><label>Table 3</label><caption><title>Comparison of the proposed approach using Dataset 2 with five algorithm results reported in [<xref rid="pone.0211215.ref009" ref-type="bibr">9</xref>].</title></caption><alternatives><graphic id="pone.0211215.t003g" xlink:href="pone.0211215.t003"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">IRWRF</th><th align="center" rowspan="1" colspan="1">EBQ</th><th align="center" rowspan="1" colspan="1">JCR</th><th align="center" rowspan="1" colspan="1">RBF</th><th align="center" rowspan="1" colspan="1">FNN</th><th align="center" rowspan="1" colspan="1">this work</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">DC</td><td align="char" char="." rowspan="1" colspan="1">85.4%</td><td align="char" char="." rowspan="1" colspan="1">83.9%</td><td align="char" char="." rowspan="1" colspan="1">47.9%</td><td align="char" char="." rowspan="1" colspan="1">51.2%</td><td align="char" char="." rowspan="1" colspan="1">40.0%</td><td align="char" char="." rowspan="1" colspan="1"><bold>86.9%</bold></td></tr><tr><td align="center" rowspan="1" colspan="1">SE</td><td align="char" char="." rowspan="1" colspan="1">98.9%</td><td align="char" char="." rowspan="1" colspan="1">95.5%</td><td align="char" char="." rowspan="1" colspan="1">56.4%</td><td align="char" char="." rowspan="1" colspan="1">87.4%</td><td align="char" char="." rowspan="1" colspan="1">47.3%</td><td align="char" char="." rowspan="1" colspan="1"><bold>89.0%</bold></td></tr><tr><td align="center" rowspan="1" colspan="1">SP</td><td align="char" char="." rowspan="1" colspan="1">92.3%</td><td align="char" char="." rowspan="1" colspan="1">88.9%</td><td align="char" char="." rowspan="1" colspan="1">92.6%</td><td align="char" char="." rowspan="1" colspan="1">56.0%</td><td align="char" char="." rowspan="1" colspan="1">86.4%</td><td align="char" char="." rowspan="1" colspan="1"><bold>62.0%</bold></td></tr></tbody></table></alternatives></table-wrap></sec></sec><sec id="sec011"><title>Conclusions and discussions</title><p>In this work a novel approach for ultrasound image feature extraction was presented. The approach is based on characterizing ultrasound texture through parametrical modelling. The image was transformed into a signal, which was decomposed in several dynamics representing different aspects of the texture. We showed that features consisting on frequency band based energy ratios between the different signal dynamics contain valuable information about texture and can be useful for US image texture classification.</p><p>The usability of the proposed approach was demonstrated in US thyroid segmentation. The 30 extracted AR features computed from energy ratios of the parametrical AR spectra obtain very good and reproducible results for differentiating thyroid and non-thyroid regions in US images. Using a simple K-Means procedure we demonstrated that thyroid patches were successfully clustered for thyroid segmentation. The approach was evaluated with two datasets and compared with ten other algorithms proposed in the literature, obtaining Dice Coefficients over 85% and outperforming other methods.</p><p>We strongly believe that this approach can be used in a variety of US applications, not only for segmentation, but also for data comparison, pattern recognition and possibly others. The presented research contribution and scientific innovation could lead to an objective characterization and differentiation of tissues in US, but likely also be used for other bio-medical imaging methods.</p><p>One of the drawbacks of the proposed approach is that edges between two tissues are prone to segmentation errors. This is due to the patch approach that we have used. In order to deal with this problem the next steps is to implement a <italic>space-variant</italic> AR modelling, analogue to the time-variant version generally used for non-stationary signal processing. This not only should deal with tissue border problems but also should allow to process <italic>signal trajectories</italic> in a volume in order to perform voxel characterization.</p><p>The main focus of this paper was not on thyroid segmentation but on analyze the usability of features that have never been used in the literature for US image analysis. These novel proposed features, even if they are linear, they have obtained interesting results in signal processing in application fields such as biosignal processing or tool wear monitoring. We wanted to analyze how this type of features could work for extracting characteristics from US images. However, in the near future many aspect of this research should be treated in order to think in clinical significant results for US texture characterization. First, a more exhaustive analysis and optimization needs to be performed for AR features selection. It is not only necessary to revise the spectral energy based features but also to see how other AR features (such as pole-based or space variant features) can be used for US texture characterization. Second, a next step should focus on analyze how AR features together with nonlinear features (such as higher order statistics or entropy-based features) and a deep learning procedure can work not only for thyroid segmentation but also for thyroid lesion classification. Finally, in order to show clinical significance, further research is required in order to see the behaviour of the proposed features in larger datasets involving unhealthy thyroids, different US acquisition parameters, different probes and US devices. This is the main next step for our approach.</p></sec></body><back><ref-list><title>References</title><ref id="pone.0211215.ref001"><label>1</label><mixed-citation publication-type="book">
<name><surname>Mirmehdi</surname><given-names>M</given-names></name>. <source>Handbook of texture analysis</source>. <publisher-name>Imperial College Press</publisher-name>; <year>2008</year>.</mixed-citation></ref><ref id="pone.0211215.ref002"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Acharya</surname><given-names>U</given-names></name>, <name><surname>Faust</surname><given-names>O</given-names></name>, <name><surname>Sree</surname><given-names>SV</given-names></name>, <name><surname>Molinari</surname><given-names>F</given-names></name>, <name><surname>Garberoglio</surname><given-names>R</given-names></name>, <name><surname>Suri</surname><given-names>J</given-names></name>. <article-title>Cost-effective and non-invasive automated benign &#x00026; malignant thyroid lesion classification in 3D contrast-enhanced ultrasound using combination of wavelets and textures: a class of ThyroScan&#x02122; algorithms</article-title>. <source>Technology in cancer research &#x00026; treatment</source>. <year>2011</year>;<volume>10</volume>(<issue>4</issue>):<fpage>371</fpage>&#x02013;<lpage>380</lpage>. <pub-id pub-id-type="doi">10.7785/tcrt.2012.500214</pub-id><pub-id pub-id-type="pmid">21728394</pub-id></mixed-citation></ref><ref id="pone.0211215.ref003"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Castellano</surname><given-names>G</given-names></name>, <name><surname>Bonilha</surname><given-names>L</given-names></name>, <name><surname>Li</surname><given-names>L</given-names></name>, <name><surname>Cendes</surname><given-names>F</given-names></name>. <article-title>Texture analysis of medical images</article-title>. <source>Clinical radiology</source>. <year>2004</year>;<volume>59</volume>(<issue>12</issue>):<fpage>1061</fpage>&#x02013;<lpage>1069</lpage>. <pub-id pub-id-type="doi">10.1016/j.crad.2004.07.008</pub-id>
<?supplied-pmid 15556588?><pub-id pub-id-type="pmid">15556588</pub-id></mixed-citation></ref><ref id="pone.0211215.ref004"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Sheeja</surname><given-names>A</given-names></name>, <name><surname>Babu</surname><given-names>SS</given-names></name>. <article-title>Thyroid Segmentation on US Medical Images: An Overview</article-title>. <source>International Journal of Emerging Technology and Advanced Engineering</source>. <year>2012</year>;<volume>2</volume>(<issue>12</issue>).</mixed-citation></ref><ref id="pone.0211215.ref005"><label>5</label><mixed-citation publication-type="book">
<name><surname>Koundal</surname><given-names>D</given-names></name>, <name><surname>Gupta</surname><given-names>S</given-names></name>, <name><surname>Singh</surname><given-names>S</given-names></name>. <chapter-title>Survey of computer-aided diagnosis of thyroid nodules in medical ultrasound images</chapter-title> In: <source>Advances in Computing and Information Technology</source>. <publisher-name>Springer</publisher-name>; <year>2013</year> p. <fpage>459</fpage>&#x02013;<lpage>467</lpage>.</mixed-citation></ref><ref id="pone.0211215.ref006"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Swapna</surname><given-names>G</given-names></name>, <name><surname>Sree</surname><given-names>SV</given-names></name>, <name><surname>Molinari</surname><given-names>F</given-names></name>, <name><surname>Gupta</surname><given-names>S</given-names></name>, <name><surname>Bardales</surname><given-names>RH</given-names></name>, <etal>et al</etal>
<article-title>A review on ultrasound-based thyroid cancer tissue characterization and automated classification</article-title>. <source>Technology in cancer research &#x00026; treatment</source>. <year>2014</year>;<volume>13</volume>(<issue>4</issue>):<fpage>289</fpage>&#x02013;<lpage>301</lpage>. <pub-id pub-id-type="doi">10.7785/tcrt.2012.500381</pub-id><pub-id pub-id-type="pmid">24206204</pub-id></mixed-citation></ref><ref id="pone.0211215.ref007"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Sollini</surname><given-names>M</given-names></name>, <name><surname>Cozzi</surname><given-names>L</given-names></name>, <name><surname>Chiti</surname><given-names>A</given-names></name>, <name><surname>Kirienko</surname><given-names>M</given-names></name>. <article-title>Texture analysis and machine learning to characterize suspected thyroid nodules and differentiated thyroid cancer: Where do we stand?</article-title>
<source>European journal of radiology</source>. <year>2018</year>;<volume>99</volume>:<fpage>1</fpage>&#x02013;<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1016/j.ejrad.2017.12.004</pub-id>
<?supplied-pmid 29362138?><pub-id pub-id-type="pmid">29362138</pub-id></mixed-citation></ref><ref id="pone.0211215.ref008"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Poudel</surname><given-names>P</given-names></name>, <name><surname>Illanes</surname><given-names>A</given-names></name>, <name><surname>Sheet</surname><given-names>D</given-names></name>, <name><surname>Friebe</surname><given-names>M</given-names></name>. <article-title>Evaluation of Commonly Used Algorithms for Thyroid Ultrasound Images Segmentation and Improvement Using Machine Learning Approaches</article-title>. <source>Journal of healthcare engineering</source>. <year>2018</year>;<volume>2018</volume>
<pub-id pub-id-type="doi">10.1155/2018/8087624</pub-id>
<?supplied-pmid 30344990?><pub-id pub-id-type="pmid">30344990</pub-id></mixed-citation></ref><ref id="pone.0211215.ref009"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Debarghya</surname><given-names>C</given-names></name>, <name><surname>Illanes</surname><given-names>A</given-names></name>, <name><surname>Poudel</surname><given-names>P</given-names></name>, <name><surname>Friebe</surname><given-names>M</given-names></name>, <name><surname>Mitra</surname><given-names>P</given-names></name>, <name><surname>Sheet</surname><given-names>D</given-names></name>. <article-title>Anatomical Structure Segmentation in Ultrasound Volumes using Cross Frame Belief Propagating Iterative Random Walks</article-title>. <source>IEEE journal of biomedical and health informatics</source>. <year>2018</year>;.</mixed-citation></ref><ref id="pone.0211215.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Iakovidis</surname><given-names>DK</given-names></name>, <name><surname>Keramidas</surname><given-names>EG</given-names></name>, <name><surname>Maroulis</surname><given-names>D</given-names></name>. <article-title>Fusion of fuzzy statistical distributions for classification of thyroid ultrasound patterns</article-title>. <source>Artificial Intelligence in Medicine</source>. <year>2010</year>;<volume>50</volume>(<issue>1</issue>):<fpage>33</fpage>&#x02013;<lpage>41</lpage>. <pub-id pub-id-type="doi">10.1016/j.artmed.2010.04.004</pub-id>
<?supplied-pmid 20427164?><pub-id pub-id-type="pmid">20427164</pub-id></mixed-citation></ref><ref id="pone.0211215.ref011"><label>11</label><mixed-citation publication-type="other">Selvathi D, Sharnitha V. Thyroid classification and segmentation in ultrasound images using machine learning algorithms. In: Signal Processing, Communication, Computing and Networking Technologies (ICSCCN), 2011 International Conference on. IEEE; 2011. p. 836&#x02013;841.</mixed-citation></ref><ref id="pone.0211215.ref012"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Koprowski</surname><given-names>R</given-names></name>, <name><surname>Korzy&#x00144;ska</surname><given-names>A</given-names></name>, <name><surname>Wr&#x000f3;bel</surname><given-names>Z</given-names></name>, <name><surname>Ziele&#x0017a;nik</surname><given-names>W</given-names></name>, <name><surname>Witkowska</surname><given-names>A</given-names></name>, <name><surname>Ma&#x00142;yszek</surname><given-names>J</given-names></name>, <etal>et al</etal>
<article-title>Influence of the measurement method of features in ultrasound images of the thyroid in the diagnosis of Hashimoto&#x02019;s disease</article-title>. <source>Biomedical engineering online</source>. <year>2012</year>;<volume>11</volume>(<issue>1</issue>):<fpage>91</fpage>
<pub-id pub-id-type="doi">10.1186/1475-925X-11-91</pub-id>
<?supplied-pmid 23190930?><pub-id pub-id-type="pmid">23190930</pub-id></mixed-citation></ref><ref id="pone.0211215.ref013"><label>13</label><mixed-citation publication-type="journal">
<name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Sree</surname><given-names>SV</given-names></name>, <name><surname>Krishnan</surname><given-names>MMR</given-names></name>, <name><surname>Molinari</surname><given-names>F</given-names></name>, <name><surname>Garberoglio</surname><given-names>R</given-names></name>, <name><surname>Suri</surname><given-names>JS</given-names></name>. <article-title>Non-invasive automated 3D thyroid lesion classification in ultrasound: a class of ThyroScan&#x02122; systems</article-title>. <source>Ultrasonics</source>. <year>2012</year>;<volume>52</volume>(<issue>4</issue>):<fpage>508</fpage>&#x02013;<lpage>520</lpage>. <pub-id pub-id-type="doi">10.1016/j.ultras.2011.11.003</pub-id>
<?supplied-pmid 22154208?><pub-id pub-id-type="pmid">22154208</pub-id></mixed-citation></ref><ref id="pone.0211215.ref014"><label>14</label><mixed-citation publication-type="journal">
<name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Chowriappa</surname><given-names>P</given-names></name>, <name><surname>Fujita</surname><given-names>H</given-names></name>, <name><surname>Bhat</surname><given-names>S</given-names></name>, <name><surname>Dua</surname><given-names>S</given-names></name>, <name><surname>Koh</surname><given-names>JE</given-names></name>, <etal>et al</etal>
<article-title>Thyroid lesion classification in 242 patient population using Gabor transform features from high resolution ultrasound images</article-title>. <source>Knowledge-Based Systems</source>. <year>2016</year>;<volume>107</volume>:<fpage>235</fpage>&#x02013;<lpage>245</lpage>. <pub-id pub-id-type="doi">10.1016/j.knosys.2016.06.010</pub-id></mixed-citation></ref><ref id="pone.0211215.ref015"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Sree</surname><given-names>SV</given-names></name>, <name><surname>Swapna</surname><given-names>G</given-names></name>, <name><surname>Gupta</surname><given-names>S</given-names></name>, <name><surname>Molinari</surname><given-names>F</given-names></name>, <name><surname>Garberoglio</surname><given-names>R</given-names></name>, <etal>et al</etal>
<article-title>Effect of complex wavelet transform filter on thyroid tumor classification in three-dimensional ultrasound</article-title>. <source>Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine</source>. <year>2013</year>;<volume>227</volume>(<issue>3</issue>):<fpage>284</fpage>&#x02013;<lpage>292</lpage>. <pub-id pub-id-type="doi">10.1177/0954411912472422</pub-id></mixed-citation></ref><ref id="pone.0211215.ref016"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Raghavendra</surname><given-names>U</given-names></name>, <name><surname>Gudigar</surname><given-names>A</given-names></name>, <name><surname>Maithri</surname><given-names>M</given-names></name>, <name><surname>Gertych</surname><given-names>A</given-names></name>, <name><surname>Meiburger</surname><given-names>KM</given-names></name>, <name><surname>Yeong</surname><given-names>CH</given-names></name>, <etal>et al</etal>
<article-title>Optimized multi-level elongated quinary patterns for the assessment of thyroid nodules in ultrasound images</article-title>. <source>Computers in biology and medicine</source>. <year>2018</year>;<volume>95</volume>:<fpage>55</fpage>&#x02013;<lpage>62</lpage>. <pub-id pub-id-type="doi">10.1016/j.compbiomed.2018.02.002</pub-id>
<?supplied-pmid 29455080?><pub-id pub-id-type="pmid">29455080</pub-id></mixed-citation></ref><ref id="pone.0211215.ref017"><label>17</label><mixed-citation publication-type="journal">
<name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Faust</surname><given-names>O</given-names></name>, <name><surname>Sree</surname><given-names>SV</given-names></name>, <name><surname>Molinari</surname><given-names>F</given-names></name>, <name><surname>Suri</surname><given-names>JS</given-names></name>. <article-title>ThyroScreen system: high resolution ultrasound thyroid image characterization into benign and malignant classes using novel combination of texture and discrete wavelet transform</article-title>. <source>Computer methods and programs in biomedicine</source>. <year>2012</year>;<volume>107</volume>(<issue>2</issue>):<fpage>233</fpage>&#x02013;<lpage>241</lpage>. <pub-id pub-id-type="doi">10.1016/j.cmpb.2011.10.001</pub-id>
<?supplied-pmid 22054816?><pub-id pub-id-type="pmid">22054816</pub-id></mixed-citation></ref><ref id="pone.0211215.ref018"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Ardakani</surname><given-names>AA</given-names></name>, <name><surname>Gharbali</surname><given-names>A</given-names></name>, <name><surname>Mohammadi</surname><given-names>A</given-names></name>. <article-title>Classification of benign and malignant thyroid nodules using wavelet texture analysis of sonograms</article-title>. <source>Journal of Ultrasound in Medicine</source>. <year>2015</year>;<volume>34</volume>(<issue>11</issue>):<fpage>1983</fpage>&#x02013;<lpage>1989</lpage>. <pub-id pub-id-type="doi">10.7863/ultra.14.09057</pub-id>
<?supplied-pmid 26396168?><pub-id pub-id-type="pmid">26396168</pub-id></mixed-citation></ref><ref id="pone.0211215.ref019"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Raghavendra</surname><given-names>U</given-names></name>, <name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Gudigar</surname><given-names>A</given-names></name>, <name><surname>Tan</surname><given-names>JH</given-names></name>, <name><surname>Fujita</surname><given-names>H</given-names></name>, <name><surname>Hagiwara</surname><given-names>Y</given-names></name>, <etal>et al</etal>
<article-title>Fusion of spatial gray level dependency and fractal texture features for the characterization of thyroid lesions</article-title>. <source>Ultrasonics</source>. <year>2017</year>;<volume>77</volume>:<fpage>110</fpage>&#x02013;<lpage>120</lpage>. <pub-id pub-id-type="doi">10.1016/j.ultras.2017.02.003</pub-id>
<?supplied-pmid 28219805?><pub-id pub-id-type="pmid">28219805</pub-id></mixed-citation></ref><ref id="pone.0211215.ref020"><label>20</label><mixed-citation publication-type="other">Ozyilmaz L, Yildirim T. Diagnosis of thyroid disease using artificial neural network methods. In: Neural Information Processing, 2002. ICONIP&#x02019;02. Proceedings of the 9th International Conference on. vol. 4. IEEE; 2002. p. 2033&#x02013;2036.</mixed-citation></ref><ref id="pone.0211215.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Chi</surname><given-names>J</given-names></name>, <name><surname>Walia</surname><given-names>E</given-names></name>, <name><surname>Babyn</surname><given-names>P</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Groot</surname><given-names>G</given-names></name>, <name><surname>Eramian</surname><given-names>M</given-names></name>. <article-title>Thyroid nodule classification in ultrasound images by fine-tuning deep convolutional neural network</article-title>. <source>Journal of digital imaging</source>. <year>2017</year>;<volume>30</volume>(<issue>4</issue>):<fpage>477</fpage>&#x02013;<lpage>486</lpage>. <pub-id pub-id-type="doi">10.1007/s10278-017-9997-y</pub-id>
<?supplied-pmid 28695342?><pub-id pub-id-type="pmid">28695342</pub-id></mixed-citation></ref><ref id="pone.0211215.ref022"><label>22</label><mixed-citation publication-type="book">
<name><surname>Manolakis</surname><given-names>DG</given-names></name>, <name><surname>Ingle</surname><given-names>VK</given-names></name>, <name><surname>Kogon</surname><given-names>SM</given-names></name>. <source>Statistical and adaptive signal processing: spectral estimation, signal modeling, adaptive filtering, and array processing</source>. <publisher-name>McGraw-Hill</publisher-name>
<publisher-loc>Boston</publisher-loc>; <year>2000</year>.</mixed-citation></ref><ref id="pone.0211215.ref023"><label>23</label><mixed-citation publication-type="book">
<name><surname>Acharya</surname><given-names>UR</given-names></name>, <name><surname>Joseph</surname><given-names>KP</given-names></name>, <name><surname>Kannathal</surname><given-names>N</given-names></name>, <name><surname>Min</surname><given-names>LC</given-names></name>, <name><surname>Suri</surname><given-names>JS</given-names></name>. <chapter-title>Heart rate variability</chapter-title> In: <source>Advances in cardiac signal processing</source>. <publisher-name>Springer</publisher-name>; <year>2007</year> p. <fpage>121</fpage>&#x02013;<lpage>165</lpage>.</mixed-citation></ref><ref id="pone.0211215.ref024"><label>24</label><mixed-citation publication-type="book">
<name><surname>Poudel</surname><given-names>P</given-names></name>, <name><surname>Ataide</surname><given-names>E</given-names></name>, <name><surname>Illanes</surname><given-names>A</given-names></name>, <name><surname>Friebe</surname><given-names>M</given-names></name>. <chapter-title>Linear Discriminant Analysis and K-Means Clustering for Classification of Thyroid Texture in Ultrasound Images</chapter-title> In: <source>Proc IEEE Eng Med Biol Soc</source>. <publisher-loc>Honolulu, USA</publisher-loc>; <year>2018</year>.</mixed-citation></ref><ref id="pone.0211215.ref025"><label>25</label><mixed-citation publication-type="book">
<name><surname>Wunderling</surname><given-names>T</given-names></name>, <name><surname>Golla</surname><given-names>B</given-names></name>, <name><surname>Poudel</surname><given-names>P</given-names></name>, <name><surname>Arens</surname><given-names>C</given-names></name>, <name><surname>Friebe</surname><given-names>M</given-names></name>, <name><surname>Hansen</surname><given-names>C</given-names></name>. <chapter-title>Comparison of thyroid segmentation techniques for 3D ultrasound</chapter-title> In: <source>Medical Imaging 2017: Image Processing</source>. <volume>vol. 10133</volume>
<publisher-name>International Society for Optics and Photonics</publisher-name>; <year>2017</year> p. <fpage>1013317</fpage>.</mixed-citation></ref></ref-list></back></article>