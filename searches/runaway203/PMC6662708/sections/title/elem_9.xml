<?xml version="1.0" encoding="UTF-8"?>
<sec id="Sec9" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Methods</div>
 <sec id="Sec10" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Panel sample collection</div>
  <p id="Par26" xmlns="http://www.w3.org/1999/xhtml">Samples were taken for molecular analyses from heated (+1 and +2 °C above ambient sea water temperatures) and non-heated (control) panels after 18 months immersion at 15 m depth near Rothera Research Station, Adelaide Island, Antarctic Peninsula (67°4′07″S, 68°07′30″W). These treatments are referred to as control +1 and +2 in the following methods. At the start of the 18-month deployments, all panels were brand new, placed on site and then gradually warmed up to the relevant temperature for colonisation in situ. Three sites around Rothera were used for the original study, with panels deployed in South Cove, Hangar Cove and North Cove on concrete substrata. At each site, four heated panels for each temperature (total of 12 panels per site) were laid in a random design in batches of four with position generated by a random number generator and this design was random with regard to both the position and the concrete block. Because of iceberg impact damage, one set of panels was retrieved from South Cove after 9 months and held in the Rothera flow-through aquarium. The water intake for the aquarium is not filtered; the inlet is at 7M and only boulder covered to protect from ice. Therefore, the animals in the aquarium experienced the same sea water, food availability and environmental conditions as the original site for a further 9 months (South Cove panels). It should furthermore be noted that most of this final 9-month period took place during winter when phytoplankton levels are extremely low. Another set of panels (North Cove panels) remained in the sea for the whole 18-month period. It was not possible to use the Hangar Cove panels in this study, as predation by urchins had dramatically altered the community composition of the panels at this site. Experimental organisms were non-regulated so ethical approval was not required. After a preliminary environmental assessment (PEA #14-11) collections were made within the Antarctic Act, permit number S7-10/2015, as granted under section 7 of the Antarctic Act 1994.</p>
 </sec>
 <sec id="Sec11" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Transcriptome methods</div>
  <p id="Par27" xmlns="http://www.w3.org/1999/xhtml">
   <span class="italic">Protolaeospira stalagmia</span> were dissected from their calcified skeletons, snap frozen in liquid nitrogen and stored at −80 °C prior to RNA extraction. Total RNA was extracted from dissected 
   <span class="italic">Protolaeospira stalagmia</span> (
   <span class="italic">n</span> = 6 per panel, per treatment: 3 each of control, +1, +2; total of 54 individuals) using ReliaPrep TM RNA Miniprep Systems (Promega) according to the manufacturer’s instructions. RNA samples were assessed for concentration and quality using a NanoDrop ND-100 Spectrometer (NanoDrop Technologies) and an Agilent 2200 Tapestation (Agilent Technologies). RNA samples (
   <span class="italic">n</span> = 6 per panel, per treatment) were pooled to obtain a total of three replicates per treatment (control, +1, +2) producing a final total of nine samples of 150 ng RNA for each sample.
  </p>
  <p id="Par28" xmlns="http://www.w3.org/1999/xhtml">To obtain sufficient RNA for library preparation each RNA pool was cDNA was amplified using the Ovation RNA-Seq system v2 kit (NuGEN) according to the manufacturer’s instructions. Library preparation and sequencing was carried out by Edinburgh Genomics (Edinburgh, UK). For each sample, cDNA was converted to a sequencing library using the TruSeq standed mRNA-Seq library for NeoPrep (Ilumina) and barcoded libraries were pooled and sequenced on an Illumina HiSeq 4000 using 125 base paired-end reads to generate 50 million raw reads per sample.</p>
  <p id="Par29" xmlns="http://www.w3.org/1999/xhtml">Reads were trimmed using Cutadapt (version 1.9 dev2)
   <span class="sup">
    <a ref-type="bibr" rid="CR46" href="#CR46">46</a>
   </span> for quality at the 3′ end using a quality threshold of 30 and for adapter sequences of the TruSeq Nano DNA kit (AGATCGGAAGAGC) and a minimum length of 35 bp. rRNA reads were removed using sortMeRNA (version 2.1)
   <span class="sup">
    <a ref-type="bibr" rid="CR47" href="#CR47">47</a>
   </span>. The filtered reads were assembled using Trinity (version 2.5)
   <span class="sup">
    <a ref-type="bibr" rid="CR48" href="#CR48">48</a>
   </span>, which produced over five million sequences. Transcripts were quantified using the RSEM method
   <span class="sup">
    <a ref-type="bibr" rid="CR49" href="#CR49">49</a>
   </span> and any sequences with TPM (transcripts per million) &lt;1 and isopct (minimal level of dominant isoform expression) &lt;1 were discarded. In order to further reduce any redundancy, transcripts with 95% similarity were clustered using CD-HIT-EST (version 4.7)
   <span class="sup">
    <a ref-type="bibr" rid="CR50" href="#CR50">50</a>,
    <a ref-type="bibr" rid="CR51" href="#CR51">51</a>
   </span>. These contigs were annotated using Trinotate (version 3.1.1)
   <span class="sup">
    <a ref-type="bibr" rid="CR48" href="#CR48">48</a>
   </span>. As part of this pipeline, peptide sequences were predicted using transdecoder, which were further searched against the SwissProt non-redundant database using BLASTP
   <span class="sup">
    <a ref-type="bibr" rid="CR52" href="#CR52">52</a>
   </span>. BLASTX
   <span class="sup">
    <a ref-type="bibr" rid="CR52" href="#CR52">52</a>
   </span> search was also performed with the transcript sequences as the query and the SwissProt non-redudant database as the target. The Pfam databases
   <span class="sup">
    <a ref-type="bibr" rid="CR53" href="#CR53">53</a>
   </span> were used to predict protein domains using HMMER
   <span class="sup">
    <a ref-type="bibr" rid="CR54" href="#CR54">54</a>
   </span>. SignalP (version 4.1)
   <span class="sup">
    <a ref-type="bibr" rid="CR55" href="#CR55">55</a>
   </span> was used to predict the presence of signal peptides, and TMHMM
   <span class="sup">
    <a ref-type="bibr" rid="CR56" href="#CR56">56</a>
   </span> was used to predict transmembrane helices within the predicted peptide sequences.
  </p>
  <p id="Par30" xmlns="http://www.w3.org/1999/xhtml">The trimmed reads free from rRNA were aligned against the reference transcriptome using bwa mem (version 0.7.13-r1126)
   <span class="sup">
    <a ref-type="bibr" rid="CR57" href="#CR57">57</a>
   </span> with parameter ‘-M’. Duplicates were marked using Picard tools (version 2.8.1) (
   <span ext-link-type="uri" xlink:href="http://broadinstitute.github.io/picard" class="ext-link" xmlns:xlink="http://www.w3.org/1999/xlink">http://broadinstitute.github.io/picard</span>). Read counts by transcript were generated using Salmon (version 0.9.1)
   <span class="sup">
    <a ref-type="bibr" rid="CR58" href="#CR58">58</a>
   </span>. The transcriptome assembly produced earlier was used to produce a quasi-mapping index. The quantification step was carried out with parameter ‘-1 U’ to specify an unstranded library and bias correction parameters –seqBias, --gcBias and –posBias
   <span class="sup">
    <a ref-type="bibr" rid="CR58" href="#CR58">58</a>
   </span>. Transcripts were filtered on counts per million (CPM) to remove transcripts consisting of near-zero counts and to avoid artefacts due to library depth. Transcripts were required to have a CPM &gt;0.3 in at least three samples, corresponding to the smallest sample group as defined by group, once any samples were removed. Reads were normalised using the weighted trimmed mean of 
   <span class="italic">M</span>-values method
   <span class="sup">
    <a ref-type="bibr" rid="CR59" href="#CR59">59</a>
   </span>. ‘TMM’ was passed as the method to the calcNormFactors method of edgeR. edgeR (version 3.16.5)
   <span class="sup">
    <a ref-type="bibr" rid="CR59" href="#CR59">59</a>
   </span> was used to perform differential expression analysis. Fold changes were estimated as per the default behaviour of edgeR. Statistical assessment of differential expression was carried out with the quasi-likehood (QL) 
   <span class="italic">F</span>-test using the following contrasts: Control versus 1 °C, controls versus 2 °C and 1 °C versus 2 °C. To adjust for confounding covariates such as batch effects, a blocking factor was incorporated as part of the additive model. Differential gene set analysis was carried out using ROAST
   <span class="sup">
    <a ref-type="bibr" rid="CR60" href="#CR60">60</a>
   </span> from the Limma package version 3.30.13 (ref. 
   <span class="sup">
    <a ref-type="bibr" rid="CR61" href="#CR61">61</a>
   </span>) of Bioconductor using the same models and contrasts as used in the differential transcript analysis expression. A PCA analysis was undertaken on normalised and filtered expression data to explore observed patterns with respect to experimental factors. The cumulative proportion of variance associated with each factor was used to study the level of structure in the data, while associations between continuous value ranges in principal components and categorical factors was assessed with an ANOVA test. The following Gene Ontology (GO) gene sets were used: GO Molecular Function, GO Cellular Component and GO Biological Process
   <span class="sup">
    <a ref-type="bibr" rid="CR62" href="#CR62">62</a>
   </span>. For GO enrichment analyses, the GO annotations were extracted from the Trans-D_trinotate_annotation_report.txt. ROAST was executed using 9999 rotations. GO terms that were not associated with at least five genes were excluded from the analysis. All transcripts in the contrasts of interest with either a BLASTX and/or a BLASTP annotation were re-searched against the human SwissProt database
   <span class="sup">
    <a ref-type="bibr" rid="CR63" href="#CR63">63</a>
   </span>. A list of unique human protein identifiers was then entered into both the STRING
   <span class="sup">
    <a ref-type="bibr" rid="CR64" href="#CR64">64</a>
   </span> and PANTHER
   <span class="sup">
    <a ref-type="bibr" rid="CR65" href="#CR65">65</a>
   </span> databases to evaluate enrichment of functional groups.
  </p>
 </sec>
 <sec id="Sec12" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Upper thermal limit experiments on 
   <span class="italic">Romanchella perrieri</span>
  </div>
  <p id="Par31" xmlns="http://www.w3.org/1999/xhtml">UTLs were measured in 
   <span class="italic">R. perrieri</span> on heated panels from two sites to evaluate whole animal acclimation. The sites were North Cove and South Cove, described earlier. The animals were taken from the same panels in South Cove that were used as a source for 
   <span class="italic">P. stalagmia</span> for the transcriptome experiments. One heated settlement panel was used for each of the UTL experiments at each temperature, for each site (total of 6 panels), with 25 animals evaluated per panel (total of 150 animals in the experiment). Heated and non-heated panels (one each of control, +1, +2) from the South Cove/aquarium and North Cove sites colonised by 
   <span class="italic">R. perrieri</span> were transferred to a 60-L jacketed tank with aerated sea water at the same temperature as the ambient sea water (0 °C) and connected to a thermocirculator (Grant Instruments Ltd, Cambridge, UK). The temperature was raised at 1 °C h
   <span class="sup">−1</span> with the temperature limit of each animal noted when they no longer responded to tactile stimuli
   <span class="sup">
    <a ref-type="bibr" rid="CR35" href="#CR35">35</a>
   </span>, i.e., did not retract into their exoskeleton, when touched with a dissecting needle seeker. UTL data were non-normal, even after transformations, so non-parametric statistical tests were used to analyse the data. A Mann–Whitney test verified that both the South Cove and North Cove data could be combined (
   <span class="italic">P</span> = 0.0896). A Kruskal–Wallis test was used to investigate if there was an effect of temperature on UTL compared with panel treatment and Mann–Whitney tests were subsequently used on these data to identify significance between panel treatments.
  </p>
 </sec>
 <sec id="Sec13" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Population genetic analyses</div>
  <p id="Par32" xmlns="http://www.w3.org/1999/xhtml">Transcripts generated for the expression analyses were used in this analysis. Default parameters were used for all programmes unless specified.</p>
  <p id="Par33" xmlns="http://www.w3.org/1999/xhtml">Supertranscripts were generated from the assembled transcriptome using the script ‘Trinity_gene_splice_modeler.py’ provided with Trinity (version 2.5.0)
   <span class="sup">
    <a ref-type="bibr" rid="CR48" href="#CR48">48</a>
   </span>. Trimmed and filtered reads were aligned to the supercontigs using STAR (version 2.5.2b)
   <span class="sup">
    <a ref-type="bibr" rid="CR66" href="#CR66">66</a>
   </span>. Potential PCR duplicates were marked using Picard tools MarkDuplicates. In accordance with GATK
   <span class="sup">
    <a ref-type="bibr" rid="CR67" href="#CR67">67</a>
   </span> best practices, reads with split mappings were split into separate reads in the BAM files using GATK (version 3.7) tool SplitNCigarReads with parameters: -rf ReassignOneMappingQuality -RMQF 255 -RMQT 60 -U ALLOW_N_CIGAR_READS. Local realignment around indels was performed using GATK tools RealignerTargetCreator and IndelRealigner. A single pileup file was generated from the nine BAM files using samtools
   <span class="sup">
    <a ref-type="bibr" rid="CR68" href="#CR68">68</a>
   </span> mpileup (version 1.3) with the parameters ‘-B -q 20-Q30’. These parameters result in bases with a base quality phred score of less than 30, and an alignment quality of less than 20, being discarded. A single ‘.sync’ file was generated from the pileup file using ‘mpileup2sync.jar’ from PoPoolation2 (ref. 
   <span class="sup">
    <a ref-type="bibr" rid="CR69" href="#CR69">69</a>
   </span>) (version 1.201).
  </p>
  <p id="Par34" xmlns="http://www.w3.org/1999/xhtml">Bayenv2 (ref. 
   <span class="sup">
    <a ref-type="bibr" rid="CR39" href="#CR39">39</a>
   </span>) was used to measure the extent to which the allele frequencies of each SNP correlate with temperature. Bayenv2 is designed to take into account the extra level of sampling error arising from pooled data from a small number of individuals. In accordance with recommendations for running Bayenv2, a set of SNPs were selected to generate a matrix of covariance between samples. Only SNPs covered by at least five reads in at least six samples, and with a minor allele supported by at least five reads in total across all samples, were selected, and only one SNP per transcript was included. The covariance matrix was generated using Bayenv2 with the following parameters: -p 9 -k 200000, and specifying specifies four diploid individuals per sample with the ‘-s’ flag. 
   <span class="italic">Z</span>-scores for each SNP were calculated using Bayenv2 with the parameters: -p 9 k 200000 -r 8372 -n 1 -e standard_env.txt -x -m pool_matrix.txt –t. Where file ‘pool_matrix.txt’ contains the covariance matrix produced in the previous step, and ‘standard_env.txt’ contains standardised measures of temperature (in degrees centigrade).
  </p>
  <p id="Par35" xmlns="http://www.w3.org/1999/xhtml">Due to the various sources of noise in this dataset, we wanted to filter out SNPs that were most likely affected by sampling error. Before attempting to calculate FDRs or perform GSEA, the SNPs were filtered to remove low coverage SNPs. Specifically, we removed SNPs that were not covered by at least five reads in each sample, or which had a minor allele supported by less than 15 reads in total across the nine samples. Because Bayenv2 does not produce 
   <span class="italic">P</span> values, we estimated the statistical significance of our results by reference to a null distribution of 
   <span class="italic">Z</span>-scores. This was created by randomly permuting the labels in file ‘standard_env.txt’ 100 times and recalculating the 
   <span class="italic">Z</span>-scores for each SNP. The null distribution of 
   <span class="italic">Z</span>-scores allowed us to calculate the probability of a high 
   <span class="italic">Z</span>-score arising by chance. The false discovery rate (FDR) for each SNP was then calculated as follows: FDR = 
   <span class="italic">ip</span>/
   <span class="italic">n</span>, where 
   <span class="italic">i</span> = number of SNPs in the dataset that achieved an equal or greater 
   <span class="italic">Z</span>-score, 
   <span class="italic">n</span> = total number of SNPs in all null permutations that achieved an equal or greater than 
   <span class="italic">Z</span>-score, and 
   <span class="italic">p</span> = number of permutations.
  </p>
  <p id="Par36" xmlns="http://www.w3.org/1999/xhtml">A score for each supertranscript was calculated by taking the mean 
   <span class="italic">Z</span>-score of all SNPs from that supertranscript. FDRs for each supertranscript with more than five SNPs that passed the filter were calculated from the null distribution as follows: FDR = 
   <span class="italic">ip</span>/
   <span class="italic">n</span>, where 
   <span class="italic">i</span> = number of supertranscripts in dataset that achieved an equal or greater mean 
   <span class="italic">Z</span>-score, 
   <span class="italic">n</span> = total number of supertranscripts with at least five SNPs passing the filter in all null permutations that achieved an equal or greater mean 
   <span class="italic">Z</span>-score, and 
   <span class="italic">p</span> = number of permutations. For each SNP, the minor allele frequency (MAF) was calculated for each of the three groups of samples. The MAF was calculated for each individual sample as follows: MAF = 
   <span class="italic">m</span>/
   <span class="italic">t</span>, where 
   <span class="italic">m</span> = number of reads supporting minor allele and 
   <span class="italic">t</span> = total number of reads covering site. The effective allele number was also calculated for each sample at each SNP, using the formula 
   <span class="italic">e</span> = ((
   <span class="italic">nc</span>)−1)/(
   <span class="italic">n</span>+
   <span class="italic">c</span>). MAF was calculated for each of the three groups by taking the average MAF for each sample weighted by the effective allele number for that sample. This allows varying the sampling error arising from the varying depths of coverage between samples to be accounted for.
  </p>
 </sec>
 <sec id="Sec14" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Biofilm methods</div>
  <p id="Par37" xmlns="http://www.w3.org/1999/xhtml">Panels from North Cove were brought up to the surface by SCUBA divers and placed in a 10 L tank on the boat with sea water at the same temperature as the ambient sea water (~0 °C). Biofilm swabs were taken from the panels while on the boat and stored in 100% ethanol for subsequent analyses. Four to five biofilm swabs were taken per treatment (control, +1, +2). Total genomic DNA was extracted from the biofilm swabs using the PowerBiofilm DNA isolation kit (MO BIO Laboratories, Inc.) following the manufacturer’s instructions. A blank swab was also included and extracted as a no-template control. DNA samples were assessed for concentration and quality using a NanoDrop ND-100 Spectrometer (NanoDrop Technologies) and an Agilent 2200 Tapestation (Agilent Technologies). To enable compatibility with the Illumina 16S Metagenomic Sequencing Protocol, the hypervariable V4 region of the 16S rRNA genes was PCR-amplified using the 16S Amplicon PCR forward primer (5′-TCGTCGGCAGCGTCAGATGTGTATAAGAGACAGCCTACGGGNGGCWGCAG) and the 16S Amplicon reverse PCR primer (5′-GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAGGACTACHVGGGTATCTAATCC). PCR reactions were carried out using the KAPA Hifi HotStart ReadyMix according to manufacturer’s instructions. Amplifications were carried out in an AlphaCycler (PCRmax) under the following conditions: 95 °C for 30 s, followed by 25 cycles of 95 °C for 30 s, 55 °C for 30 s and 72 °C for 30 s. A final elongation step at 72 °C for 5 min was performed. Resulting PCR products were checked by standard agarose gel (1.5%) electrophoresis and purified using the QIAquick PCR Purification kit (Qiagen) following the manufacturer’s instructions.</p>
  <p id="Par38" xmlns="http://www.w3.org/1999/xhtml">Library preparation and sequencing was carried out by the Department of Biochemistry at the University of Cambridge. For each sample (
   <span class="italic">n</span> = 4–5 swabs per sample per treatment: control, +1, +2 and control) DNA was converted in to a sequencing library using the 16S Metagenomic Sequencing Library preparation kit (DNA input 1 ug, 8 PCR cycles), and sequenced in triplicate (39 samples total) on an Illumina MiSeq using 300 base paired-end reads, to generate 44–50 million raw reads per pool.
  </p>
  <p id="Par39" xmlns="http://www.w3.org/1999/xhtml">Oligotyping analysis was used
   <span class="sup">
    <a ref-type="bibr" rid="CR22" href="#CR22">22</a>
   </span> to define biofilm community composition differences in heated and non-heated settlement panels. Adapters were trimmed from the raw reads using trim_galore software (
   <span ext-link-type="uri" xlink:href="https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/" class="ext-link" xmlns:xlink="http://www.w3.org/1999/xlink">https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/</span>). Reads were merged using mothur v.1.35.1 (ref. 
   <span class="sup">
    <a ref-type="bibr" rid="CR70" href="#CR70">70</a>
   </span>), MiSeq SOP site accessed on the 18/08/17). Entropy and oligotyping analyses were conducted according to ref. 
   <span class="sup">
    <a ref-type="bibr" rid="CR21" href="#CR21">21</a>
   </span>. Sequences were not aligned to a reference alignment since length read varied due to partially overlapping reads. Hence the 
   <span class="italic">0-pad-with-gaps</span> script from the Minimum entropy decomposition (MED) pipeline 1.2 (ref. 
   <span class="sup">
    <a ref-type="bibr" rid="CR71" href="#CR71">71</a>
   </span>) was run on the reads. All analyses were carried out using default parameters unless otherwise specified. MED analysis was performed using the MED pipeline version 1.2. The minimum substantive abundance criterion (M) was set to 50 to filter noise in the data. After the initial round of oligotyping, high entropy positions were chosen (-C option). To minimise the impact of sequences errors, an oligotype was required to be represented in at least 1000 reads (-M option). Moreover, rare oligotypes present in less than five samples were discarded (-s option). These parameters led to 1,478,129 sequences left in the database. Oligotypes were searched using blastn against the ENA sequence database using NCBI Blast +via the EBI web services
   <span class="sup">
    <a ref-type="bibr" rid="CR72" href="#CR72">72</a>
   </span>. Further oligotyping analysis was performed on the rare oligotypes removed from the original analysis to look at differences in microbial diversity in the rarer species between treatments (control, +1, +2). Rare oligotypes were explored by selecting the parameter M (minimum substantive abundance) and by using the oligotype command in the pipeline to scrutinise the data. The minimum substantive abundance criterion was set to 50 (-M 50) to filter noise in the data. After the initial round of oligotyping, nucleotide positions (9, 13, 120, 122 and 130) were carefully selected to explore the rare oligotypes. Two more rounds of oligotyping were performed with the minimum substantive abundance set to 50 and by further selecting nucleotide positions (9, 13, 26, 80, 120, 122 and 130). Those rare oligotypes enriched by PCR errors did not converge. Individual oligotype sequences were searched against reference sequences in the NCBI’s nr database using BLAST
   <span class="sup">
    <a ref-type="bibr" rid="CR73" href="#CR73">73</a>
   </span>.
  </p>
 </sec>
 <sec id="Sec15" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Reporting Summary</div>
  <p id="Par40" xmlns="http://www.w3.org/1999/xhtml">Further information on research design is available in the 
   <a rid="MOESM3" ref-type="media" href="#MOESM3">Nature Research Reporting Summary</a> linked to this article.
  </p>
 </sec>
</sec>
