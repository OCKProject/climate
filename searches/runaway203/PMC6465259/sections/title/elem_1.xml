<?xml version="1.0" encoding="UTF-8"?>
<sec id="Sec2" sec-type="results" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Results</div>
 <sec id="Sec3" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">The role of reliability</div>
  <p id="Par7" xmlns="http://www.w3.org/1999/xhtml">Causal extreme event attribution relies on climate model experiments that discern the influence of an external factor (such as increased levels of greenhouse gases). These experiments simulate the possible evolutions of the climate system using an ensemble approach, i.e., generating several climate simulations under the same conditions, but with tiny initial perturbations to obtain a range of possible climate realisations. This ensemble approach allows to quantify the probability that a rare event occurs under given conditions
   <span class="sup">
    <a ref-type="bibr" rid="CR24" href="#CR24">24</a>
   </span>. In the context of attribution to climate change, two types of ensembles are required: one incorporating all observed radiative forcings (ALL, i.e., including anthropogenic greenhouse gases and aerosols in addition to natural forcings) and one counterfactual using natural forcings alone (NAT, i.e., including solar forcings and volcanic aerosols). The ensembles are carried out using coupled (ocean-atmosphere) climate models or atmosphere-only models, which are forced by observed sea–surface temperature (SST) and sea–ice concentrations
   <span class="sup">
    <a ref-type="bibr" rid="CR7" href="#CR7">7</a>
   </span>. The atmosphere-only approach has been the dominant approach up to date leading to several large data bases designed for extreme event attribution
   <span class="sup">
    <a ref-type="bibr" rid="CR21" href="#CR21">21</a>,
    <a ref-type="bibr" rid="CR23" href="#CR23">23</a>,
    <a ref-type="bibr" rid="CR24" href="#CR24">24</a>
   </span>. Both types of model approaches (coupled or atmosphere-only) simulate a nonstationary climate given that the radiative and the marine boundary forcing (in the atmosphere-only experiments) change over time. A reliable ensemble response to these forcings is fundamental as illustrated in the following example.
  </p>
  <p id="Par8" xmlns="http://www.w3.org/1999/xhtml">The example uses the case of high temperatures during Northern Hemisphere summers (June-to-August (JJA)) and warm Southern Hemisphere winters, respectively, which have been the subject of many event attribution
   <span class="sup">
    <a ref-type="bibr" rid="CR2" href="#CR2">2</a>–
    <a ref-type="bibr" rid="CR4" href="#CR4">4</a>
   </span> and physical process studies
   <span class="sup">
    <a ref-type="bibr" rid="CR25" href="#CR25">25</a>–
    <a ref-type="bibr" rid="CR27" href="#CR27">27</a>
   </span>. Figure 
   <a rid="Fig1" ref-type="fig" href="#Fig1">1a</a> shows the summer (JJA) 2-m air temperature evolution over a grid point in Sudan in an ensemble of atmosphere-only simulations from the UK Met Office quasi-operational system (HadGEM3-A
   <span class="sup">
    <a ref-type="bibr" rid="CR21" href="#CR21">21</a>
   </span>). The grid point in Sudan has been chosen to illustrate the influence of marine conditions on a continental area and to select a region that is highly vulnerable to climate variability judging from recent observations. The ensemble, including anthropogenic forcings (red) undergoes a positive-temperature trend. This trend is absent in the NAT simulations (green) and, hence, attributable to human-induced climate change. Both ensembles exhibit a pronounced interannual variability that is coherent among the ensemble members due to the impact of tropical SST forcings in this region
   <span class="sup">
    <a ref-type="bibr" rid="CR28" href="#CR28">28</a>
   </span>. Although a similar interannual signal is reflected in the observations (black lines showing two different datasets) the model ensemble range is clearly too narrow. Indeed, the observations fall outside the model ensemble range more often than if the observations could be considered an equiprobable realisation of the model ensemble. This is illustrated with a rank histogram
   <span class="sup">
    <a ref-type="bibr" rid="CR16" href="#CR16">16</a>
   </span> in Fig. 
   <a rid="Fig2" ref-type="fig" href="#Fig2">2</a> (inset in panel a). The rank histogram counts the position of the observation amongst the ranked members of the ensemble in each year. If the observation could be considered an equiprobable member of the model ensemble, the rank histogram would be perfectly flat. On the contrary, peaks stand out at the tail ends of the diagram, which illustrates that the observation falls too often outside the model range.
   <div id="Fig1" class="fig">
    <span class="label">Fig. 1</span>
    <div class="caption">
     <p>Effect of ensemble calibration on an attribution case for boreal hot summers for a grid point in Sudan (12.6°N, 34.4°W). Panels 
      <span class="bold">a</span> and 
      <span class="bold">b</span> show the observed historical evolution of summer temperatures (black, two different datasets) and the single-model ensemble of the UK quasi-operational attribution system (HadGEM3-A) considering all forcings (red) and only natural forcings (blue) as anomalies from present day climatology (1981–2010) derived from the all forcings ensemble. Panels 
      <span class="bold">c</span> and 
      <span class="bold">d</span> show the probability distribution of temperature and the associated fraction of attributable risk (FAR) due to climate change (distribution red opposed to the blue one) for a 1 in 5-year event in the NAT simulation (
      <span class="italic">x</span>
      <sub>EX</sub>)
     </p>
    </div>
    <div xlink:href="41467_2019_9729_Fig1_HTML" id="d29e427" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
   </div>
   <div id="Fig2" class="fig">
    <span class="label">Fig. 2</span>
    <div class="caption">
     <p>Reliability of event attribution experiments to simulate probabilities of high temperatures during boreal summers. The reliability measures the accuracy of simulated probabilities and a value of one denotes perfect reliability (see methods reliability assessment). Reliability is shown for 
      <span class="bold">a</span> the single-model ensemble of the UK quasi-operational attribution system (HadGEM3-A), 
      <span class="bold">b</span> the single-model system (HadGEM3-A) after the ensemble calibration, 
      <span class="bold">c</span> the multi-model event attribution system of Climate of the 20th Century Plus project (C20C+) and 
      <span class="bold">d</span> a 100-member ensemble of the weather@home project using HadCM3
      <span class="sup">
       <a ref-type="bibr" rid="CR23" href="#CR23">23</a>
      </span>. The small boxes in panels 
      <span class="bold">a</span> and 
      <span class="bold">b</span> denote the ranked histogram (counts of the position where the observations fall in the ensemble over the historical period) for the grid point denoted in panel 
      <span class="bold">a</span> over Sudan analysed in Fig. 
      <a rid="Fig1" ref-type="fig" href="#Fig1">1</a>
     </p>
    </div>
    <div xlink:href="41467_2019_9729_Fig2_HTML" id="d29e464" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
   </div>
  </p>
  <p id="Par9" xmlns="http://www.w3.org/1999/xhtml">One way to quantify this overconfidence objectively is to compute the mean squared differences between simulated probabilities and observed frequencies to exceed a threshold (in this case 1 in 5 years hot summers). This mean difference is widely known as the reliability component of the Brier score
   <span class="sup">
    <a ref-type="bibr" rid="CR16" href="#CR16">16</a>
   </span>, which is shown in Fig. 
   <a rid="Fig2" ref-type="fig" href="#Fig2">2</a> for the entire globe (shown as 1 minus the Brier score reliability component). Central Africa (see the grid point of the example indicated) reveals to be a region of general low reliability, but other areas are also affected. The lack of reliability persists even when using a set of four different atmosphere-only models from the C20C+ project
   <span class="sup">
    <a ref-type="bibr" rid="CR24" href="#CR24">24</a>
   </span> (Fig. 
   <a rid="Fig2" ref-type="fig" href="#Fig2">2</a>, panel c) or a model with large global model ensemble (100 members) used in the weather@home project (panel d)
   <span class="sup">
    <a ref-type="bibr" rid="CR23" href="#CR23">23</a>
   </span>. This suggests that a common structural deficiency of the models or the experimental design exists that prevents the problem to be overcome by the traditional multi-model or large-ensemble approaches. The result further demonstrates that the lack of reliability (overconfidence) identified in decadal-long forced SST-driven simulations
   <span class="sup">
    <a ref-type="bibr" rid="CR29" href="#CR29">29</a>
   </span> does not arise from the short simulation length, but also persists in 50-year-long simulations of the C20C+ project.
  </p>
  <p id="Par10" xmlns="http://www.w3.org/1999/xhtml">Using unreliable ensembles, i.e., those in which simulated probabilities do not match the observed frequencies, to attribute a hypothetical extreme event
   <span class="sup">
    <a ref-type="bibr" rid="CR30" href="#CR30">30</a>
   </span> has a direct consequence on attribution statements as illustrated in Fig. 
   <a rid="Fig1" ref-type="fig" href="#Fig1">1</a>. Assume a 1-in-5-year event (event probabilities estimated in the NAT simulation
   <span class="sup">
    <a ref-type="bibr" rid="CR30" href="#CR30">30</a>
   </span>, same probability as used to assess the reliability) would occur in the grid-cell selected over Sudan (black vertical line) in an arbitrary recent year (2003). In the NAT ensemble this event would be much less likely than in ALL, i.e., such an event would be almost entirely attributed to human activity. To measure the level of attribution it is common to express the fraction of attributable risk
   <span class="sup">
    <a ref-type="bibr" rid="CR10" href="#CR10">10</a>
   </span> (fraction of attributable risk (FAR) = 1 − P
   <sub>NAT</sub>/P
   <sub>ALL</sub>) or simply the risk ratio (RR = P
   <sub>ALL</sub>/P
   <sub>NAT</sub>), where P
   <sub>NAT</sub> and P
   <sub>ALL</sub> denote the probability to exceed the observed event magnitude in the NAT and ALL ensembles, respectively. Values of FAR larger than zero denote that the event is attributable to anthropogenic activity (or another external factor that is being discerned). In the example provided, FAR is almost equal to one. This means that this class of events are entirely attributable to human influence in this specific year. From visual inspection and the quantified lack of reliability, we know that the probability distributions are overly confident. The magnitude of the attributable risk is, therefore, likely overestimated and we therefore need to improve the reliability prior to the calculation of the FAR
   <span class="sup">
    <a ref-type="bibr" rid="CR12" href="#CR12">12</a>
   </span>.
  </p>
 </sec>
 <sec id="Sec4" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Calibration of climate model ensembles</div>
  <p id="Par11" xmlns="http://www.w3.org/1999/xhtml">Low reliability in ensemble simulations is a pervasive problem in weather and climate forecasting
   <span class="sup">
    <a ref-type="bibr" rid="CR31" href="#CR31">31</a>
   </span>. A range of methods referred to as ensemble calibration have therefore been proposed to overcome this deficiency
   <span class="sup">
    <a ref-type="bibr" rid="CR32" href="#CR32">32</a>–
    <a ref-type="bibr" rid="CR34" href="#CR34">34</a>
   </span>. These approaches are promising tools for the formulation of trustworthy event attribution statements, as we show in the following. Ensemble calibration corrects the model response to prevailing conditions for example as part of interannual climate variability (implicitly simulated by the model, e.g., an El Niño state) as a function of the model’s ability to simulate the response to these (technically as a function of the reliability). This implies a correction of the ensemble spread (often a widening but also a narrowing is sometimes required) and a correction of the amplitude of the ensemble mean signal that deviates from the climatological state
   <span class="sup">
    <a ref-type="bibr" rid="CR32" href="#CR32">32</a>
   </span>. In doing so, the model ensemble becomes more reliable, i.e., more trustworthy from a probabilistic point of view.
  </p>
  <p id="Par12" xmlns="http://www.w3.org/1999/xhtml">In the context of event attribution, it is fundamental that the model response to the external driver, to which we aim to establish a causal link, is retained after the calibration. This is a concern in traditional approaches since the ensemble is simultaneously calibrated for short-term and long-term variabilities
   <span class="sup">
    <a ref-type="bibr" rid="CR34" href="#CR34">34</a>–
    <a ref-type="bibr" rid="CR36" href="#CR36">36</a>
   </span>. Here, we propose a forecast calibration technique that can cope with this difficulty. The approach relies on the ensemble inflation (see Methods) and corrects the ensemble separately for near-term variations (forced for instance by interannual SST variations or volcanic eruptions) and long-term trends (forced for instance by greenhouse gas concentration changes). Note that the climate simulations analysed here all use observed SST as ocean surface boundary conditions, which prescribes low-frequency variability in the model simulations in phase with variability in the observations. Trend differences over the 50-year period would, therefore, primarily be due to different responses to anthropogenic forcing as opposed to climate variability. However, other more comprehensive approaches
   <span class="sup">
    <a ref-type="bibr" rid="CR11" href="#CR11">11</a>
   </span> would be relevant in a coupled-model setup or in presence of a highly nonlinear temporal changes in response to anthropogenic forcing. The long-term trend is only corrected for the ensemble including the anthropogenic forcings since no observations are available for a world without climate change. Also note that typical methods that correct the mean state of the simulations
   <span class="sup">
    <a ref-type="bibr" rid="CR37" href="#CR37">37</a>,
    <a ref-type="bibr" rid="CR38" href="#CR38">38</a>
   </span> (known as bias-correction methods) would not be able to correct the reliability illustrated in the example in Fig. 
   <a rid="Fig1" ref-type="fig" href="#Fig1">1</a> since the errors in the ensemble response differ from year to year
   <span class="sup">
    <a ref-type="bibr" rid="CR38" href="#CR38">38</a>
   </span>.
  </p>
  <p id="Par13" xmlns="http://www.w3.org/1999/xhtml">The impact of the forecast calibration is illustrated across all three figures (Figs. 
   <a rid="Fig1" ref-type="fig" href="#Fig1">1</a>–
   <a rid="Fig3" ref-type="fig" href="#Fig3">3</a>). In the example provided for Sudan (Fig. 
   <a rid="Fig1" ref-type="fig" href="#Fig1">1</a>), the calibration corrects both the ensemble mean and the spread (the long-term trend remains almost unaffected), which yields higher levels of reliability and greatly improves the rank histogram for the example (inset in Fig. 
   <a rid="Fig2" ref-type="fig" href="#Fig2">2</a>, panel b). A lower value of FAR is obtained as a consequence. The change of FAR on a global scale is illustrated in Fig. 
   <a rid="Fig3" ref-type="fig" href="#Fig3">3</a>. Over many regions the calibration reduces the FAR but there are also regions where FAR is underestimated by the raw model output as, e.g., Central Europe or Brazil. The overall change of FAR results from the correction of both the near-term response (ensemble correction) and the long-term change (linear trend over 50 years). The contribution from each component, as well as the impact on the risk ratio shown in the supplementary information (Supplementary Figs. 
   <a rid="MOESM1" ref-type="media" href="#MOESM1">1, 2</a>). In the example provided, correcting the near-term response particularly impacts the result over the tropics
   <span class="sup">
    <a ref-type="bibr" rid="CR29" href="#CR29">29</a>
   </span>, while correcting the response to long-term forcing most strongly affects the mid-latitudes. The supplementary information further shows consistent results when using a different physical variable and a different return-period (JJA precipitation in a 1-in-10 year event, Supplementary Fig. 
   <a rid="MOESM1" ref-type="media" href="#MOESM1">3</a>) and an application of the calibration on artificial attribution data
   <span class="sup">
    <a ref-type="bibr" rid="CR12" href="#CR12">12</a>
   </span>, which demonstrates that the calibration perfectly corrects the reliability and FAR in an idealised context (Supplementary Fig. 
   <a rid="MOESM1" ref-type="media" href="#MOESM1">4</a>).
   <div id="Fig3" class="fig">
    <span class="label">Fig. 3</span>
    <div class="caption">
     <p>Effect of the model ensemble calibration on the fraction of attributable risk (FAR) to anthropogenic forcings of boreal hot summers. The change denotes the FAR calculated after the calibration minus the FAR calculated from the raw HadGEM3-A, as illustrated in Fig. 
      <a rid="Fig1" ref-type="fig" href="#Fig1">1</a> but on a global scale. The model probabilities are estimated by fitting a Normal distribution to all ensemble members. Stippling denotes a significant change in FAR determined by resampling at a 10% significance level
     </p>
    </div>
    <div xlink:href="41467_2019_9729_Fig3_HTML" id="d29e623" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
   </div>
  </p>
  <p id="Par14" xmlns="http://www.w3.org/1999/xhtml">While the additional analysis supports the conclusions of the study, it does not claim to be exhaustive and further applications may need to test the approach for other types of events. The current proposed method is generic, since it corrects the entire model distribution, which is advantageous compared to quantile-specific calibration approaches. However, the method might for instance not be suitable to correct a highly non-linear response to anthropogenic forcing or to correct heavily skewed native model distributions, and non-parametric approaches might be useful in such cases. Also, physical deficiencies of general circulation models as for instance the correct positioning of the storm tracks are unlikely corrected by this approach and hence calibration always be complemented with an evaluation of the model’s ability to simulate the underlying physical processes
   <span class="sup">
    <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
   </span>.
  </p>
 </sec>
</sec>
