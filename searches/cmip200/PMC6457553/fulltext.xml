<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6457553</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0214535</article-id><article-id pub-id-type="publisher-id">PONE-D-18-32816</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Models</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth Sciences</subject><subj-group><subject>Seasons</subject><subj-group><subject>Summer</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Dynamical Systems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Dynamical Systems</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Climate Modeling</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth Sciences</subject><subj-group><subject>Atmospheric Science</subject><subj-group><subject>Climatology</subject><subj-group><subject>Climate Modeling</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Nonlinear Dynamics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Nonlinear Dynamics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Nonlinear Systems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems Science</subject><subj-group><subject>Nonlinear Systems</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth Sciences</subject><subj-group><subject>Seasons</subject><subj-group><subject>Winter</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Materials Science</subject><subj-group><subject>Material Properties</subject><subj-group><subject>Surface Properties</subject><subj-group><subject>Surface Temperature</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Accounting for skill in trend, variability, and autocorrelation facilitates better multi-model projections: Application to the AMOC and temperature time series</article-title><alt-title alt-title-type="running-head">Projections accounting for model trend and variability skill</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8233-9467</contrib-id><name><surname>Olson</surname><given-names>Roman</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="aff" rid="aff002"><sup>2</sup></xref><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0003-429X</contrib-id><name><surname>An</surname><given-names>Soon-Il</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Funding acquisition</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Resources</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Fan</surname><given-names>Yanan</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff004"><sup>4</sup></xref></contrib><contrib contrib-type="author"><name><surname>Evans</surname><given-names>Jason P.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff005"><sup>5</sup></xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>Department of Atmospheric Sciences, Yonsei University, Seoul, South Korea</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>Center for Climate Physics, Institute for Basic Science, Busan, South Korea</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Pusan National University, Busan, South Korea</addr-line></aff><aff id="aff004"><label>4</label>
<addr-line>School of Mathematics and Statistics, UNSW Australia, Sydney, New South Wales, Australia</addr-line></aff><aff id="aff005"><label>5</label>
<addr-line>Climate Change Research Centre and ARC Centre for Excellence in Climate Extremes, UNSW Australia, Sydney, New South Wales, Australia</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>A&#x000f1;el</surname><given-names>Juan A.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Universidade de Vigo, SPAIN</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>sian@yonsei.ac.kr</email></corresp></author-notes><pub-date pub-type="epub"><day>10</day><month>4</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>14</volume><issue>4</issue><elocation-id>e0214535</elocation-id><history><date date-type="received"><day>15</day><month>11</month><year>2018</year></date><date date-type="accepted"><day>14</day><month>3</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2019 Olson et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Olson et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0214535.pdf"/><abstract><p>We present a novel quasi-Bayesian method to weight multiple dynamical models by their skill at capturing both potentially non-linear trends and first-order autocorrelated variability of the underlying process, and to make weighted probabilistic projections. We validate the method using a suite of one-at-a-time cross-validation experiments involving Atlantic meridional overturning circulation (AMOC), its temperature-based index, as well as Korean summer mean maximum temperature. In these experiments the method tends to exhibit superior skill over a trend-only Bayesian model averaging weighting method in terms of weight assignment and probabilistic forecasts. Specifically, mean credible interval width, and mean absolute error of the projections tend to improve. We apply the method to a problem of projecting summer mean maximum temperature change over Korea by the end of the 21<sup>st</sup> century using a multi-model ensemble. Compared to the trend-only method, the new method appreciably sharpens the probability distribution function (pdf) and increases future most likely, median, and mean warming in Korea. The method is flexible, with a potential to improve forecasts in geosciences and other fields.</p></abstract><funding-group><award-group id="award001"><funding-source><institution>National research foundation of Korea</institution></funding-source><award-id>NRF-2018R1A5A1024958</award-id><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0003-429X</contrib-id><name><surname>An</surname><given-names>Soon-Il</given-names></name></principal-award-recipient></award-group><award-group id="award002"><funding-source><institution>National Research Foundation of Korea</institution></funding-source><award-id>NRF-2017K1A3A7A03087790</award-id><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0003-429X</contrib-id><name><surname>An</surname><given-names>Soon-Il</given-names></name></principal-award-recipient></award-group><funding-statement>RO and SIA were supported by Basic Science Research Program through National Research Foundation of Korea (NRF-2017K1A3A7A03087790, NRF-2018R1A5A1024958) (<ext-link ext-link-type="uri" xlink:href="http://www.nrf.re.kr/eng/main">http://www.nrf.re.kr/eng/main</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="8"/><table-count count="2"/><page-count count="24"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>The relevant data and code implementing the methodology and used to produce the results of the paper (including programs to make the figures) are available as a supplementary file S2_File.zip. Observational data used in this paper are freely available from third party websites, with details provided in the references. The Climate Model Intercomparison Project phase 5 model output is available from <ext-link ext-link-type="uri" xlink:href="https://esgf-node.llnl.gov/projects/esgf-llnl/">https://esgf-node.llnl.gov/projects/esgf-llnl/</ext-link>. Data access requires filling in a registration form at <ext-link ext-link-type="uri" xlink:href="https://esgf-node.llnl.gov/user/add/">https://esgf-node.llnl.gov/user/add/</ext-link>. The results of the cross-validation and projection experiments, including the weights, the Markov chain Monte Carlo chains, the R programming language workspaces, and the control input files are available from the <ext-link ext-link-type="uri" xlink:href="https://www.climatelab.yonsei.ac.kr/forum">https://www.climatelab.yonsei.ac.kr/forum</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>The relevant data and code implementing the methodology and used to produce the results of the paper (including programs to make the figures) are available as a supplementary file S2_File.zip. Observational data used in this paper are freely available from third party websites, with details provided in the references. The Climate Model Intercomparison Project phase 5 model output is available from <ext-link ext-link-type="uri" xlink:href="https://esgf-node.llnl.gov/projects/esgf-llnl/">https://esgf-node.llnl.gov/projects/esgf-llnl/</ext-link>. Data access requires filling in a registration form at <ext-link ext-link-type="uri" xlink:href="https://esgf-node.llnl.gov/user/add/">https://esgf-node.llnl.gov/user/add/</ext-link>. The results of the cross-validation and projection experiments, including the weights, the Markov chain Monte Carlo chains, the R programming language workspaces, and the control input files are available from the <ext-link ext-link-type="uri" xlink:href="https://www.climatelab.yonsei.ac.kr/forum">https://www.climatelab.yonsei.ac.kr/forum</ext-link>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>1 Introduction</title><p>A common forecasting problem is one of probabilistic multi-model forecasts of a stochastic dynamical system [<xref rid="pone.0214535.ref001" ref-type="bibr">1</xref>&#x02013;<xref rid="pone.0214535.ref018" ref-type="bibr">18</xref>]. Sometimes, when a collection of complex dynamical models is used to provide multi-model forecasts, these forecasts are weighted according to model performance compared to observations [<xref rid="pone.0214535.ref001" ref-type="bibr">1</xref>,<xref rid="pone.0214535.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0214535.ref010" ref-type="bibr">10</xref>,<xref rid="pone.0214535.ref019" ref-type="bibr">19</xref>&#x02013;<xref rid="pone.0214535.ref023" ref-type="bibr">23</xref>]. The Bayesian approach to this problem assumes that associated with <italic>k</italic> dynamical models are <italic>k</italic> competing statistical models <italic>M</italic><sub><italic>i</italic></sub> for vector of observations <bold><italic>y</italic></bold>. These statistical models result in a conditional probability density function (pdf) for <bold><italic>y</italic></bold> given that <italic>M</italic><sub><italic>i</italic></sub> is reasonable, <italic>p</italic>(<bold><italic>y</italic></bold>|<italic>M</italic><sub><italic>i</italic></sub>). Typically, in a multi-model evaluation context, the pdf <italic>p</italic>(<bold><italic>y</italic></bold>|<italic>M</italic><sub><italic>i</italic></sub>) is a multivariate statistical distribution centered on <italic>i</italic>th dynamical model trend <bold><italic>x</italic></bold><sub><bold><italic>i</italic></bold></sub>. Each model is associated with a prior belief in its adequacy (&#x0201c;prior&#x0201d;) <italic>p</italic>(<italic>M</italic><sub><italic>i</italic></sub>), which can be derived from previous work, or may be more subjective. The posterior probability, or weight, for each model <italic>i</italic> given the observations is then found using Bayes theorem [<xref rid="pone.0214535.ref024" ref-type="bibr">24</xref>]:
<disp-formula id="pone.0214535.e001"><alternatives><graphic xlink:href="pone.0214535.e001.jpg" id="pone.0214535.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>)</mml:mo><mml:mo>&#x0221d;</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives><label>(1)</label></disp-formula></p><p>Specifically, the posterior probability of each statistical (and corresponding dynamical) model is the likelihood of observations <bold><italic>y</italic></bold> coming from the model (given by the pdf <italic>p</italic>(<bold><italic>y</italic></bold>|<italic>M</italic><sub><italic>i</italic></sub>)), multiplied by the model prior.</p><p>In ensemble modelling, models are usually judged on how well they represent the mean state of the system, its trend, or spatio-temporal fields [<xref rid="pone.0214535.ref001" ref-type="bibr">1</xref>,<xref rid="pone.0214535.ref003" ref-type="bibr">3</xref>,<xref rid="pone.0214535.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0214535.ref014" ref-type="bibr">14</xref>,<xref rid="pone.0214535.ref022" ref-type="bibr">22</xref>,<xref rid="pone.0214535.ref023" ref-type="bibr">23</xref>]. However, it is increasingly being recognized that variability is of utmost importance for future prediction. Specifically, for some systems (stochastic dynamical systems) the stationary pdf of the equilibrium solution is directly affected by system dynamics (i.e., the nonlinear operator in the ordinary differential equations) through the Fokker-Planck (Kolmogorov forward) equation. Recent climate science work identifies variability as a key factor impacting climate projections [<xref rid="pone.0214535.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0214535.ref025" ref-type="bibr">25</xref>]. Furthermore, variability has been used as a novel and effective constraint for climate sensitivity [<xref rid="pone.0214535.ref026" ref-type="bibr">26</xref>]. In addition, variability also has major relevance for forewarning of critical thresholds (i.e., a forcing value above which the underlying system shifts to a new equilibrium; [<xref rid="pone.0214535.ref027" ref-type="bibr">27</xref>]). Specifically, an increase in variance or lag-1 autocorrelation with time, as well as skewness and kurtosis, have been used as such early warning indicators [<xref rid="pone.0214535.ref028" ref-type="bibr">28</xref>&#x02013;<xref rid="pone.0214535.ref031" ref-type="bibr">31</xref>]. This motivates using variability properties of the system as a novel metric to assess performance of multiple dynamical system models.</p><p>Several new studies break important new ground by incorporating variability into the weighting [<xref rid="pone.0214535.ref017" ref-type="bibr">17</xref>,<xref rid="pone.0214535.ref032" ref-type="bibr">32</xref>&#x02013;<xref rid="pone.0214535.ref034" ref-type="bibr">34</xref>], but they typically assume stationarity of the pdf of the system [<xref rid="pone.0214535.ref017" ref-type="bibr">17</xref>,<xref rid="pone.0214535.ref032" ref-type="bibr">32</xref>,<xref rid="pone.0214535.ref033" ref-type="bibr">33</xref>], or cannot work with complex dynamical models [<xref rid="pone.0214535.ref034" ref-type="bibr">34</xref>]. Some previous work does explicitly weight dynamical models by performance in variability and trends in a statistically-sound way [<xref rid="pone.0214535.ref035" ref-type="bibr">35</xref>]. However, the method in its current form works only for linear trends (as a function of time) and does not account for autocorrelation in the variability.</p><p>Here we propose a novel method to weight models of complex dynamical systems by their performance in autocorrelation, variability, and a potentially nonlinear trend (i.e., nonlinear with time) compared to observations, and to make probabilistic forecasts. The method is based on Bayesian Model Averaging (BMA) [<xref rid="pone.0214535.ref020" ref-type="bibr">20</xref>,<xref rid="pone.0214535.ref021" ref-type="bibr">21</xref>]. While the framework is Bayesian, it deviates from traditional Bayesian theory in some steps of the estimation process. We highlight these deviations where they arise in more detail in later sections. Consequently, we call our approach &#x0201c;quasi-Bayesian&#x0201d;. Using several simulated and observed datasets (involving AMOC, its temperature-based index, and summer mean maximum temperature over Korea) we show that the new method results in better weighting and tends to improve forecasts of system mean change under new conditions compared to when trend-only BMA weighting is used. Thus, this work has implications for improving projections of many environmental systems. The approach is not restricted to linear trends, making it relatively easy to apply to new datasets. Finally, we apply the method to a real case problem of projecting future summer mean temperature changes over Korea.</p><p>The rest of the paper is structured as follows. Section 2 describes the novel methodology to weight models by trend and variability performance, to combine those weights, to make multi-model weighted projections, as well as the computational details. The main interest here is not the procedure for obtaining the trend and variability components, but the algorithm for model weighting. In Section 3 we describe leave-one-out cross-validation experiments to test method performance against a trend-only BMA method. Here we also provide the specific details on how the trend and variability components were extracted from the data. Section 4 describes the results of these experiments. Section 5 discusses the application of the method to make multi-model probabilistic projections of Korean summer mean maximum temperature change. Section 6 briefly discusses the main findings of the study and places it in context of prior work. Section 7 discusses the limitations of the work, and Section 8 presents conclusions.</p></sec><sec sec-type="materials|methods" id="sec002"><title>2 Materials and methods</title><sec id="sec003"><title>2.1 Overview of the method</title><p>At the start of the analysis, we assume that we have a collection of dynamical model time series outputs, and that these outputs can be decomposed into long-term trend and variability components. The details of this decomposition are not critical for this study, as we focus on the statistical methodology for the weighting. The weights (or probabilities) for the two submodels are calculated separately, using the Bayesian statistical paradigm, and then combined. The combined weights can then be used to make predictions (<xref ref-type="fig" rid="pone.0214535.g001">Fig 1</xref>).</p><fig id="pone.0214535.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g001</object-id><label>Fig 1</label><caption><title>Schematic illustrating the proposed &#x0201c;trend+var&#x0201d; method.</title></caption><graphic xlink:href="pone.0214535.g001"/></fig></sec><sec id="sec004"><title>2.2 Notation and decomposition of model output</title><p>Consider that <italic>k</italic> models are available. We postulate that each dynamical model is associated with a statistical model <italic>M</italic><sub><italic>i</italic></sub> for the observations. <italic>M</italic><sub><italic>i</italic></sub> can be thought of as a statistical event, which when true indicates that <italic>i</italic>th dynamical model is a reasonable representation of real system. <italic>M</italic><sub><italic>i</italic></sub> consists of two submodels: a trend submodel <italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub> (related to the trend in the system), and a variability submodel <italic>M</italic><sub><italic>V</italic>,<italic>i</italic></sub> (modelling internal fluctuations in the system). When <italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub> is true, the <italic>i</italic>th dynamical model correctly captures the trend of the system. Likewise, when <italic>M</italic><sub><italic>V</italic>,<italic>i</italic></sub> is true, the <italic>i</italic>th dynamical model correctly captures the variability of the system. Alternatively, we can consider the model for anomalies scaled by the mean (<italic>M</italic><sub><italic>V0</italic>,<italic>i</italic></sub>). Each model produces time series output of a physical quantity during the period when observations are available (&#x0201c;calibration period&#x0201d;), as well as under new forcing conditions, usually associated with future system projections (&#x0201c;projection period&#x0201d;). We are interested in finding the probability distribution of a change of the system mean &#x00394; between a &#x0201c;projection reference period&#x0201d; (typically the same as the calibration period) and the projection period. We denote the raw calibration period model output from the <italic>i</italic>th dynamical model by vector <inline-formula id="pone.0214535.e002"><alternatives><graphic xlink:href="pone.0214535.e002.jpg" id="pone.0214535.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>'</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>'</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> where superscript &#x0201c;<italic>'</italic>&#x0201d; indicates that the output is raw (un-smoothed), and <italic>n</italic> is the length of the record. The model output is a regularly spaced time series. We consider decomposition of the form:
<disp-formula id="pone.0214535.e003"><alternatives><graphic xlink:href="pone.0214535.e003.jpg" id="pone.0214535.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x023df;</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:munder><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x023df;</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:munder></mml:math></alternatives><label>(2)</label></disp-formula></p><p>We will use the term &#x0201c;anomalies&#x0201d; to refer to the variability component of the time series. The trend <bold><italic>x</italic></bold><sub><bold><italic>i</italic></bold></sub> can be either a linear trend, or a more flexible nonlinear trend obtained, for example, from robust locally weighted regression [<xref rid="pone.0214535.ref036" ref-type="bibr">36</xref>]. We assume that this decomposition is deterministic, unique, and is performed before the start of the main analysis. We also assume that the estimate of the trend is a reasonable proxy for the true unknown trend. While it may be possible to also incorporate the uncertainty in this decomposition, we leave it to future work. The focus here is not on how to properly decompose a time series into a long-term trend and variability, but on the novel methodology for weighting by performance in both. See [<xref rid="pone.0214535.ref018" ref-type="bibr">18</xref>] for an example of use of an alternative methodology to decompose the data. The use of alternative methods for data decomposition is subject of future research. We describe the decomposition method we use for each dataset in Section 3. The same decomposition is also applied to the observed time series <bold><italic>y'</italic></bold>:
<disp-formula id="pone.0214535.e004"><alternatives><graphic xlink:href="pone.0214535.e004.jpg" id="pone.0214535.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>.</mml:mo></mml:math></alternatives><label>(3)</label></disp-formula></p><p>Another option is relative decomposition. It takes the following form:
<disp-formula id="pone.0214535.e005"><alternatives><graphic xlink:href="pone.0214535.e005.jpg" id="pone.0214535.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>&#x023df;</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:munder><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>-</mml:mo></mml:mover><mml:munder accentunder="false"><mml:mrow><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>&#x023df;</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:munder><mml:mo>,</mml:mo></mml:math></alternatives><label>(4)</label></disp-formula>
where <inline-formula id="pone.0214535.e006"><alternatives><graphic xlink:href="pone.0214535.e006.jpg" id="pone.0214535.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the deterministic sample mean of the <italic>i</italic>th dynamical model output, and <inline-formula id="pone.0214535.e007"><alternatives><graphic xlink:href="pone.0214535.e007.jpg" id="pone.0214535.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are normalized anomalies; and similarly for the observations:
<disp-formula id="pone.0214535.e008"><alternatives><graphic xlink:href="pone.0214535.e008.jpg" id="pone.0214535.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:math></alternatives><label>(5)</label></disp-formula>
where <inline-formula id="pone.0214535.e009"><alternatives><graphic xlink:href="pone.0214535.e009.jpg" id="pone.0214535.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the observed mean.</p><p>Next subsections contain the following: subsection 2.3 discusses the trend submodel weighting (which largely follows previous work), subsection 2.4 centers on the variability submodel weighting, section 2.5 discusses combining the component weights for each model, section 2.6 is dedicated to procedure for making weighted multi-model projections, and section 2.7 presents computational details on the implementation of the method.</p></sec><sec id="sec005"><title>2.3 Weighting the trend submodels</title><p>The trend submodel weighting is implemented following prior work, and full details are provided there [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>]. Essentially, this method is BMA that also considers the uncertainty due to model error, and uncertainty in statistical properties of data-model residuals. Here, we consider <italic>k</italic> competing statistical models <italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub> for raw observations <bold><italic>y&#x02019;</italic></bold>. We stress that statistical and dynamical models are conceptually related: i.e., if the statistical model <italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub> is true, it implies that the associated <italic>i</italic>th dynamical model correctly represents the trend in the system. Each <italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub> is a hierarchical statistical model that connects modelled deterministic trend from the <italic>i</italic>th model during the calibration period <bold><italic>x</italic></bold><sub><bold><italic>i</italic></bold></sub> to real system trend <bold><italic>y</italic></bold>, and then the system trend to actual observations <bold><italic>y'</italic></bold> (<xref ref-type="disp-formula" rid="pone.0214535.e010">Eq 6</xref>):
<disp-formula id="pone.0214535.e010"><alternatives><graphic xlink:href="pone.0214535.e010.jpg" id="pone.0214535.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi><mml:mi mathvariant="bold-italic">&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">D</mml:mi></mml:mrow></mml:msub><mml:mspace width="4pt"/></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">N</mml:mi><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(6)</label></disp-formula>
where <italic>f</italic><bold><italic>&#x003b5;</italic></bold><sub><bold><italic>D</italic></bold></sub> is random discrepancy (long-term model error), and <italic><bold>&#x003b5;</bold><sub><bold>NV</bold></sub></italic> is random internal variability (as well as short-term observational error).</p><p>Here we deviate somewhat from orthodox Bayesian practice. A typical Bayesian approach would assume a distributional form for the discrepancy vector <italic>f</italic><bold><italic>&#x003b5;</italic></bold><sub><bold><italic>D</italic></bold></sub>. However, because this error is likely long-term dependent, and the probability distributions for its components are not necessarily normal, finding and justifying a proper parametric model for it is non-trivial. To deal with this conundrum, we adopt an approach inspired by prior work [<xref rid="pone.0214535.ref037" ref-type="bibr">37</xref>]. We postulate that model error can be derived from inter-model trend differences. The reasoning for this implementation is as follows. Imagine a particular trend submodel <italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub> represents the &#x0201c;true&#x0201d; system. Associated with this system is trend <bold><italic>x</italic></bold><sub><bold><italic>i</italic></bold></sub> and pseudo-observations <bold><inline-formula id="pone.0214535.e011"><alternatives><graphic xlink:href="pone.0214535.e011.jpg" id="pone.0214535.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula></bold>. If only the rest of the models are available to the researcher, then the best-fit model <italic>j</italic> to these pseudo-observations is associated with trend <bold><italic>x</italic></bold><sub><bold><italic>j</italic></bold></sub>. The difference between the best model and the pseudo-observed trends is then the unscaled error of the <italic>j</italic>th model. Thus, we obtain samples for unscaled discrepancy <bold><italic>&#x003b5;</italic></bold><sub><bold><italic>D</italic></bold></sub> directly from the differences between each model&#x02019;s trend and the next-closest model trend (see [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>] for details). We acknowledge that this parameterization is simplified; model error is an emergent research topic [<xref rid="pone.0214535.ref037" ref-type="bibr">37</xref>]. We thus hope this work can galvanize more research on parametrizing model error.</p><p>The second non-orthodox idea, is related to the deterministic <italic>f</italic> factor (&#x0201c;error expansion factor&#x0201d;, <xref ref-type="disp-formula" rid="pone.0214535.e010">Eq 6</xref>). This factor is a new addition to the model presented in previous work [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>]. <italic>f</italic> is a parameter that scales <bold><italic>&#x003b5;</italic></bold><sub><bold><italic>D</italic></bold></sub> to account for potential overconfidence. The non-orthodox idea relates to the procedure for selecting <italic>f</italic>. Specifically, we do not estimate <italic>f</italic> from present-day observations as a strict Bayesian would do, but rather we select <italic>f</italic> that results in correct coverage of the 90% posterior credible intervals during cross-validation experiments (different <italic>f</italic> for each dataset). The reason for this is as follows. Using just present-day observations to estimate <italic>f</italic> may produce small <italic>f</italic> values that result in overconfident future projections. This is because models have been developed so that they match observed data. Philosophically, present-day model-data agreement may be due to overfitting, and may not be reflective of the actual amount of error in the models.</p><p>The internal variability <bold><italic>&#x003b5;</italic></bold><sub><bold><italic>NV</italic></bold></sub> (<xref ref-type="disp-formula" rid="pone.0214535.e010">Eq 6</xref>) is modelled as an AR(1) process with random parameters <bold><italic>&#x003b8;</italic></bold> = (<italic>&#x003c3;</italic>, <italic>&#x003c1;</italic>), where <italic>&#x003c3;</italic> is innovation standard deviation and <italic>&#x003c1;</italic> is autocorrelation. Following Bayes theorem, and marginalization theorem, the trend model weights are then calculated as:
<disp-formula id="pone.0214535.e012"><alternatives><graphic xlink:href="pone.0214535.e012.jpg" id="pone.0214535.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mi mathvariant="bold">'</mml:mi><mml:mo>)</mml:mo><mml:mo>&#x0221d;</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mrow><mml:mo stretchy="false">&#x0222c;</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">'</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mi>d</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mi>d</mml:mi><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(7)</label></disp-formula></p><p>Here, <italic>p</italic>(<italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub>) denotes the prior for the <italic>i</italic>th trend model, <italic>p</italic>(<bold><italic>y</italic></bold><italic>'</italic>|<bold><italic>y</italic></bold>,<bold><italic>&#x003b8;</italic></bold>, <italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub>) is the AR1 likelihood resulting from the bottom line of <xref ref-type="disp-formula" rid="pone.0214535.e010">Eq (6)</xref>, <italic>p</italic>(<bold><italic>&#x003b8;</italic></bold>) denotes the prior for the AR1 parameters, and <italic>p</italic>(<bold><italic>y</italic></bold>|<italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub>) is obtained according to the top line of <xref ref-type="disp-formula" rid="pone.0214535.e010">Eq (6)</xref> using samples from <italic>f</italic><bold><italic>&#x003b5;</italic></bold><sub><bold><italic>D</italic></bold></sub> as discussed above. Unlike the previous work [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>], here we assume uniform prior probabilities for trend models <italic>p</italic>(<italic>M</italic><sub><italic>T</italic>,<italic>i</italic></sub>). The integral is evaluated using Monte Carlo integration, which is simpler to implement than Markov chain Monte Carlo methods used in some studies [<xref rid="pone.0214535.ref002" ref-type="bibr">2</xref>]. For the relative low dimension parameter space that we deal with here, simple Monte Carlo is adequate. Additional experiments suggest the sample size we use for the Monte Carlo integration is reasonable to minimize Monte Carlo error (Text A in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). Once calculated, the weights are normalized to sum to 1 to facilitate interpretation as probabilities. We provide technical details in Text A in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>.</p></sec><sec id="sec006"><title>2.4 Weighting the variability submodels</title><p>Variability models are weighted using similar ideas to the ones used in trend weight estimation. We consider <italic>k</italic> competing statistical models for calibration period anomalies observations &#x00394;<italic><bold>y</bold></italic> = (&#x00394;<italic>y</italic><sub>1</sub>, &#x00394;<italic>y</italic><sub>2</sub>, &#x02026;, &#x00394;<italic>y</italic><sub><italic>n</italic></sub>) (see <xref ref-type="disp-formula" rid="pone.0214535.e004">Eq (3)</xref>). Each <italic>i</italic>th variability model <italic>M</italic><sub><italic>V</italic>,<italic>i</italic></sub> models the anomalies hierarchically in the following form:
<disp-formula id="pone.0214535.e013"><alternatives><graphic xlink:href="pone.0214535.e013.jpg" id="pone.0214535.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msup><mml:mo>(</mml:mo><mml:mn>9</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:maligngroup/><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(8)</label></disp-formula>
where <inline-formula id="pone.0214535.e014"><alternatives><graphic xlink:href="pone.0214535.e014.jpg" id="pone.0214535.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, are autocorrelation and innovation standard deviation of the real climate, <inline-formula id="pone.0214535.e015"><alternatives><graphic xlink:href="pone.0214535.e015.jpg" id="pone.0214535.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> are summary statistics of autocorrelation and innovation standard deviation from <italic>i</italic>th model anomalies, <italic>f</italic><bold><italic>&#x003b5;</italic></bold><sup><bold><italic>V</italic></bold></sup> is model error (where <bold><italic>&#x003b5;</italic></bold><sup><bold><italic>V</italic></bold></sup> = (<italic>&#x003b5;</italic><sub><italic>&#x003c3;</italic></sub>, <italic>&#x003b5;</italic><sub><italic>&#x003c1;</italic></sub>), and <italic>f</italic> is a deterministic scaling factor to widen the distribution to correct for potential overconfidence), and <inline-formula id="pone.0214535.e016"><alternatives><graphic xlink:href="pone.0214535.e016.jpg" id="pone.0214535.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>. The top line of <xref ref-type="disp-formula" rid="pone.0214535.e013">Eq (8)</xref> connects real system anomaly properties to model summary statistics, and the bottom line shows that observed anomalies are modelled as red noise with parameters (<italic>&#x003c3;</italic><sub><italic>y</italic></sub>, <italic>&#x003c1;</italic><sub><italic>y</italic></sub>) of the real system.</p><p>Thus, in the top line of <xref ref-type="disp-formula" rid="pone.0214535.e013">Eq (8)</xref> instead of performing full posterior sampling to obtain samples for real system autocorrelation and innovation standard deviation parameters <inline-formula id="pone.0214535.e017"><alternatives><graphic xlink:href="pone.0214535.e017.jpg" id="pone.0214535.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> we assume they are centered around summary statistics <inline-formula id="pone.0214535.e018"><alternatives><graphic xlink:href="pone.0214535.e018.jpg" id="pone.0214535.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> of <italic>i</italic>th physical model anomalies with an additive error <italic>f<bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic>. Each model&#x02019;s summary statistics are taken as the corresponding MLE estimates. Again, we refrain from assuming any parametric form for <italic><bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic>. Similar to the error for the trend model, here we also assume samples for <italic><bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic> are obtained from differences between each model MLE summary statistics <inline-formula id="pone.0214535.e019"><alternatives><graphic xlink:href="pone.0214535.e019.jpg" id="pone.0214535.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> and the next-closest model summary statistics <inline-formula id="pone.0214535.e020"><alternatives><graphic xlink:href="pone.0214535.e020.jpg" id="pone.0214535.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>. The next-closest model is found as follows: for each model <italic>i</italic> we compare the conditional likelihood of <italic>i</italic>th model anomalies given AR(1) parameters of other variability submodels <inline-formula id="pone.0214535.e021"><alternatives><graphic xlink:href="pone.0214535.e021.jpg" id="pone.0214535.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, <italic>j</italic> &#x02260; <italic>i</italic> under the AR(1) statistical model, and find a model <italic>j</italic> that maximizes this likelihood. We also add a sample of zero vector (0,0) to <italic><bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic> for computational stability. We post-multiply these samples by a scaling factor <italic>f</italic> to obtain samples for <italic>f<bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic>. <italic>f</italic> is the same parameter that is used to scale trend model discrepancy (Section 2.3).</p><p>This approach gives us only <italic>k</italic>+1 samples from <italic>f<bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic>. To obtain a larger number of samples which are well-dispersed, we add to <italic>f<bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic> realizations from an independent bivariate normal distribution with standard deviations in each dimension set to 1/5 of the original <italic>k</italic>+1 sample ranges. We use the value of 1/5 because it results in samples with a reasonably smooth density that preserve<strike>s</strike> large scale cross-correlation structure between the original <italic>k</italic>+1 samples of <italic>&#x003b5;</italic><sub><italic>&#x003c3;</italic></sub> and <italic>&#x003b5;</italic><sub><italic>&#x003c1;</italic></sub>, and provides a decent approximation to the underlying pdf for <italic>f<bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic> (Fig A in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). Sensitivity tests indicate that using lower standard deviations can degrade the smoothness of the pdf (not shown).</p><p>Then, the posterior probability of the variability model <italic>i</italic> is, using Bayes rule [<xref rid="pone.0214535.ref024" ref-type="bibr">24</xref>] and probability rules:
<disp-formula id="pone.0214535.e022"><alternatives><graphic xlink:href="pone.0214535.e022.jpg" id="pone.0214535.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi mathvariant="bold-italic">d</mml:mi><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>&#x0221d;</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mrow><mml:mo stretchy="false">&#x0222b;</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi mathvariant="bold-italic">d</mml:mi><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives><label>(9)</label></disp-formula>
where <inline-formula id="pone.0214535.e023"><alternatives><graphic xlink:href="pone.0214535.e023.jpg" id="pone.0214535.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> is an AR1 likelihood function, <inline-formula id="pone.0214535.e024"><alternatives><graphic xlink:href="pone.0214535.e024.jpg" id="pone.0214535.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> is sampled using the top line of <xref ref-type="disp-formula" rid="pone.0214535.e013">Eq (8)</xref> using bootstrapping from <italic>f<bold>&#x003b5;</bold><sup><bold>V</bold></sup></italic> as described above, and <italic>p</italic>(<italic>M</italic><sub><italic>V</italic>,<italic>i</italic></sub>) is the prior probability (&#x0201c;prior&#x0201d;) for the <italic>i</italic>th variability submodel. We assume equal priors for all submodels. This integral is also evaluated using Monte Carlo integration. Specifically, we sample from the conditional pdf of real system summary statistics given each variability model <inline-formula id="pone.0214535.e025"><alternatives><graphic xlink:href="pone.0214535.e025.jpg" id="pone.0214535.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> as described above, and for each sample we calculate the conditional likelihood for the observed anomalies <inline-formula id="pone.0214535.e026"><alternatives><graphic xlink:href="pone.0214535.e026.jpg" id="pone.0214535.e026g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M26"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>. The integral is approximated as a simple mean of the conditional likelihoods across the samples. Probabilities are calculated for each submodel and are normalized to sum up to 1. The implementation using relative variability <italic>M</italic><sub><italic>V0</italic></sub> is identical except the residuals <bold><italic>&#x00394;x</italic></bold><sub><bold><italic>i</italic></bold></sub> and <bold><italic>&#x00394;y</italic></bold> are normalized by the respective model and observational means prior to the analysis. We provide technical details on the implementation in Text B in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>.</p></sec><sec id="sec007"><title>2.5 Combined weights and Bayesian model averaging</title><p>In the next step, the weights for the two submodels are put together to form a single combined model weight. Using probability laws:
<disp-formula id="pone.0214535.e027"><alternatives><graphic xlink:href="pone.0214535.e027.jpg" id="pone.0214535.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:math></alternatives><label>(10)</label></disp-formula></p><p>We make two simplifying assumptions. First, we observe that in the datasets described in Section 3 typically the relationships between the variability summary statistics <inline-formula id="pone.0214535.e028"><alternatives><graphic xlink:href="pone.0214535.e028.jpg" id="pone.0214535.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pone.0214535.e029"><alternatives><graphic xlink:href="pone.0214535.e029.jpg" id="pone.0214535.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> on one hand, and trend model probability on the other hand, appear to be weak (Figs B-K in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). In addition, the corresponding linear coefficients are almost always weak (weak is defined as the absolute values less than 0.5). Assuming that the relationships based on the sample summary statistics are a good proxy for those based on the population properties, we make an assumption that the probability of the trend model is independent of the variability model:
<disp-formula id="pone.0214535.e030"><alternatives><graphic xlink:href="pone.0214535.e030.jpg" id="pone.0214535.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&#x02248;</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">'</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:math></alternatives><label>(11)</label></disp-formula>
which allows us to directly plug in trend model weights obtained using the method in Section 2.3. Second, since only anomalies are used to weight the variability model:
<disp-formula id="pone.0214535.e031"><alternatives><graphic xlink:href="pone.0214535.e031.jpg" id="pone.0214535.e031g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M31"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mspace width="4pt"/><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:math></alternatives><label>(12)</label></disp-formula></p><p>This quantity is obtained following Section 2.4. As a result, the combined weights can be expressed as a product of the trend and variability submodel weights:
<disp-formula id="pone.0214535.e032"><alternatives><graphic xlink:href="pone.0214535.e032.jpg" id="pone.0214535.e032g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M32"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="bold-italic">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:math></alternatives><label>(13)</label></disp-formula></p><p>We stress that even though the independence assumption generally appears reasonable here<strike>,</strike> it may not always apply. Hence, it is recommended to check it when applying the methodology to new datasets. Incorporating the potential dependence between the trend and variability submodels into our framework is the subject of future research. Once calculated, the probabilities are normalized to sum up to 1, meaning that we restrict our probability space to the union of available models <italic>M</italic><sub><italic>i</italic></sub>.</p></sec><sec id="sec008"><title>2.6 Future Projections</title><p>Future model projections are implemented largely following previous work [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>]. Once the weights are obtained, the statistical model for system change between projection reference and projection periods &#x00394; follows the BMA formula [<xref rid="pone.0214535.ref020" ref-type="bibr">20</xref>,<xref rid="pone.0214535.ref021" ref-type="bibr">21</xref>]:
<disp-formula id="pone.0214535.e033"><alternatives><graphic xlink:href="pone.0214535.e033.jpg" id="pone.0214535.e033g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M33"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">&#x00394;</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">&#x00394;</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(14)</label></disp-formula>
where <italic>D</italic> = (<bold><italic>y</italic></bold>, <bold><italic>&#x00394;y</italic></bold>) is collection of all available observations, <italic>p</italic>(&#x00394;|<italic>M</italic><sub><italic>i</italic></sub>, <italic>D</italic>) is conditional probability for the change given than <italic>i</italic>th dynamical model is correct, and <italic>w</italic><sub><italic>i</italic></sub> = <italic>p</italic>(<italic>M</italic><sub><italic>i</italic></sub>|<italic>D</italic>) is the probability for the <italic>i</italic>th model (i.e., model weight) found earlier (<xref ref-type="disp-formula" rid="pone.0214535.e032">Eq (13)</xref>) as the product of the trend and variability model probabilities. This represents a skill-weighted mixture of pdfs from individual models. Here we consider &#x00394; to be a simple difference between projection period mean and forecast reference period mean. Future predictions are largely modelled following prior work [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>]. Just as for the calibration period, we assume a deterministic decomposition of projection period output into trend and anomalies:
<disp-formula id="pone.0214535.e034"><alternatives><graphic xlink:href="pone.0214535.e034.jpg" id="pone.0214535.e034g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M34"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:munder><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:munder accentunder="false"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>&#x023df;</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:munder></mml:math></alternatives><label>(15)</label></disp-formula></p><p>The exact decomposition method for each dataset is listed in Section 3. Next, we consider the following statistical model for dynamical system time-series projections (all quantities are vectors):
<disp-formula id="pone.0214535.e035"><alternatives><graphic xlink:href="pone.0214535.e035.jpg" id="pone.0214535.e035g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M35"><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">'</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:math></alternatives><label>(16)</label></disp-formula>
where <bold>y</bold><italic>'</italic><sup>(<bold><italic>f</italic></bold>)</sup> is the projection time series, <inline-formula id="pone.0214535.e036"><alternatives><graphic xlink:href="pone.0214535.e036.jpg" id="pone.0214535.e036g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M36"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is <italic>i</italic>th model trend output from <xref ref-type="disp-formula" rid="pone.0214535.e034">Eq (15)</xref>, <bold><italic>b</italic></bold><sup>(<bold><italic>f</italic>)</bold></sup> = <italic>b</italic><sup>(<bold><italic>f</italic></bold>)</sup><bold>1</bold> is random time-constant bias, and <inline-formula id="pone.0214535.e037"><alternatives><graphic xlink:href="pone.0214535.e037.jpg" id="pone.0214535.e037g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M37"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is random short-term internal variability in each model. Thus, we assume fthat if <italic>i</italic>th model is correct, the vector projection is the sum of <italic>i</italic>th model trend, a time constant bias, and internal variability. Here we again deviate somewhat from the traditional Bayesian theory in that the components of this model are partially informed by inter-model differences, and by model output during cross-validation experiments. Such steps are necessitated by the absence of actual system observations over the projection period to inform us about these components. We model the bias parameter as <inline-formula id="pone.0214535.e038"><alternatives><graphic xlink:href="pone.0214535.e038.jpg" id="pone.0214535.e038g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M38"><mml:msubsup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mi>f</mml:mi><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> where <inline-formula id="pone.0214535.e039"><alternatives><graphic xlink:href="pone.0214535.e039.jpg" id="pone.0214535.e039g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M39"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is sample standard deviation of future period-mean next-closest model differences (where next-best is used in the <italic>l</italic><sub><italic>1</italic></sub> distance sense), and <italic>f</italic> is the deterministic model error expansion factor (the same factor that is used for model weighting). Two different formulations are implemented for internal variability. In the first formulation (&#x0201c;boot&#x0201d;; [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>]) we use simple bootstrapping from <inline-formula id="pone.0214535.e040"><alternatives><graphic xlink:href="pone.0214535.e040.jpg" id="pone.0214535.e040g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M40"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">&#x00394;</mml:mi><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> to generate internal variability samples. In the alternative formulation (&#x0201c;ar1&#x0201d;) we sample <inline-formula id="pone.0214535.e041"><alternatives><graphic xlink:href="pone.0214535.e041.jpg" id="pone.0214535.e041g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M41"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b5;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> as a red noise process with parameters <inline-formula id="pone.0214535.e042"><alternatives><graphic xlink:href="pone.0214535.e042.jpg" id="pone.0214535.e042g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M42"><mml:msubsup><mml:mrow><mml:mi mathvariant="bold-italic">&#x003b8;</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, the sample innovation standard deviation and autocorrelation of future anomalies. An improvement would be to consider the uncertainty in the AR1 parameters; we do not do this here to simplify the method. To obtain projection period mean changes from the reference period, we take weighted samples of future projections using Eqs (<xref ref-type="disp-formula" rid="pone.0214535.e033">14</xref>) and (<xref ref-type="disp-formula" rid="pone.0214535.e035">16</xref>), and simply subtract projection reference period mean modeled value for each model. As in previous work [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>], we use 100,000 samples for all experiments.</p><p>The overall algorithm for the method is illustrated in <xref ref-type="fig" rid="pone.0214535.g002">Fig 2</xref>. The method estimates model weights from calibration period observations, and has one fixed parameter <italic>f</italic>, quantifying model error. Larger <italic>f</italic> values lead to higher model errors, and as a result broader projections with higher coverage of the 90% posterior credible intervals. Unlike standard Bayesian analysis, we first choose <italic>f</italic> to obtain approximately correct empirical coverage of the 90% posterior credible intervals during cross-validation. For the cross-validation, each model is selected as the &#x0201c;truth&#x0201d; one-at-a-time. Models are weighted using the output from the &#x0201c;true&#x0201d; model. The &#x0201c;true&#x0201d; model is then excluded from the model set, and the future weighted projections from the remaining models are compared to the output from the &#x0201c;true&#x0201d; model. Once <italic>f</italic> achieves approximately correct empirical coverage, the method is used for actual projections constrained by real observations. If there are many replicates (or regions) of the system, cross-validation can also be performed by splitting the calibration period into two subperiods. In step 1, observations during the first subperiod in each region/replicate can be used to assign replicate/region-specific weights. In step 2, observations during the second subperiod can test the empirical coverage of the posterior credible intervals. Here, however, we focus on the one-at-a-time cross-validation using future model output. This is because (i) the length of historical record for which high-quality observations are available is too short for most of the experiments [<xref rid="pone.0214535.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0214535.ref039" ref-type="bibr">39</xref>], (ii) observational records suffer from observational errors, and (iii) climate signal (e.g., the magnitude of climate changes) is quite low in the historical period. We choose various variables and periods to test the method under different conditions.</p><fig id="pone.0214535.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g002</object-id><label>Fig 2</label><caption><title>&#x0201c;trend+var&#x0201d; algorithm.</title></caption><graphic xlink:href="pone.0214535.g002"/></fig></sec><sec id="sec009"><title>2.7. Computational details</title><p>All experiments have been performed on an Intel Xeon CPU X5650 @ 2.67GHz GNU/Linux 2.6.18-164.el5 supercomputer, using R programming language version 3.3.3. For other required packages the following versions were used: mblm 0.12 and KernSmooth 2.23&#x02013;15. We provide the R code as <xref ref-type="supplementary-material" rid="pone.0214535.s002">S2 File</xref>. This code is provided under the GNU general public license v3.</p><p>In the next section we describe several cross-validation experiments for our method and compare the performance of the method (which we call hereafter &#x0201c;trend+var&#x0201d;) with a BMA method where all variability submodel weights are set to equal (termed hereafter &#x0201c;trend&#x0201d;). Note that &#x0201c;trend&#x0201d; method is BMA which still weights models by their performance in terms of trend.</p></sec></sec><sec id="sec010"><title>3 Leave-one-out cross-validation experiments to test method skill</title><sec id="sec011"><title>3.1 Overview of leave-one-out cross-validation experiments</title><p>To evaluate method performance, we carry out leave-one-out cross-validation experiments with several simulated and observed datasets: (i) Atlantic meridional overturning circulation (AMOC) strength [Sv] from 13 global climate models (GCMs) (AMOC experiment), (ii) Korean summer mean maximum temperatures from 29 GCMs (Korea_temp), (iii) Korean temperatures with an extended calibration period (Korea_temp_long), (iv) winter East Sea surface temperatures (SSTs) (Winter SST Experiment), (v) temperature-based AMOC Index (temperature in northern North Atlantic &#x0201c;gyre&#x0201d; minus Northern Hemisphere temperature) from 13 GCMs (AMOCIndex), and (vi) the same as (v) but also considering information from climate observations (AMOCIndex_obs). We discuss each experiment in greater detail in the following subsections. The cases differ in terms of the calibration, projection, and projection reference periods (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>). In experiments involving model output only, each of the models is selected as &#x0201c;truth&#x0201d; one at time, and its output is used to weight the models. Then, during the validation period, the projected pdfs of changes using the remaining models are compared to the &#x0201c;true&#x0201d; model output. The set-up for the AMOCIndex_obs is slightly different: both calibration and validation periods have available instrumental observations. Here, instead of selecting each model output as pseudo-observations one-at-a-time, we simply use actual observations to both weight the climate models, and to evaluate the projections. All experiments are performed with both &#x0201c;trend&#x0201d; and &#x0201c;trend+var&#x0201d; methods. Both methods have been calibrated for each experiment to have approximately correct coverage (correct % of cases where the &#x0201c;truth&#x0201d; is outside the 90% posterior credible intervals) by adjusting the model error expansion factor <italic>f</italic> (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>). The calibrated values of <italic>f</italic> for the AMOCIndex experiments are also used for the corresponding AMOCIndex_obs experiments. We focus on the Winter_SST experiment here, however summary results for all experiments are also provided.</p><table-wrap id="pone.0214535.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.t001</object-id><label>Table 1</label><caption><title>Basic information about the design of leave-one-out cross-validation experiments, and the method performance.</title><p><bold>Bold font</bold> indicates improvement of the &#x0201c;trend+var&#x0201d; method, compared to the &#x0201c;trend&#x0201d; method. <italic>k</italic> is the number of models in the ensemble; MCIW is mean 90% credible interval width; MAE is mean absolute bias of the mean; CIW is 90% credible interval width; AB is absolute bias of the mean.</p></caption><alternatives><graphic id="pone.0214535.t001g" xlink:href="pone.0214535.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Experiment</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">k</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Calibration Period</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Projection Reference Period</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Projection Period</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Trend f</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Trend+Var f</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Metric</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Trend</th><th align="left" style="background-color:#FFFF00" rowspan="1" colspan="1">Trend+Var</th></tr></thead><tbody><tr><td align="left" rowspan="2" colspan="1">AMOC</td><td align="left" rowspan="2" colspan="1">13</td><td align="left" rowspan="2" colspan="1">1880&#x02013;2004</td><td align="left" rowspan="2" colspan="1">1960&#x02013;1999</td><td align="left" rowspan="2" colspan="1">2060&#x02013;2099</td><td align="char" char="." rowspan="2" colspan="1">1.5</td><td align="char" char="." rowspan="2" colspan="1">1.5</td><td align="left" rowspan="1" colspan="1">MCIW</td><td align="left" rowspan="1" colspan="1">9.53 Sv</td><td align="left" rowspan="1" colspan="1"><bold>9.46 Sv</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">MAB</td><td align="left" rowspan="1" colspan="1">2.30 Sv</td><td align="left" rowspan="1" colspan="1"><bold>2.06 Sv</bold></td></tr><tr><td align="left" rowspan="2" colspan="1">Korea_temp</td><td align="left" rowspan="2" colspan="1">29</td><td align="left" rowspan="2" colspan="1">1973&#x02013;2005</td><td align="left" rowspan="2" colspan="1">1973&#x02013;2005</td><td align="left" rowspan="2" colspan="1">2081&#x02013;2100</td><td align="char" char="." rowspan="2" colspan="1">1.55</td><td align="char" char="." rowspan="2" colspan="1">0.75</td><td align="left" rowspan="1" colspan="1">MCIW</td><td align="left" rowspan="1" colspan="1">4.34 K</td><td align="left" rowspan="1" colspan="1"><bold>3.23 K</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">MAB</td><td align="left" rowspan="1" colspan="1">1.01 K</td><td align="left" rowspan="1" colspan="1"><bold>0.88 K</bold></td></tr><tr><td align="left" rowspan="2" colspan="1">Korea_temp_long</td><td align="left" rowspan="2" colspan="1">29</td><td align="left" rowspan="2" colspan="1">1950&#x02013;2005</td><td align="left" rowspan="2" colspan="1">1950&#x02013;2005</td><td align="left" rowspan="2" colspan="1">2081&#x02013;2100</td><td align="char" char="." rowspan="2" colspan="1">2.22</td><td align="char" char="." rowspan="2" colspan="1">2.3</td><td align="left" rowspan="1" colspan="1">MCIW</td><td align="left" rowspan="1" colspan="1">4.28 K</td><td align="left" rowspan="1" colspan="1"><bold>3.60 K</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">MAB</td><td align="left" rowspan="1" colspan="1">0.96 K</td><td align="left" rowspan="1" colspan="1"><bold>0.79 K</bold></td></tr><tr><td align="left" rowspan="2" colspan="1">Winter_SST</td><td align="left" rowspan="2" colspan="1">26</td><td align="left" rowspan="2" colspan="1">1941&#x02013;2000</td><td align="left" rowspan="2" colspan="1">1941&#x02013;2000</td><td align="left" rowspan="2" colspan="1">2061&#x02013;2000</td><td align="char" char="." rowspan="2" colspan="1">2.5</td><td align="char" char="." rowspan="2" colspan="1">2.05</td><td align="left" rowspan="1" colspan="1">MCIW</td><td align="left" rowspan="1" colspan="1">3.40 K</td><td align="left" rowspan="1" colspan="1"><bold>2.90 K</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">MAB</td><td align="left" rowspan="1" colspan="1">0.86 K</td><td align="left" rowspan="1" colspan="1"><bold>0.78 K</bold></td></tr><tr><td align="left" rowspan="2" colspan="1">AMOCIndex</td><td align="left" rowspan="2" colspan="1">13</td><td align="left" rowspan="2" colspan="1">1880&#x02013;1945</td><td align="left" rowspan="2" colspan="1">1880&#x02013;1945</td><td align="left" rowspan="2" colspan="1">1965&#x02013;2004</td><td align="char" char="." rowspan="2" colspan="1">3.75</td><td align="char" char="." rowspan="2" colspan="1">3.75</td><td align="left" rowspan="1" colspan="1">MCIW</td><td align="left" rowspan="1" colspan="1">1.42 K</td><td align="left" rowspan="1" colspan="1">1.44 K</td></tr><tr><td align="left" rowspan="1" colspan="1">MAB</td><td align="left" rowspan="1" colspan="1">0.23 K</td><td align="left" rowspan="1" colspan="1">0.23 K</td></tr><tr><td align="left" rowspan="2" colspan="1">AMOCIndex_obs</td><td align="left" rowspan="2" colspan="1">13</td><td align="left" rowspan="2" colspan="1">1880&#x02013;1945</td><td align="left" rowspan="2" colspan="1">1880&#x02013;1945</td><td align="left" rowspan="2" colspan="1">1965&#x02013;2004</td><td align="char" char="." rowspan="2" colspan="1">3.75</td><td align="char" char="." rowspan="2" colspan="1">3.75</td><td align="left" rowspan="1" colspan="1">CIW</td><td align="left" rowspan="1" colspan="1">1.42 K</td><td align="left" rowspan="1" colspan="1">1.43 K</td></tr><tr><td align="left" rowspan="1" colspan="1">AB</td><td align="left" rowspan="1" colspan="1">0.42 K</td><td align="left" rowspan="1" colspan="1"><bold>0.41 K</bold></td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec012"><title>3.2 AMOC experiment</title><p>For the AMOC experiment (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>), data extraction and processing largely follow previous work [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>]. The Climate Model Intercomparison Project phase 5 (CMIP5; [<xref rid="pone.0214535.ref040" ref-type="bibr">40</xref>]) model output for this (and other) experiments has been obtained from the ESGF LLNL portal [<xref rid="pone.0214535.ref041" ref-type="bibr">41</xref>]. Future forecasts use the RCP8.5 emissions scenario [<xref rid="pone.0214535.ref042" ref-type="bibr">42</xref>]. We use robust locally-weighted &#x0201c;lowess&#x0201d; regression [<xref rid="pone.0214535.ref036" ref-type="bibr">36</xref>] to obtain the trend model component during the calibration period, and Theil-Sen slopes [<xref rid="pone.0214535.ref043" ref-type="bibr">43</xref>]&#x02013;in the validation period. We set the &#x0201c;lowess&#x0201d; smoother span parameter to 0.8 during the smoothing. We use this span value because it appears effective at removing interdecadal variability. The smoothed model output is illustrated in <xref ref-type="fig" rid="pone.0214535.g003">Fig 3</xref>. Importantly, we see nonlinearities in the modeled trends. Previous variability weighting work does not account for such nonlinearities [<xref rid="pone.0214535.ref035" ref-type="bibr">35</xref>]. During the trend weighting we use smoothed output as anomalies with respect to the entire calibration period. We use normalized (by the absolute AMOC) anomalies to weight the variability models. Future projections use the &#x0201c;boot&#x0201d; variant of the method.</p><fig id="pone.0214535.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g003</object-id><label>Fig 3</label><caption><title>AMOC anomaly trends for the calibration period [Sv], as simulated by the CMIP5 climate models.</title></caption><graphic xlink:href="pone.0214535.g003"/></fig></sec><sec id="sec013"><title>3.3 Korea_temp and Korea_temp_long experiments</title><p>Korea_temp and Korea_temp_long differ only in the calibration periods and the error expansion factors <italic>f</italic>, with Korea_temp_long using a longer calibration period. These experiments use output from historical and future RCP8.5 runs of 29 CMIP5 model runs (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>, Table A in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). First, Korean daily maximum temperatures are calculated as spatial averages over land grid cells (cells with more than 80% land) between 34&#x02013;40&#x000b0;N and 125&#x02013;130&#x000b0;E [<xref rid="pone.0214535.ref038" ref-type="bibr">38</xref>]. The JJA (June, July, August) means are then obtained for each year. Theil-Sen slopes are used for obtaining model trends during the model output decomposition. During the weighting, smoothed output is used as anomalies with respect to the entire calibration period. Future projections use the &#x0201c;boot&#x0201d; variant of the method. Note that the Korea_temp &#x0201c;trend+var&#x0201d; experiment has a slightly elevated coverage of 93%. Decreasing <italic>f</italic> to obtain approximately 90% coverage is expected to improve performance metrics, but also to make probability densities too discontinuous. Hence, we use the value of <italic>f</italic> = 0.75.</p></sec><sec id="sec014"><title>3.4 Winter_SST experiment</title><p>Winter_SST experiment uses winter sea surface temperatures from the East Sea from historical and future RCP8.5 runs of 26 CMIP5 climate models (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>, Table B in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). We select this dataset because we find considerable relationships between present-day internal variability properties and future SST change in this region and season (<xref ref-type="fig" rid="pone.0214535.g004">Fig 4</xref>; for model number corresponding to each model see Fig L in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). We define the East Sea as the area between 35 &#x000b0;N and 42&#x000b0;N, and between 130 &#x000b0;E and 139 &#x000b0;E. We use a simple average of all ocean points in this region. During the weighting we use the output as anomalies with respect to the calibration period. Furthermore, we use Theil-Sen slopes to obtain model output trends. Future projections use the &#x0201c;ar1&#x0201d; variant of the method, since we detect a considerable autocorrelation in the model output anomalies.</p><fig id="pone.0214535.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g004</object-id><label>Fig 4</label><caption><title>Relationship between sample innovation standard deviations <inline-formula id="pone.0214535.e043"><alternatives><graphic id="pone.0214535.e043g" xlink:href="pone.0214535.e043"/><mml:math id="M43"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="4pt"/></mml:math></alternatives></inline-formula>(normalized in the AMOC experiment) and sample lag-1 autocorrelations of model anomalies during the calibration <inline-formula id="pone.0214535.e044"><alternatives><graphic id="pone.0214535.e044g" xlink:href="pone.0214535.e044"/><mml:math id="M44"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> for each model, and projected changes (projected mean minus reference period mean) for the experiments using simulated data.</title></caption><graphic xlink:href="pone.0214535.g004"/></fig></sec><sec id="sec015"><title>3.5 AMOCIndex experiment</title><p>AMOCIndex experiment (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>) relies on historical output from the same 13 CMIP5 models used for the AMOC experiment. AMOC Index is defined as sea surface temperature in northern North Atlantic &#x0201c;gyre&#x0201d; minus Northern Hemisphere temperature. It is physically linked to northward heat transport by the AMOC, and hence can be used as a proxy for AMOC [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>,<xref rid="pone.0214535.ref044" ref-type="bibr">44</xref>]. Data extraction and processing follow [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>], with a few changes. The Index is used as an anomaly with respect to the entire historical period 1880&#x02013;2004. We then use a portion of the historical period (1880&#x02013;1945) for calibration, and another portion (1965&#x02013;2004) for projections. Smoothing is performed using Theil-Sen slopes. Projections use the &#x0201c;ar1&#x0201d; variant of the method.</p></sec><sec id="sec016"><title>3.6 AMOCIndex_obs experiment</title><p>For the AMOCIndex_obs we use actual observations both to weight the models, and to validate the probabilistic projections. Otherwise, the experiment relies on the same model output as AMOCIndex experiment. The observations are a simple average of two AMOC Index versions: one calculated with ERSSTv4 SSTs [<xref rid="pone.0214535.ref045" ref-type="bibr">45</xref>&#x02013;<xref rid="pone.0214535.ref047" ref-type="bibr">47</xref>], and one with COBE-SST2 SSTs [<xref rid="pone.0214535.ref048" ref-type="bibr">48</xref>]. ERSSTv4 data is publicly curated by National Oceanic and Atmospheric Administration [<xref rid="pone.0214535.ref049" ref-type="bibr">49</xref>], while COBE-SST2 observations are provided by M. Ishii on the servers of Hokkaido University, Japan [<xref rid="pone.0214535.ref050" ref-type="bibr">50</xref>]. Both versions use GISTEMP Northern Hemisphere temperatures [<xref rid="pone.0214535.ref051" ref-type="bibr">51</xref>]. GISTEMP observations are maintained by NASA Goddard Institute for Space Studies [<xref rid="pone.0214535.ref052" ref-type="bibr">52</xref>]. For comparison with model output the COBE-SST2 SSTs are first interpolated to a 2&#x000d7;2&#x000b0; grid using bilinear interpolation, while the ERSSTv4 observations are already on such a grid. For both &#x0201c;trend&#x0201d; and &#x0201c;trend+var&#x0201d; experiments, <italic>f</italic> is taken from corresponding AMOCIndex experiments.</p></sec></sec><sec id="sec017"><title>4 Results of leave-one-out cross-validation experiments</title><p>The new method tends to be better able to correctly identify the &#x0201c;true&#x0201d; model from pseudo-observations (<xref ref-type="fig" rid="pone.0214535.g005">Fig 5</xref>, Fig M in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). This is not surprising since it uses extra variability information that is not available to the &#x0201c;trend&#x0201d; method. This extra information can provide a powerful constraint because models differ considerably in their representation of internal variability, based on sample estimates of the variability properties (<xref ref-type="fig" rid="pone.0214535.g004">Fig 4</xref>). The most striking improvement is obtained for the AMOC experiment while arguably the least improvement&#x02013;for the AMOCIndex (Fig M in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>).</p><fig id="pone.0214535.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g005</object-id><label>Fig 5</label><caption><title>Model weights for Winter_SST cross-validation experiments.</title><p>Rows represent different &#x0201c;true&#x0201d; models. Color represents model weight.</p></caption><graphic xlink:href="pone.0214535.g005"/></fig><p>Another important metric is the factor <italic>f</italic> that provides calibrated projections. This factor can be interpreted as a rough measure of model error relative to the next-closest inter-model differences in output space. The values feature a substantial range from 0.75 to 3.75 (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>). For experiments AMOC, AMOCIndex, and Korea_temp_long, <italic>f</italic> is the same or similar for both methods. Thus, under our statistical model, the best dynamical models for both &#x0201c;trend&#x0201d; and &#x0201c;trend+var&#x0201d; experiments are approximately equally close to the &#x0201c;true&#x0201d; unobserved trends in the real system, in both calibration and projection periods. However, for the rest of the simulated data experiments the new method achieves a lower <italic>f</italic>. Here, the best model for the &#x0201c;trend+var&#x0201d; method is closer (more than twice as close for Korea_temp) to the &#x0201c;true&#x0201d; trend of the system, compared to the best model under the &#x0201c;trend&#x0201d; experiment, both in calibration <italic>and</italic> projection periods.</p><p>We now turn our attention to the question of future prediction. First, it is worth noting that we do not find a significant bias between projections and &#x0201c;true&#x0201d; model output in any of our leave-one-out cross-validation experiments. The new method tends to improve in terms of the mean 90% credible interval width as well as mean absolute bias of the mean (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>, Figs <xref ref-type="fig" rid="pone.0214535.g006">6</xref> and <xref ref-type="fig" rid="pone.0214535.g007">7</xref>, Figs N-Q in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). Specifically, in the Korea_temp experiments, the forecast 90% credible intervals on average sharpen by about 25%. For some cases (e.g., models 3 and 22 of the Korea_temp experiment), the improvements are particularly dramatic, featuring a drastic sharpening of the pdf and a strong reduction in the 90% credible intervals, with a low bias; Figs P and Q in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). The only cases with no improvement are AMOCIndex, and corresponding AMOCIndex_obs (<xref rid="pone.0214535.t001" ref-type="table">Table 1</xref>). We note that these experiments rely on the same model output. They also use a weaker historical climate forcing during the projection period, whereas other experiments use stronger RCP8.5 future forcing. It is worthwhile noting that the experiments with the improvement boast a visual relationship between sample estimates of variability properties and future changes (<xref ref-type="fig" rid="pone.0214535.g004">Fig 4</xref>). Specifically, models with higher innovation standard deviation tend to produce higher summer mean maximum temperature warming in the Korean temperature experiments. A positive relationship between standard deviation and future temperature change has been previously found in previous work for many regions [<xref rid="pone.0214535.ref006" ref-type="bibr">6</xref>]. The relationships for the AMOC experiment are different: future AMOC slowdown appears to be stronger for models with higher autocorrelation and low normalized innovation standard deviation. In the Winter_SST experiment, the relationships also involve both variability properties: higher <inline-formula id="pone.0214535.e045"><alternatives><graphic xlink:href="pone.0214535.e045.jpg" id="pone.0214535.e045g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M45"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and low <inline-formula id="pone.0214535.e046"><alternatives><graphic xlink:href="pone.0214535.e046.jpg" id="pone.0214535.e046g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M46"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>&#x003c1;</mml:mi></mml:mrow><mml:mo>&#x002c7;</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> in the models are associated with smallest future warming. Thus, we speculate that the degree of improvement may be related to the strength of statistical relationships between the variability parameters and future change. Testing this hypothesis is left to future work. There can be considerable shifts in the pdf between the &#x0201c;trend&#x0201d; and &#x0201c;trend+var&#x0201d; method (Figs N-Q in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). This is consistent with the fact that additional fluctuation data can provide a relatively independent constraint on the model weights.</p><fig id="pone.0214535.g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g006</object-id><label>Fig 6</label><caption><title>Probabilistic projections for winter East Sea surface temperature change from 1941&#x02013;2000 to 2061&#x02013;2100 [K] under the RCP8.5 emissions scenario for the &#x0201c;trend only&#x0201d; Winter_SST cross-validation experiment.</title><p>Subplots differ in the assumed &#x0201c;true&#x0201d; model. Red circles are deterministic projections from each remaining model, red dotted lines are 90% posterior credible intervals. Black lines are changes from the &#x0201c;true&#x0201d; models.</p></caption><graphic xlink:href="pone.0214535.g006"/></fig><fig id="pone.0214535.g007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g007</object-id><label>Fig 7</label><caption><title>As <xref ref-type="fig" rid="pone.0214535.g006">Fig 6</xref>, but for &#x0201c;trend+var&#x0201d; experiment implementing the new proposed method.</title></caption><graphic xlink:href="pone.0214535.g007"/></fig><p>We note that the improvement in performance by the &#x0201c;trend+var&#x0201d; method is not caused by any increase in number of parameters resulting in overfitting. The overall statistical model for the projections is the same in both cases: a weighted mixture of pdfs from individual models. The increase in skill is due to better estimation of individual model weights <italic>w</italic><sub><italic>i</italic></sub> in the &#x0201c;trend+var&#x0201d; model through using new variability data constraints on the models.</p></sec><sec id="sec018"><title>5 Real-Case application: Projecting korean summer mean maximum temperature</title><p>We now apply both the &#x0201c;trend&#x0201d; and &#x0201c;trend+var&#x0201d; methods to make projections of Korean summer mean maximum temperature. Specifically, we use 29 GCMs from Coupled Model Intercomparison Project phase 5 (CMIP5, [<xref rid="pone.0214535.ref040" ref-type="bibr">40</xref>]) model runs (the same model set as for the Korea_temp experiment). The models are weighted using 1973&#x02013;2005 station observational data provided by Korean Meteorological Administration (KMA) weather stations [<xref rid="pone.0214535.ref038" ref-type="bibr">38</xref>,<xref rid="pone.0214535.ref053" ref-type="bibr">53</xref>]. We apply simple area average to daily mean maximum temperatures from the stations before calculating summer mean values. We use this short period because it has the best observational coverage, however to provide a liberal estimate of the uncertainty we take model error expansion factors <italic>f</italic> from the corresponding longer-period Korea_temp_long experiments. Future changes (2081&#x02013;2100 minus 1973&#x02013;2005) under the RCP8.5 emissions scenario [<xref rid="pone.0214535.ref042" ref-type="bibr">42</xref>] are presented in <xref ref-type="fig" rid="pone.0214535.g008">Fig 8</xref>. The results show (a) notably higher projected warming and (b) considerable reduction of the low-warming (&#x0003c; 2 K) tails after the variability weighting. Specifically, the mean increases from 4.9 K to 5.6 K, and the 5<sup>th</sup> percentile from 1.8 K to 3.2 K. The new projection mode leaps from 5.3 K to 6.6 K (<xref rid="pone.0214535.t002" ref-type="table">Table 2</xref>). In addition, the 90% credible interval shrinks from 5.5 K to 4.3 K (22% reduction).</p><fig id="pone.0214535.g008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.g008</object-id><label>Fig 8</label><caption><title>Probabilistic projections of summer mean maximum temperature change 1973&#x02013;2005 to 2081&#x02013;2100 over Korea under the RCP8.5 emissions scenario using &#x0201c;trend&#x0201d; and &#x0201c;trend+var&#x0201d; methods.</title><p>Vertical lines are the means and the 90% posterior credible intervals.</p></caption><graphic xlink:href="pone.0214535.g008"/></fig><table-wrap id="pone.0214535.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0214535.t002</object-id><label>Table 2</label><caption><title>Summary of Korean summer mean maximum temperature change probabilistic projections from 1973&#x02013;2005 to 2081&#x02013;2100 under the RCP8.5 emissions scenario from the &#x0201c;trend&#x0201d; and &#x0201c;trend+var&#x0201d; methods.</title></caption><alternatives><graphic id="pone.0214535.t002g" xlink:href="pone.0214535.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" style="background-color:#FFFF00" rowspan="1" colspan="1">Experiment</th><th align="center" style="background-color:#FFFF00" rowspan="1" colspan="1">Mean</th><th align="center" style="background-color:#FFFF00" rowspan="1" colspan="1">Median</th><th align="center" style="background-color:#FFFF00" rowspan="1" colspan="1">Mode</th><th align="center" style="background-color:#FFFF00" rowspan="1" colspan="1">90% Credible Interval</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">Trend</td><td align="center" rowspan="1" colspan="1">4.9 K</td><td align="center" rowspan="1" colspan="1">5.0 K</td><td align="center" rowspan="1" colspan="1">5.3 K</td><td align="center" rowspan="1" colspan="1">(1.8, 7.3)</td></tr><tr><td align="center" rowspan="1" colspan="1">Trend+var</td><td align="center" rowspan="1" colspan="1">5.6 K</td><td align="center" rowspan="1" colspan="1">5.9 K</td><td align="center" rowspan="1" colspan="1">6.6 K</td><td align="center" rowspan="1" colspan="1">(3.2, 7.5)</td></tr></tbody></table></alternatives></table-wrap></sec><sec sec-type="conclusions" id="sec019"><title>6 Discussion</title><p>Here we present a novel method &#x0201c;trend+var&#x0201d; to weight models of complex dynamical systems by their skill at representing both autocorrelated variability and trend in observations. The key step is association of two statistical models with each dynamical model: a trend statistical model, and a variability statistical model. The component submodels are weighted separately using relevant observations, and then the weights are combined. The combined weights are used to make weighted probabilistic multi-model projections. In a series of cross-validation experiments, we show that the new method appears to better identify the &#x0201c;true&#x0201d; model compared to the trend-only weighting method (&#x0201c;trend&#x0201d;). The new method also tends to perform better in terms of mean 90% posterior credible interval and mean absolute bias. Our analysis deviates in some aspects from the traditional Bayesian framework, in order to avoid making difficult-to-justify parametric assumptions about model error, and to alleviate potential overconfidence in one-at-a-time cross-validation experiments.</p><p>Applying the new method to the real case of projecting Korean summer mean maximum temperature change by the end of this century considerably increases future projections. These projections are more informative than from the &#x0201c;trend&#x0201d; method because they use the additional variability and short-term memory (quantified by the lag-1 autocorrelation coefficient) information from both models and observations. Since the BMA predictive model is the same (<xref ref-type="disp-formula" rid="pone.0214535.e033">Eq 14</xref>), the increase in skill is not due to an increased number of parameters, but is derived purely through better estimation of model weights. Recent work has found correlations with absolute values of up to approximately 0.8 between present-day interannual summer temperature sample standard deviation in global and regional climate models, and long-term future mean and/or variability changes for some regions [<xref rid="pone.0214535.ref006" ref-type="bibr">6</xref>,<xref rid="pone.0214535.ref025" ref-type="bibr">25</xref>]. This suggests that historical variability in those regions may provide a valuable constraint on the models. Applying the method to those regions should be considered for future work.</p><p>It is worth discussing differences between this study and previous Bayesian work. Here we for the first time implement a quasi-Bayesian statistical method that weights models by their performance in terms of both trend, variability, and short-term memory (as quantified by the lag-1 autocorrelation) for a relatively general case: arbitrary (potentially non-linear) trend function and red noise variability. The method can be extended to more complex variability structures. Model weights are obtained by constraining the method with calibration period observations, while a parameter controlling model error assumptions is calibrated using cross-validation experiments. Some prior work does also incorporate variability into model weights [<xref rid="pone.0214535.ref035" ref-type="bibr">35</xref>], however their method has so far been demonstrated on a simple case: serially uncorrelated variability, and a linear mean function. Other studies [<xref rid="pone.0214535.ref003" ref-type="bibr">3</xref>,<xref rid="pone.0214535.ref004" ref-type="bibr">4</xref>,<xref rid="pone.0214535.ref006" ref-type="bibr">6</xref>] also incorporates variability into the analyses. However, these studies do not actually use variability performance to weight the models and ignore autocorrelation skill. Unlike previous work, we do consider autocorrelation, which is a common feature of variability in many observed and modeled processes [<xref rid="pone.0214535.ref054" ref-type="bibr">54</xref>&#x02013;<xref rid="pone.0214535.ref056" ref-type="bibr">56</xref>].</p></sec><sec id="sec020"><title>7 Caveats</title><p>Our study is subject to several caveats. First, the anomalies around the long-term trend, as well as model-observational residuals are assumed to be red noise processes. However, our framework can be extended to more general cases in the future. We compare the spectra of model anomalies (normalized in the AMOC experiment) for each model and experiment to the 90% confidence intervals for the corresponding AR1 process spectra, based on 1000 random realizations (Figs R-T in <xref ref-type="supplementary-material" rid="pone.0214535.s001">S1 File</xref>). Relevant comparison for the AMOCIndex experiment is shown in <xref ref-type="fig" rid="pone.0214535.g004">Fig 4</xref> of a preceding study [<xref rid="pone.0214535.ref009" ref-type="bibr">9</xref>]. These results indicate that AR1 process is a reasonable approximation to the internal variability for these systems. Second, when combining the weights of the variability and trend submodels we are assuming independence. While this assumption appears to be generally reasonable here, it may not apply for other datasets. Incorporating dependence should be considered in future studies. Thus, our method is expected to be ideal for cases where there is at least some relationship between present-day variability and future changes, yet the relationship between present-day trends and variability in the models is sufficiently weak to justify the independence assumption we make here. Third, by using a common error expansion factor <italic>f</italic> for the internal variability, trend submodel errors, as well as for the forecasts, we are assuming the magnitudes of errors in these three components are linked. A way forward in subsequent work may be to assume different <italic>f</italic> for trend and variability. The best <italic>f</italic> values could then be found using constrained optimization (optimizing future performance metrics while constraining coverage to be correct). This is beyond the scope of this study. Fourth, when sampling future internal variability, we do not consider the uncertainty in the AR1 parameters of the anomalies. However, as explained in Section 3, we calibrate our method to account for potential overconfidence by scaling the magnitude of the model errors. Other caveats include the simplicity of the future model bias and of the cross-validation experiments, as well as no explicit representation of observational error. For the future Korean temperature projections, the high density of observational network mitigates some of these concerns, as random errors are expected to decrease after averaging across many stations. In addition, theoretically if modelled and observed data from multiple regions are used together in a cross-validation framework, the observational error will be implicitly incorporated into the analysis after nudging the <italic>f</italic> parameter. Nonetheless, an explicit representation of observed error should be considered in the future.</p><p>While the focus on this paper is on the statistical weighting methodology by trend and variability performance, the simplicity of the decomposition into trend and variability (e.g., lowess method or linear detrending) deserves mention. The nonlinear trends discussed here may include residual contributions from long-term internal climate variability. However, this can be handled by the trend-weighting part of the method since this part accounts for long-term model error [<xref rid="pone.0214535.ref035" ref-type="bibr">35</xref>]. The unfiltered long-term variability in each model can be simply considered as part of this long-term model error. Previous work provides examples of using a more sophisticated decomposition [<xref rid="pone.0214535.ref018" ref-type="bibr">18</xref>]. Improving the decomposition methodology is beyond the scope of the paper, and is subject of future work.</p><p>This work assumes stationarity of model weights: if a model is correct during the calibration period, it is also assumed to be correct in the validation period. This is a standard assumption of the BMA method [<xref rid="pone.0214535.ref001" ref-type="bibr">1</xref>,<xref rid="pone.0214535.ref005" ref-type="bibr">5</xref>,<xref rid="pone.0214535.ref020" ref-type="bibr">20</xref>,<xref rid="pone.0214535.ref021" ref-type="bibr">21</xref>,<xref rid="pone.0214535.ref035" ref-type="bibr">35</xref>].</p><p>Notably, this work does not properly confront the issue of model dependence (e.g., the fact that models coming from the same research group, or models with similar outputs are dependent in the general sense of the term) [<xref rid="pone.0214535.ref012" ref-type="bibr">12</xref>,<xref rid="pone.0214535.ref057" ref-type="bibr">57</xref>&#x02013;<xref rid="pone.0214535.ref060" ref-type="bibr">60</xref>]. This needs to be addressed in future work.</p><p>The best new datasets to apply the method to are the ones either with many regions, or with repeated experiments, and where a long calibration period can be split into two subperiods. In this case method performance can be systematically assessed using real observations in cross-validation experiments, and <italic>f</italic> can be properly calibrated. However, any assumption about <italic>f</italic> under new conditions is inherently untestable. Hence, we recommend including equal weights projections along with projections from this (or any other) weighting scheme. In the absence of many regions, and with only short time series available, one has to resort to simulated cross-validation experiments using calibration, projection, and projection reference period model output to calibrate the method. In such cases, if models share common errors, the real value of <italic>f</italic> may be higher than estimated.</p></sec><sec sec-type="conclusions" id="sec021"><title>8 Conclusions</title><p>We present a statistically-rigorous novel method to weight multiple models of stochastic dynamical systems by their skill at representing both internal variability (including autocorrelation) and a nonlinear trend of a time series process, and to make predictions of system change under new conditions. The weight is interpreted as a likelihood of a dynamical model being adequate at capturing both trend and variability aspects of the process. This is a particularly important diagnostic given the broad relevance of variability (e.g., variability can affect extreme events such as heat waves and droughts in climate science). We show that the proposed method tends to better identify &#x0201c;true&#x0201d; models in a suite of leave-one-out cross-validation experiments compared to a typically-used trend-only BMA weighting method. The new method also tends to improve forecasts, as judged by the mean 90% credible interval width and mean absolute bias. This has important implications specifically for multi-model climate projections. Applying the method to project Korean summer mean maximum temperature changes over this century considerably increases future projections. Specifically, the mode of 1973&#x02013;2005 to 2081&#x02013;2100 warming under the RCP8.5 emissions scenario increases by 1.3 K to 6.6 K, while the mean shifts from 4.9 K to 5.6 K. Furthermore, the pdf becomes 22% sharper as measured by the 90% posterior credible interval.</p></sec><sec sec-type="supplementary-material" id="sec022"><title>Supporting information</title><supplementary-material content-type="local-data" id="pone.0214535.s001"><label>S1 File</label><caption><title>The combined supporting information file contains supplementary Texts A and B, supplementary Figs A to T, and supplementary Tables A and B.</title><p>(PDF)</p></caption><media xlink:href="pone.0214535.s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0214535.s002"><label>S2 File</label><caption><title>The file contains the R programming language computer code that implements the model weighting methodology.</title><p>(ZIP)</p></caption><media xlink:href="pone.0214535.s002.zip"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>For their roles in producing, coordinating, and making available the CMIP5 model output, we acknowledge the climate modeling groups, the World Climate Research Programme&#x02019;s (WCRP) Working Group on Coupled Modelling (WGCM), and the Global Organization for Earth System Science Portals (GO-ESSP). A portion of model outputs used here has been obtained from the German Climate Computing Centre (DKRZ), funded through the Federal Ministry for Education and Research. Jong-Soo Shin provided technical assistance with extracting Korean and East Sea temperature model output. We are thankful to Cameron Farnsworth for providing comments on the manuscript, and to Soong-Ki Kim for thought-provoking discussions.</p></ack><ref-list><title>References</title><ref id="pone.0214535.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Bhat</surname><given-names>KS</given-names></name>, <name><surname>Haran</surname><given-names>M</given-names></name>, <name><surname>Terando</surname><given-names>A</given-names></name>, <name><surname>Keller</surname><given-names>K</given-names></name>. <article-title>Climate Projections Using Bayesian Model Averaging and Space-Time Dependence</article-title>. <source>J Agric Biol Environ Stat</source>. <year>2011</year>;<volume>16</volume>(<issue>4</issue>):<fpage>606</fpage>&#x02013;<lpage>28</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Buser</surname><given-names>CM</given-names></name>, <name><surname>K&#x000fc;nsch</surname><given-names>HR</given-names></name>, <name><surname>L&#x000fc;thi</surname><given-names>D</given-names></name>, <name><surname>Wild</surname><given-names>M</given-names></name>, <name><surname>Sch&#x000e4;r</surname><given-names>C</given-names></name>. <article-title>Bayesian multi-model projection of climate: bias assumptions and interannual variability</article-title>. <source>Clim Dyn</source>. <year>2009</year>
<month>11</month>
<day>1</day>;<volume>33</volume>(<issue>6</issue>):<fpage>849</fpage>&#x02013;<lpage>68</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Buser</surname><given-names>CM</given-names></name>, <name><surname>K&#x000fa;nsch</surname><given-names>HR</given-names></name>, <name><surname>Sch&#x000e4;r</surname><given-names>C</given-names></name>. <article-title>Bayesian multi-model projections of climate: Generalization and application to ENSEMBLES results</article-title>. <source>Clim Res</source>. <year>2010</year>;<volume>44</volume>(<issue>2&#x02013;3</issue>):<fpage>227</fpage>&#x02013;<lpage>41</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Chandler</surname><given-names>RE</given-names></name>. <article-title>Exploiting strength, discounting weakness: combining information from multiple climate simulators</article-title>. <source>Philos Trans R Soc Lond Ser A</source>. <year>2013</year>
<month>4</month>
<day>1</day>;<volume>371</volume>:<fpage>20120388</fpage>&#x02013;<lpage>20120388</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Duan</surname><given-names>Q</given-names></name>, <name><surname>Ajami</surname><given-names>NK</given-names></name>, <name><surname>Gao</surname><given-names>X</given-names></name>, <name><surname>Sorooshian</surname><given-names>S</given-names></name>. <article-title>Multi-model ensemble hydrologic prediction using Bayesian model averaging</article-title>. <source>Adv Water Resour</source>. <year>2007</year>
<month>5</month>;<volume>30</volume>(<issue>5</issue>):<fpage>1371</fpage>&#x02013;<lpage>86</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Huttunen</surname><given-names>JMJ</given-names></name>, <name><surname>R&#x000e4;is&#x000e4;nen</surname><given-names>J</given-names></name>, <name><surname>Nissinen</surname><given-names>A</given-names></name>, <name><surname>Lipponen</surname><given-names>A</given-names></name>, <name><surname>Kolehmainen</surname><given-names>V</given-names></name>. <article-title>Cross-validation analysis of bias models in Bayesian multi-model projections of climate</article-title>. <source>Clim Dyn</source>. <year>2017</year>
<month>3</month>
<day>1</day>;<volume>48</volume>(<issue>5&#x02013;6</issue>):<fpage>1555</fpage>&#x02013;<lpage>70</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Knutti</surname><given-names>R</given-names></name>. <article-title>Should we believe model predictions of future climate change?</article-title>
<source>Philos Trans R Soc Lond Math Phys Eng Sci</source>. <year>2008</year>
<month>12</month>
<day>28</day>;<volume>366</volume>(<issue>1885</issue>):<fpage>4647</fpage>&#x02013;<lpage>64</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Olson</surname><given-names>R</given-names></name>, <name><surname>Fan</surname><given-names>Y</given-names></name>, <name><surname>Evans</surname><given-names>JP</given-names></name>. <article-title>A simple method for Bayesian model averaging of regional climate model projections: Application to southeast Australian temperatures</article-title>. <source>Geophys Res Lett</source>. <year>2016</year>
<month>7</month>
<day>28</day>;<volume>43</volume>(<issue>14</issue>):2016GL069704.</mixed-citation></ref><ref id="pone.0214535.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Olson</surname><given-names>R</given-names></name>, <name><surname>An</surname><given-names>S-I</given-names></name>, <name><surname>Fan</surname><given-names>Y</given-names></name>, <name><surname>Evans</surname><given-names>JP</given-names></name>, <name><surname>Caesar</surname><given-names>L</given-names></name>. <article-title>North Atlantic observations sharpen meridional overturning projections</article-title>. <source>Clim Dyn</source>. <year>2017</year>
<month>8</month>
<volume>23</volume>;<fpage>1</fpage>&#x02013;<lpage>18</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Raftery</surname><given-names>AE</given-names></name>, <name><surname>Gneiting</surname><given-names>T</given-names></name>, <name><surname>Balabdaoui</surname><given-names>F</given-names></name>, <name><surname>Polakowski</surname><given-names>M</given-names></name>. <article-title>Using Bayesian model averaging to calibrate forecast ensembles</article-title>. <source>Mon Weather Rev</source>. <year>2005</year>;<volume>133</volume>(<issue>5</issue>):<fpage>1155</fpage>&#x02013;<lpage>74</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Rougier</surname><given-names>J</given-names></name>, <name><surname>Goldstein</surname><given-names>M</given-names></name>, <name><surname>House</surname><given-names>L</given-names></name>. <article-title>Second-order exchangeability analysis for multimodel ensembles</article-title>. <source>J Am Stat Assoc</source>. <year>2013</year>;<volume>108</volume>(<issue>503</issue>):<fpage>852</fpage>&#x02013;<lpage>63</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Steinschneider</surname><given-names>S</given-names></name>, <name><surname>McCrary</surname><given-names>R</given-names></name>, <name><surname>Mearns</surname><given-names>LO</given-names></name>, <name><surname>Brown</surname><given-names>C</given-names></name>. <article-title>The effects of climate model similarity on probabilistic climate projections and the implications for local, risk-based adaptation planning</article-title>. <source>Geophys Res Lett</source>. <year>2015</year>
<month>6</month>
<day>28</day>;<volume>42</volume>(<issue>12</issue>):2015GL064529.</mixed-citation></ref><ref id="pone.0214535.ref013"><label>13</label><mixed-citation publication-type="book"><name><surname>Tebaldi</surname><given-names>C</given-names></name>, <name><surname>Sanso</surname><given-names>B</given-names></name>, <name><surname>Smith</surname><given-names>RL</given-names></name>, <name><surname>Ferreira</surname><given-names>MAR</given-names></name>. <chapter-title>Characterizing Uncertainty of Future Climate Change Projections using Hierarchical Bayesian Models</chapter-title> In: <name><surname>Jose</surname><given-names>Bernardo</given-names></name>, <name><surname>Bayarri</surname><given-names>MJ</given-names></name>, <name><surname>Berger</surname><given-names>JO</given-names></name>, <name><surname>Dawid</surname><given-names>AP</given-names></name>, <name><surname>Heckerman</surname><given-names>D</given-names></name>, <name><surname>Smith</surname><given-names>AFM</given-names></name>, <etal>et al</etal>, editors. <source>Bayesian Statistics 9</source>. <publisher-name>Oxford Scholarship Online</publisher-name>; <year>2011</year>.</mixed-citation></ref><ref id="pone.0214535.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Tebaldi</surname><given-names>C</given-names></name>, <name><surname>Sans&#x000f3;</surname><given-names>B</given-names></name>. <article-title>Joint projections of temperature and precipitation change from multiple climate models: A hierarchical Bayesian approach</article-title>. <source>J R Stat Soc Ser A Stat Soc</source>. <year>2009</year>;<volume>172</volume>(<issue>1</issue>):<fpage>83</fpage>&#x02013;<lpage>106</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Terando</surname><given-names>A</given-names></name>, <name><surname>Keller</surname><given-names>K</given-names></name>, <name><surname>Easterling</surname><given-names>WE</given-names></name>. <article-title>Probabilistic projections of agro-climate indices in North America</article-title>. <source>J Geophys Res Atmospheres</source>. <year>2012</year>;<volume>117</volume>(<issue>8</issue>).</mixed-citation></ref><ref id="pone.0214535.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Wallach</surname><given-names>D</given-names></name>, <name><surname>Mearns</surname><given-names>LO</given-names></name>, <name><surname>Ruane</surname><given-names>AC</given-names></name>, <name><surname>R&#x000f6;tter</surname><given-names>RP</given-names></name>, <name><surname>Asseng</surname><given-names>S</given-names></name>. <article-title>Lessons from climate modeling on the design and use of ensembles for crop modeling</article-title>. <source>Clim Change</source>. <year>2016</year>;<volume>139</volume>(<issue>3&#x02013;4</issue>):<fpage>551</fpage>&#x02013;<lpage>64</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Xu</surname><given-names>Y</given-names></name>, <name><surname>Gao</surname><given-names>X</given-names></name>, <name><surname>Giorgi</surname><given-names>F</given-names></name>. <article-title>Upgrades to the reliability ensemble averaging method for producing probabilistic climate-change projections</article-title>. <source>Clim Res</source>. <year>2010</year>;<volume>41</volume>(<issue>1</issue>):<fpage>61</fpage>&#x02013;<lpage>81</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Qi</surname><given-names>Y</given-names></name>, <name><surname>Qian</surname><given-names>C</given-names></name>, <name><surname>Yan</surname><given-names>Z</given-names></name>. <article-title>An alternative multi-model ensemble mean approach for near-term projection</article-title>. <source>Int J Climatol</source>. <year>2017</year>
<month>1</month>
<day>1</day>;<volume>37</volume>(<issue>1</issue>):<fpage>109</fpage>&#x02013;<lpage>22</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Acharya</surname><given-names>N</given-names></name>, <name><surname>Chattopadhyay</surname><given-names>S</given-names></name>, <name><surname>Mohanty</surname><given-names>UC</given-names></name>, <name><surname>Ghosh</surname><given-names>K</given-names></name>. <article-title>Prediction of Indian summer monsoon rainfall: a weighted multi-model ensemble to enhance probabilistic forecast skills</article-title>. <source>Meteorol Appl</source>. <year>2014</year>
<month>7</month>
<day>1</day>;<volume>21</volume>(<issue>3</issue>):<fpage>724</fpage>&#x02013;<lpage>32</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Hoeting</surname><given-names>JA</given-names></name>, <name><surname>Madigan</surname><given-names>D</given-names></name>, <name><surname>Raftery</surname><given-names>AE</given-names></name>, <name><surname>Volinsky</surname><given-names>CT</given-names></name>. <article-title>Bayesian Model Averaging: A Tutorial</article-title>. <source>Stat Sci</source>. <year>1999</year>;<volume>14</volume>(<issue>4</issue>):<fpage>382</fpage>&#x02013;<lpage>417</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Montgomery</surname><given-names>JM</given-names></name>, <name><surname>Nyhan</surname><given-names>B</given-names></name>. <article-title>Bayesian model averaging: Theoretical developments and practical applications</article-title>. <source>Polit Anal</source>. <year>2010</year>;<volume>18</volume>(<issue>2</issue>):<fpage>245</fpage>&#x02013;<lpage>70</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Yun</surname><given-names>WT</given-names></name>, <name><surname>Stefanova</surname><given-names>L</given-names></name>, <name><surname>Krishnamurti</surname><given-names>TN</given-names></name>. <article-title>Improvement of the Multimodel Superensemble Technique for Seasonal Forecasts</article-title>. <source>J Clim</source>. <year>2003</year>
<month>11</month>
<day>1</day>;<volume>16</volume>(<issue>22</issue>):<fpage>3834</fpage>&#x02013;<lpage>40</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Yun</surname><given-names>WT</given-names></name>, <name><surname>Stefanova</surname><given-names>L</given-names></name>, <name><surname>Mitra</surname><given-names>AK</given-names></name>, <name><surname>Kumar</surname><given-names>TSVV</given-names></name>, <name><surname>Dewar</surname><given-names>W</given-names></name>, <name><surname>Krishnamurti</surname><given-names>TN</given-names></name>. <article-title>A multi-model superensemble algorithm for seasonal climate prediction using DEMETER forecasts</article-title>. <source>Tellus A</source>. <year>2005</year>
<month>5</month>
<day>1</day>;<volume>57</volume>(<issue>3</issue>):<fpage>280</fpage>&#x02013;<lpage>9</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Bayes</surname><given-names>M</given-names></name>, <name><surname>Price</surname><given-names>M</given-names></name>. <article-title>An Essay towards Solving a Problem in the Doctrine of Chances. By the Late Rev. Mr. Bayes, F. R. S. Communicated by Mr. Price, in a Letter to John Canton, A. M. F. R. S</article-title>. <source>Philos Trans</source>. <year>1763</year>
<month>1</month>
<day>1</day>;<volume>53</volume>:<fpage>370</fpage>&#x02013;<lpage>418</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Fischer</surname><given-names>EM</given-names></name>, <name><surname>Rajczak</surname><given-names>J</given-names></name>, <name><surname>Sch&#x000e4;r</surname><given-names>C</given-names></name>. <article-title>Changes in European summer temperature variability revisited</article-title>. <source>Geophys Res Lett</source>. <year>2012</year>
<month>10</month>
<day>16</day>;<volume>39</volume>(<issue>19</issue>):<fpage>L19702</fpage>.</mixed-citation></ref><ref id="pone.0214535.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Cox</surname><given-names>PM</given-names></name>, <name><surname>Huntingford</surname><given-names>C</given-names></name>, <name><surname>Williamson</surname><given-names>MS</given-names></name>. <article-title>Emergent constraint on equilibrium climate sensitivity from global temperature variability</article-title>. <source>Nature</source>. <year>2018</year>;<volume>553</volume>(<issue>7688</issue>):<fpage>319</fpage>&#x02013;<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1038/nature25450</pub-id>
<?supplied-pmid 29345639?><pub-id pub-id-type="pmid">29345639</pub-id></mixed-citation></ref><ref id="pone.0214535.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Kopp</surname><given-names>RE</given-names></name>, <name><surname>Shwom</surname><given-names>RL</given-names></name>, <name><surname>Wagner</surname><given-names>G</given-names></name>, <name><surname>Yuan</surname><given-names>J</given-names></name>. <article-title>Tipping elements and climate&#x02013;economic shocks: Pathways toward integrated assessment</article-title>. <source>Earths Future</source>. <year>2016</year>;<volume>4</volume>(<issue>8</issue>):<fpage>346</fpage>&#x02013;<lpage>72</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Feng</surname><given-names>QY</given-names></name>, <name><surname>Viebahn</surname><given-names>JP</given-names></name>, <name><surname>Dijkstra</surname><given-names>HA</given-names></name>. <article-title>Deep ocean early warning signals of an Atlantic MOC collapse</article-title>. <source>Geophys Res Lett</source>. <year>2014</year>;<volume>41</volume>(<issue>16</issue>):<fpage>6008</fpage>&#x02013;<lpage>14</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Kleinen</surname><given-names>T</given-names></name>, <name><surname>Held</surname><given-names>H</given-names></name>, <name><surname>Petschel-Held</surname><given-names>G</given-names></name>. <article-title>The potential role of spectral properties in detecting thresholds in the Earth system: Application to the thermohaline circulation</article-title>. <source>Ocean Dyn</source>. <year>2003</year>;<volume>53</volume>(<issue>2</issue>):<fpage>53</fpage>&#x02013;<lpage>63</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Lenton</surname><given-names>TM</given-names></name>, <name><surname>Livina</surname><given-names>VN</given-names></name>, <name><surname>Dakos</surname><given-names>V</given-names></name>, <name><surname>Van Nes</surname><given-names>EH</given-names></name>, <name><surname>Scheffer</surname><given-names>M</given-names></name>. <article-title>Early warning of climate tipping points from critical slowing down: Comparing methods to improve robustness</article-title>. <source>Philos Trans R Soc Math Phys Eng Sci</source>. <year>2012</year>;<volume>370</volume>(<issue>1962</issue>):<fpage>1185</fpage>&#x02013;<lpage>204</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Thomas</surname><given-names>ZA</given-names></name>. <article-title>Using natural archives to detect climate and environmental tipping points in the Earth System</article-title>. <source>Quat Sci Rev</source>. <year>2016</year>;<volume>152</volume>:<fpage>60</fpage>&#x02013;<lpage>71</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Braverman</surname><given-names>A</given-names></name>, <name><surname>Cressie</surname><given-names>N</given-names></name>, <name><surname>Teixeira</surname><given-names>J</given-names></name>. <article-title>A likelihood-based comparison of temporal models for physical processes</article-title>. <source>Stat Anal Data Min</source>. <year>2011</year>
<month>6</month>
<day>1</day>;<volume>4</volume>(<issue>3</issue>):<fpage>247</fpage>&#x02013;<lpage>58</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Kwasniok</surname><given-names>F</given-names></name>. <article-title>Analysis and modelling of glacial climate transitions using simple dynamical systems</article-title>. <source>Phil Trans R Soc A</source>. <year>2013</year>
<month>5</month>
<day>28</day>;<volume>371</volume>(<issue>1991</issue>):<fpage>20110472</fpage>
<pub-id pub-id-type="doi">10.1098/rsta.2011.0472</pub-id>
<?supplied-pmid 23588043?><pub-id pub-id-type="pmid">23588043</pub-id></mixed-citation></ref><ref id="pone.0214535.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Peavoy</surname><given-names>D</given-names></name>, <name><surname>Franzke</surname><given-names>C</given-names></name>. <article-title>Bayesian analysis of rapid climate change during the last glacial using Greenland &#x003b4;18O data</article-title>. <source>Clim Past</source>. <year>2010</year>;<volume>6</volume>(<issue>6</issue>):<fpage>787</fpage>&#x02013;<lpage>94</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Fan</surname><given-names>Y</given-names></name>, <name><surname>Olson</surname><given-names>R</given-names></name>, <name><surname>Evans</surname><given-names>JP</given-names></name>. <article-title>A Bayesian posterior predictive framework for weighting ensemble regional climate models</article-title>. <source>Geosci Model Dev</source>. <year>2017</year>
<month>6</month>
<day>23</day>;<volume>10</volume>(<issue>6</issue>):<fpage>2321</fpage>&#x02013;<lpage>32</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Cleveland</surname><given-names>WS</given-names></name>. <article-title>Robust Locally Weighted Regression and Smoothing Scatterplots</article-title>. <source>J Am Stat Assoc</source>. <year>1979</year>
<month>12</month>
<day>1</day>;<volume>74</volume>(<issue>368</issue>):<fpage>829</fpage>&#x02013;<lpage>36</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Sexton</surname><given-names>DMH</given-names></name>, <name><surname>Murphy</surname><given-names>JM</given-names></name>, <name><surname>Collins</surname><given-names>M</given-names></name>, <name><surname>Webb</surname><given-names>MJ</given-names></name>. <article-title>Multivariate probabilistic projections using imperfect climate models part I: Outline of methodology</article-title>. <source>Clim Dyn</source>. <year>2012</year>;<volume>38</volume>(<issue>11&#x02013;12</issue>):<fpage>2513</fpage>&#x02013;<lpage>42</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Shin</surname><given-names>J</given-names></name>, <name><surname>Olson</surname><given-names>R</given-names></name>, <name><surname>An</surname><given-names>S-I</given-names></name>. <article-title>Projected Heat Wave Characteristics over the Korean Peninsula During the Twenty-First Century</article-title>. <source>Asia-Pac J Atmospheric Sci</source>. <year>2018</year>;<volume>54</volume>(<issue>1</issue>):<fpage>53</fpage>&#x02013;<lpage>61</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Kanzow</surname><given-names>T</given-names></name>, <name><surname>Cunningham</surname><given-names>SA</given-names></name>, <name><surname>Johns</surname><given-names>WE</given-names></name>, <name><surname>Hirschi</surname><given-names>JJ-M</given-names></name>, <name><surname>Marotzke</surname><given-names>J</given-names></name>, <name><surname>Baringer</surname><given-names>MO</given-names></name>, <etal>et al</etal>
<article-title>Seasonal Variability of the Atlantic Meridional Overturning Circulation at 26.5&#x000b0;N</article-title>. <source>J Clim</source>. <year>2010</year>
<month>6</month>
<day>11</day>;<volume>23</volume>(<issue>21</issue>):<fpage>5678</fpage>&#x02013;<lpage>98</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Taylor</surname><given-names>KE</given-names></name>, <name><surname>Stouffer</surname><given-names>RJ</given-names></name>, <name><surname>Meehl</surname><given-names>GA</given-names></name>. <article-title>An Overview of CMIP5 and the Experiment Design</article-title>. <source>Bull Am Meteorol Soc</source>. <year>2011</year>
<month>10</month>
<day>7</day>;<volume>93</volume>(<issue>4</issue>):<fpage>485</fpage>&#x02013;<lpage>98</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref041"><label>41</label><mixed-citation publication-type="other">ESGF LLNL. ESGF @ DOE/LLNL [Internet]. 2016. <ext-link ext-link-type="uri" xlink:href="https://esgf-node.llnl.gov/projects/esgf-llnl/">https://esgf-node.llnl.gov/projects/esgf-llnl/</ext-link></mixed-citation></ref><ref id="pone.0214535.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Moss</surname><given-names>RH</given-names></name>, <name><surname>Edmonds</surname><given-names>JA</given-names></name>, <name><surname>Hibbard</surname><given-names>KA</given-names></name>, <name><surname>Manning</surname><given-names>MR</given-names></name>, <name><surname>Rose</surname><given-names>SK</given-names></name>, <name><surname>Vuuren</surname><given-names>DP</given-names></name>, <etal>et al</etal>
<article-title>The next generation of scenarios for climate change research and assessment</article-title>. <source>Nature</source>. <year>2010</year>
<month>2</month>
<day>11</day>;<volume>463</volume>(<issue>7282</issue>):<fpage>747</fpage>&#x02013;<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1038/nature08823</pub-id>
<?supplied-pmid 20148028?><pub-id pub-id-type="pmid">20148028</pub-id></mixed-citation></ref><ref id="pone.0214535.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Sen</surname><given-names>PK</given-names></name>. <article-title>Estimates of the Regression Coefficient Based on Kendall&#x02019;s Tau</article-title>. <source>J Am Stat Assoc</source>. <year>1968</year>;<volume>63</volume>(<issue>324</issue>):<fpage>1379</fpage>&#x02013;<lpage>89</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Rahmstorf</surname><given-names>S</given-names></name>, <name><surname>Box</surname><given-names>JE</given-names></name>, <name><surname>Feulner</surname><given-names>G</given-names></name>, <name><surname>Mann</surname><given-names>ME</given-names></name>, <name><surname>Robinson</surname><given-names>A</given-names></name>, <name><surname>Rutherford</surname><given-names>S</given-names></name>, <etal>et al</etal>
<article-title>Exceptional twentieth-century slowdown in Atlantic Ocean overturning circulation</article-title>. <source>Nat Clim Change</source>. <year>2015</year>
<month>5</month>;<volume>5</volume>(<issue>5</issue>):<fpage>475</fpage>&#x02013;<lpage>80</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref045"><label>45</label><mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>B</given-names></name>, <name><surname>Banzon</surname><given-names>VF</given-names></name>, <name><surname>Freeman</surname><given-names>E</given-names></name>, <name><surname>Lawrimore</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>W</given-names></name>, <name><surname>Peterson</surname><given-names>TC</given-names></name>, <etal>et al</etal>
<article-title>Extended Reconstructed Sea Surface Temperature Version 4 (ERSST.v4). Part I: Upgrades and Intercomparisons</article-title>. <source>J Clim</source>. <year>2014</year>
<month>10</month>
<day>14</day>;<volume>28</volume>(<issue>3</issue>):<fpage>911</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Huang</surname><given-names>B</given-names></name>, <name><surname>Thorne</surname><given-names>PW</given-names></name>, <name><surname>Smith</surname><given-names>TM</given-names></name>, <name><surname>Liu</surname><given-names>W</given-names></name>, <name><surname>Lawrimore</surname><given-names>J</given-names></name>, <name><surname>Banzon</surname><given-names>VF</given-names></name>, <etal>et al</etal>
<article-title>Further Exploring and Quantifying Uncertainties for Extended Reconstructed Sea Surface Temperature (ERSST) Version 4 (v4)</article-title>. <source>J Clim</source>. <year>2015</year>
<month>12</month>
<day>11</day>;<volume>29</volume>(<issue>9</issue>):<fpage>3119</fpage>&#x02013;<lpage>42</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>W</given-names></name>, <name><surname>Huang</surname><given-names>B</given-names></name>, <name><surname>Thorne</surname><given-names>PW</given-names></name>, <name><surname>Banzon</surname><given-names>VF</given-names></name>, <name><surname>Zhang</surname><given-names>H-M</given-names></name>, <name><surname>Freeman</surname><given-names>E</given-names></name>, <etal>et al</etal>
<article-title>Extended Reconstructed Sea Surface Temperature Version 4 (ERSST.v4): Part II. Parametric and Structural Uncertainty Estimations</article-title>. <source>J Clim</source>. <year>2014</year>
<month>11</month>
<day>20</day>;<volume>28</volume>(<issue>3</issue>):<fpage>931</fpage>&#x02013;<lpage>51</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Hirahara</surname><given-names>S</given-names></name>, <name><surname>Ishii</surname><given-names>M</given-names></name>, <name><surname>Fukuda</surname><given-names>Y</given-names></name>. <article-title>Centennial-Scale Sea Surface Temperature Analysis and Its Uncertainty</article-title>. <source>J Clim</source>. <year>2013</year>
<month>9</month>
<day>3</day>;<volume>27</volume>(<issue>1</issue>):<fpage>57</fpage>&#x02013;<lpage>75</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref049"><label>49</label><mixed-citation publication-type="other">Huang B, Banzon VF, Freeman E, Lawrimore J, Liu W, Peterson TC, et al. Extended Reconstructed Sea Surface Temperature (ERSST), Version 4, NOAA National Centers for Environmental Information [Internet]. 2016. <ext-link ext-link-type="uri" xlink:href="https://data.nodc.noaa.gov/cgi-bin/iso?id=gov.noaa.ncdc:C00884">https://data.nodc.noaa.gov/cgi-bin/iso?id=gov.noaa.ncdc:C00884</ext-link></mixed-citation></ref><ref id="pone.0214535.ref050"><label>50</label><mixed-citation publication-type="other">Ishii M. COBE-SST2 Version 2.9.2 [Internet]. 2016. <ext-link ext-link-type="uri" xlink:href="https://amaterasu.ees.hokudai.ac.jp/~ism/pub/cobe-sst2/">https://amaterasu.ees.hokudai.ac.jp/~ism/pub/cobe-sst2/</ext-link></mixed-citation></ref><ref id="pone.0214535.ref051"><label>51</label><mixed-citation publication-type="journal"><name><surname>Hansen</surname><given-names>J</given-names></name>, <name><surname>Ruedy</surname><given-names>R</given-names></name>, <name><surname>Sato</surname><given-names>M</given-names></name>, <name><surname>Lo</surname><given-names>K</given-names></name>. <article-title>Global Surface Temperature Change</article-title>. <source>Rev Geophys</source>. <year>2010</year>
<month>12</month>
<day>1</day>;<volume>48</volume>(<issue>4</issue>):<fpage>RG4004</fpage>.</mixed-citation></ref><ref id="pone.0214535.ref052"><label>52</label><mixed-citation publication-type="other">GISTEMP Team. GISS Surface Temperature Analysis (GISTEMP) [Internet]. NASA Goddard Institute for Space Studies; 2016 [cited 2016 Jun 15]. <ext-link ext-link-type="uri" xlink:href="https://data.giss.nasa.gov/gistemp/">https://data.giss.nasa.gov/gistemp/</ext-link></mixed-citation></ref><ref id="pone.0214535.ref053"><label>53</label><mixed-citation publication-type="other">Korea Meteorological Administration. Open Portal for Meteorological Data (in Korean) [Internet]. 2016. <ext-link ext-link-type="uri" xlink:href="https://data.kma.go.kr">https://data.kma.go.kr</ext-link></mixed-citation></ref><ref id="pone.0214535.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Hasselmann</surname><given-names>K</given-names></name>. <article-title>Stochastic climate models Part I. Theory</article-title>. <source>Tellus</source>. <year>1976</year>
<month>1</month>
<day>1</day>;<volume>28</volume>(<issue>6</issue>):<fpage>473</fpage>&#x02013;<lpage>85</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Keller</surname><given-names>K</given-names></name>, <name><surname>McInerney</surname><given-names>D</given-names></name>. <article-title>The dynamics of learning about a climate threshold</article-title>. <source>Clim Dyn</source>. <year>2008</year>
<month>2</month>
<day>1</day>;<volume>30</volume>(<issue>2&#x02013;3</issue>):<fpage>321</fpage>&#x02013;<lpage>32</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>Olson</surname><given-names>R</given-names></name>, <name><surname>Sriver</surname><given-names>R</given-names></name>, <name><surname>Chang</surname><given-names>W</given-names></name>, <name><surname>Haran</surname><given-names>M</given-names></name>, <name><surname>Urban</surname><given-names>NM</given-names></name>, <name><surname>Keller</surname><given-names>K</given-names></name>. <article-title>What is the effect of unresolved internal climate variability on climate sensitivity estimates?</article-title>
<source>J Geophys Res Atmospheres</source>. <year>2013</year>;<volume>118</volume>(<issue>10</issue>):<fpage>4348</fpage>&#x02013;<lpage>58</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref057"><label>57</label><mixed-citation publication-type="journal"><name><surname>Annan</surname><given-names>JD</given-names></name>, <name><surname>Hargreaves</surname><given-names>JC</given-names></name>. <article-title>On the meaning of independence in climate science</article-title>. <source>Earth Syst Dyn</source>. <year>2017</year>;<volume>8</volume>(<issue>1</issue>):<fpage>211</fpage>&#x02013;<lpage>24</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Bishop</surname><given-names>CH</given-names></name>, <name><surname>Abramowitz</surname><given-names>G</given-names></name>. <article-title>Climate model dependence and the replicate Earth paradigm</article-title>. <source>Clim Dyn</source>. <year>2013</year>;<volume>41</volume>(<issue>3&#x02013;4</issue>):<fpage>885</fpage>&#x02013;<lpage>900</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref059"><label>59</label><mixed-citation publication-type="journal"><name><surname>Haughton</surname><given-names>N</given-names></name>, <name><surname>Abramowitz</surname><given-names>G</given-names></name>, <name><surname>Pitman</surname><given-names>A</given-names></name>, <name><surname>Phipps</surname><given-names>SJ</given-names></name>. <article-title>Weighting climate model ensembles for mean and variance estimates</article-title>. <source>Clim Dyn</source>. <year>2015</year>;<volume>45</volume>(<issue>11&#x02013;12</issue>):<fpage>3169</fpage>&#x02013;<lpage>81</lpage>.</mixed-citation></ref><ref id="pone.0214535.ref060"><label>60</label><mixed-citation publication-type="journal"><name><surname>Leduc</surname><given-names>M</given-names></name>, <name><surname>Laprise</surname><given-names>R</given-names></name>, <name><surname>de El&#x000ed;a</surname><given-names>R</given-names></name>, <name><surname>&#x00160;eparovi&#x00107;</surname><given-names>L</given-names></name>. <article-title>Is institutional democracy a good proxy for model independence?</article-title>
<source>J Clim</source>. <year>2016</year>;<volume>29</volume>(<issue>23</issue>):<fpage>8301</fpage>&#x02013;<lpage>16</lpage>.</mixed-citation></ref></ref-list></back></article>