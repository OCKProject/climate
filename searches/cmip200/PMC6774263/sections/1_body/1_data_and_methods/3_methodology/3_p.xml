<?xml version="1.0" encoding="UTF-8"?>
<p class="p">The presence of high autocorrelation in the data can influence the 
 <styled-content style="italic-in-any-context" class="styled-content">k</styled-content>‐means clustering algorithm, potentially inflating the optimal ratio. This is exacerbated by the fact that the algorithm will always generate the number of clusters one asks for, meaning large optimal ratios may occur purely by chance. This raises two issues. First, how does one evaluate the statistical significance of the regimes generated? Second, given the influence of autocorrelation, which may vary between simulations, how does one compare optimal ratios across multiple models? Both these questions are addressed by defining a “significance” metric in the following manner. A statistical null hypothesis is assumed in which the phase space in question has no particular regime structure and therefore the atmosphere has no preferred locations or directions of movement in phase space. Concretely, the null hypothesis posits that the phase space is equivalent to that expected from assuming that each of the four coordinates of the atmosphere, in this truncated four‐dimensional phase space, are behaving like independent Markov processes with a fixed mean, variance, and lag‐1 correlation equaling those of the data set in question. The assumption of the process being first order (and therefore using the lag‐1 correlation) was justified by plotting the autocorrelation of our data sets and noting that these were very well captured by a basic exponential decay. While skewness in the data can, in principle, also influence clustering, we found little sensitivity to the computed metrics when adding skewness to the null hypothesis, and this was therefore ignored. Randomly generating four such Markov processes defines new atmospheric coordinates, which will populate the four‐dimensional phase space; by applying the clustering algorithm to this data set, one computes the optimal ratio for the clusters produced. Repeating this for 500 different synthetic data sets generates a distribution of optimal ratios that could be expected from our null hypothesis. We define the 
 <styled-content style="italic-in-any-context" class="styled-content">sharpness</styled-content> of the clustering to be the percentage of points in this distribution 
 <styled-content style="italic-in-any-context" class="styled-content">below</styled-content> the optimal ratio actually computed with the original data set. A sharpness close to 100% therefore implies a large optimal ratio unlikely to have arisen by chance from an atmosphere with no regime structure. Crucially, by effectively “normalizing” the optimal ratio relative to the autocorrelation of the underlying data, the sharpness metric can readily be compared across multiple models. In Dawson et al. (
 <xref rid="grl59251-bib-0007" ref-type="ref" class="xref">2012</xref>), this metric was referred to simply as “significance,” but as we are using this as a metric in and of itself, we rename it to avoid potential confusion. However, it is important to keep in mind that this is a measure of confidence in clustering and so may change according to the sample size.
</p>
