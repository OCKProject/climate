<?xml version="1.0" encoding="UTF-8"?>
<p class="p">A standard metric to rate the relative importance of explanatory variables is the Pearson correlation coefficient, whose square (the coefficient of determination 
 <italic class="italic">R</italic>
 <sup class="sup">2</sup>) measures the amount of total variability accounted for by each explanatory variable without considering the others. Closely related to the Pearson correlation coefficient is the partial correlation coefficient 
 <italic class="italic">ρ</italic>
 <sub class="sub">
  <italic class="italic">X</italic>
  <italic class="italic">Y</italic>·
  <bold class="bold">Z</bold>
 </sub> (e.g., Brown &amp; Hendrix, 
 <xref rid="grl57416-bib-0005" ref-type="ref" class="xref">2005</xref>), which measures the degree of correlation between two variables (
 <italic class="italic">X</italic>, 
 <italic class="italic">Y</italic>), controlling for a set of other variables (
 <bold class="bold">Z</bold>). The squared partial correlation coefficient, 
 <math id="nlm-math-1" class="math">
  <msubsup class="msubsup">
   <mrow class="mrow">
    <mi class="mi">ρ</mi>
   </mrow>
   <mrow class="mrow">
    <mi class="mi">XY</mi>
    <mo class="mo">·</mo>
    <mi mathvariant="bold" class="mi">Z</mi>
   </mrow>
   <mrow class="mrow">
    <mn class="mn">2</mn>
   </mrow>
  </msubsup>
 </math>, can be interpreted as how much of the remaining unexplained variance of 
 <italic class="italic">Y</italic> is explained by the 
 <italic class="italic">n</italic>th variable 
 <italic class="italic">X</italic> after the introduction of 
 <italic class="italic">n</italic> − 1 variables 
 <bold class="bold">Z</bold>.
</p>
