<?xml version="1.0" encoding="UTF-8"?>
<p class="p">Turing [
 <xref rid="RSPA20150772C1" ref-type="bibr" class="xref">1</xref>] famously asked the question: How could one tell the difference between a human and an artificial intelligence? His answer was (deceptively) simple: ask them questions. If you cannot tell which is which from their answers, then for all practical purposes there is no difference. Very high-resolution limited-area weather forecast models, integrated a day or so from their initial conditions, pass the Turing test on scales larger than the model grid-scale (
 <italic class="italic">ca</italic> 1â€‰km): for example, it is often impossible to tell which is a forecast rainfall field and which is the observed field, as determined from radar echoes. By contrast, it is relatively easy to tell the difference between output from a climate model and the real world at scales larger than the grid-scale of the climate model. On scales close to the grid-scale, even an amateur would notice that cloud structures looked unrealistic. However, more seriously, there are also substantial errors on scales much larger than the grid-scale [
 <xref rid="RSPA20150772C2" ref-type="bibr" class="xref">2</xref>].
</p>
