<?xml version="1.0" encoding="UTF-8"?>
<p class="p">The solution is sensitive to the initialization and choice of 
 <italic class="italic">K</italic>, and the algoritwhm partitions the parameter subspace using linear hyperplanes. This linearity constraint means that higher numbers of 
 <italic class="italic">K</italic> can both assist in partitioning the subspace more appropriately, and isolate noise. The appendix demonstrates the small sensitivity of the result to the algorithm's initial random seed, and the impact of varying 
 <italic class="italic">K</italic>. An optimal value of 
 <italic class="italic">K</italic> is determined as 
 <italic class="italic">K</italic> &gt; 35 using the Akaike and Bayesian Information Criteria (AIC and BIC; Akaike, 1973). Information criteria provide a measure of the quality of a statistical model, rewarding increased likelihood across a data set and penalizing overfitting. AIC and BIC indicate robust regimes as they both asymptote in the bottom left panel of Figure 
 <xref rid="ess2278-fig-0002" ref-type="fig" class="xref">2</xref>, suggesting that no information is gained by further increasing 
 <italic class="italic">K</italic>. 
 <italic class="italic">K</italic> = 50 is used for the remaining analysis, where five clusters are individually analyzed as they are considered to represent somewhat classical dynamical regimes, and the remaining 45 clusters are taken together as a single “nonlinear regime.”
</p>
