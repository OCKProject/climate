<?xml version="1.0" encoding="UTF-8"?>
<p class="p">Prediction accuracy and validation of the models were assessed on the basis of Area Under the Receiving Operator Curve (AUC), sensitivity (correctly classified presences) and specificity (correctly classified absences) [
 <xref rid="pone.0195752.ref020" ref-type="bibr" class="xref">20</xref>, 
 <xref rid="pone.0195752.ref056" ref-type="bibr" class="xref">56</xref>–
 <xref rid="pone.0195752.ref057" ref-type="bibr" class="xref">57</xref>]. These measures are estimated from 578 random splits of the field dataset into a calibration subset with 70% of the data and a validation subset with 30% of the data, which is used by the model to assess the statistical significance [
 <xref rid="pone.0195752.ref020" ref-type="bibr" class="xref">20</xref>]. AUC values range from 0 to 1. Values between 0.2–0.5 were considered low, 0.5–0.7 moderate and &gt;0.7 as high while validating the model results. The jackknife procedure also called ‘leave one out’ was followed to assess the importance of variables [
 <xref rid="pone.0195752.ref013" ref-type="bibr" class="xref">13</xref>, 
 <xref rid="pone.0195752.ref056" ref-type="bibr" class="xref">56</xref>]. Jackknife, an alternative approach for assessing variable importance which provides statistics on the significance of each variable in the model [
 <xref rid="pone.0195752.ref057" ref-type="bibr" class="xref">57</xref>–
 <xref rid="pone.0195752.ref059" ref-type="bibr" class="xref">59</xref>].
</p>
