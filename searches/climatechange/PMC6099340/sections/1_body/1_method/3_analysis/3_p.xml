<?xml version="1.0" encoding="UTF-8"?>
<p class="p">All three researchers used this broad coding scheme to code all comments individually and then discussed each comment to arrive at an agreed decision. This yielded a total of 420 broad codes distributed across the 300 comments (because some comments were coded for more than one theme). To check that no one coder was overly influential in these discussions, and that the coding scheme was sufficiently reliable, 10 comments from each newspaper were randomly selected for repeat individual blind coding, several months after the main coding period had ended. To assess interrater reliability, Cohen's kappa scores were calculated between the agreed coding and the individual blind coding of each author, with 0 used where the number of codes recorded for any comment differed. All authors' individual coding agreed substantially with the agreed coding, κ = .723, .689, and .776, all 
 <italic class="italic">p</italic> &lt; .001.
</p>
