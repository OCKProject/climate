<?xml version="1.0" encoding="UTF-8"?>
<fig fig-type="Figure" xml:lang="en" id="ece33403-fig-0001" orientation="portrait" position="float" class="fig">
 <label class="label">Figure 1</label>
 <caption class="caption">
  <p class="p">Representation of workflow starting with creating nine species distribution models (
   <styled-content style="fixed-case" class="styled-content">SDM</styled-content>s) by training with each of nine covariate sets using the Biomod ensemble and then conducting a 
   <italic class="italic">range change analysis</italic> by projecting to future climate (general circulation model data; 
   <styled-content style="fixed-case" class="styled-content">GCM</styled-content>) or conducting a 
   <italic class="italic">model performance analysis</italic> by predicting to testing data. The range change analysis involved projections of each 
   <styled-content style="fixed-case" class="styled-content">SDM</styled-content> to 10 
   <styled-content style="fixed-case" class="styled-content">GCM</styled-content>s to obtain future probabilities of occurrence, then thresholding each projection 12 different ways to obtain occurrence (0/1) values, then calculating range change (range change index; 
   <styled-content style="fixed-case" class="styled-content">RCI</styled-content>) based on the difference between future versus hindcast occurrence (not shown). The model performance analysis involved predictions of each 
   <styled-content style="fixed-case" class="styled-content">SDM</styled-content> to subsets of historical climate data based on (a) extrapolation data split or (b) cross‐validation (
   <styled-content style="fixed-case" class="styled-content">CV</styled-content>) data splits to obtain historic probabilities of occurrence, then thresholding each prediction 12 different ways to obtain occurrence values, and then assessing model performance based on predicted versus actual occurrence. We used the two types of analyses to address three questions: (1) how much uncertainty is attributable to each uncertainty source (
   <styled-content style="fixed-case" class="styled-content">GCM</styled-content>, hypothesis, collinearity, and threshold)? (2) what is the effect of each decision on amount of projected range change?; and (3) what is the effect of modeling decisions on model performance in extrapolation and compared to 
   <styled-content style="fixed-case" class="styled-content">CV</styled-content>? For objectives 1 and 2, with 1,080 (3 × 3 × 10 × 12) projections per species, we (1) modeled deviance in 
   <styled-content style="fixed-case" class="styled-content">RCI</styled-content> explained by each uncertainty source, and, (2) modeled the contributions to 
   <styled-content style="fixed-case" class="styled-content">RCI</styled-content> for the 28 (3 + 3 + 10 + 12) decisions. For the 108 (3 × 3 × 12) historical predictions per species, we modeled the relationship across the 18 (3 + 3 + 12) decisions with model performance in extrapolation (3a) and cross‐validation (3b)
  </p>
 </caption>
 <graphic id="nlm-graphic-3" xlink:href="ECE3-7-8841-g001" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
</fig>
