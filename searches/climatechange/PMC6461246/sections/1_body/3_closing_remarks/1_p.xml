<?xml version="1.0" encoding="UTF-8"?>
<p class="p">This paper devises a smooth Bayesian model based on penalized splines so to track time-varying conformance to Benford’s law. We have explored the dynamics of the first- and second-digit probability to test the homogeneity of the GTC dataset by comparing the variation with Benford’s Law. Our model enables us to track directly spans of years at which conformance to Benford’s Law is lower, and therefore facilitates the statistical inference about the intrinsic distribution of the first or second digits by evaluating discrepancies from Benford’s Law. Numerical studies in the 
 <xref ref-type="supplementary-material" rid="pone.0213300.s001" class="xref">S1 File</xref> show that our method avoids pitfalls faced by pointwise empirical approaches. With respect to our empirical findings versus those of [
 <xref rid="pone.0213300.ref008" ref-type="bibr" class="xref">8</xref>]. There seems to be a consensus that the heterogeneity up to early 20th century could be mainly induced by the incomplete management of cyclone records and inevitable measurement errors. Technological developments in the 20th century have enable meteorologists to detect even tiny cyclones and to precisely locate the tracks of those cyclones, which results in the consistently increasing number of cyclones until the 1970s. Our results suggest that heterogeneity starts increasing again, even though the frequency of cyclones has been stable since the 1970s. While technological improvements are cumulative we find that the most recent heterogeneity levels actually tend to be higher than the ones from 1842 to 1890 (see 
 <xref ref-type="fig" rid="pone.0213300.g004" class="xref">Fig 4</xref>); this finding seems to contradict [
 <xref rid="pone.0213300.ref008" ref-type="bibr" class="xref">8</xref>] (cf 
 <xref ref-type="fig" rid="pone.0213300.g005" class="xref">Fig 5</xref> in their paper), possibly due to the above-mentioned bias issue.
</p>
