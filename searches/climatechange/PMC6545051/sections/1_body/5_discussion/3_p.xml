<?xml version="1.0" encoding="UTF-8"?>
<p class="p">The reframing of the risk question from the prediction space to the decision space may seem uncomfortable from a physical science perspective, but is in fact quite orthodox from the perspective of statistical inference. Despite the widespread use of 
 <italic class="italic">p</italic>-values as an ostensibly objective measure of statistical significance, the inference derived from data concerning a particular hypothesis is far from a straightforward matter and involves many assumptions [
 <xref rid="RSPA20190013C66" ref-type="bibr" class="xref">66</xref>]. In the Neyman–Pearson framework, the inference problem is regularized by placing it in a decision context between two alternative hypotheses, which takes into account the possibility of both type 1 and type 2 errors [
 <xref rid="RSPA20190013C67" ref-type="bibr" class="xref">67</xref>]. In the Bayesian framework, the strength of evidence between these alternative hypotheses (
 <italic class="italic">H</italic>
 <sub class="sub">1</sub> and 
 <italic class="italic">H</italic>
 <sub class="sub">2</sub>) provided by the data 
 <italic class="italic">D</italic> is given by 
 <disp-formula id="RSPA20190013M6.1" class="disp-formula">
  <label class="label">6.1</label>
  <math id="DM9" class="math">
   <mfrac class="mfrac">
    <mrow class="mrow">
     <mi class="mi">P</mi>
     <mo stretchy="false" class="mo">(</mo>
     <mrow class="mrow">
      <msub class="msub">
       <mi class="mi">H</mi>
       <mn class="mn">2</mn>
      </msub>
     </mrow>
     <mrow class="mrow">
      <mo stretchy="false" class="mo">|</mo>
     </mrow>
     <mi class="mi">D</mi>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
    <mrow class="mrow">
     <mi class="mi">P</mi>
     <mo stretchy="false" class="mo">(</mo>
     <mrow class="mrow">
      <msub class="msub">
       <mi class="mi">H</mi>
       <mn class="mn">1</mn>
      </msub>
     </mrow>
     <mrow class="mrow">
      <mo stretchy="false" class="mo">|</mo>
     </mrow>
     <mi class="mi">D</mi>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
   </mfrac>
   <mo class="mo">=</mo>
   <mfrac class="mfrac">
    <mrow class="mrow">
     <mi class="mi">P</mi>
     <mo stretchy="false" class="mo">(</mo>
     <mi class="mi">D</mi>
     <mrow class="mrow">
      <mo stretchy="false" class="mo">|</mo>
     </mrow>
     <mrow class="mrow">
      <msub class="msub">
       <mi class="mi">H</mi>
       <mn class="mn">2</mn>
      </msub>
     </mrow>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
    <mrow class="mrow">
     <mi class="mi">P</mi>
     <mo stretchy="false" class="mo">(</mo>
     <mi class="mi">D</mi>
     <mrow class="mrow">
      <mo stretchy="false" class="mo">|</mo>
     </mrow>
     <mrow class="mrow">
      <msub class="msub">
       <mi class="mi">H</mi>
       <mn class="mn">1</mn>
      </msub>
     </mrow>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
   </mfrac>
   <mfrac class="mfrac">
    <mrow class="mrow">
     <mi class="mi">P</mi>
     <mo stretchy="false" class="mo">(</mo>
     <mrow class="mrow">
      <mrow class="mrow">
       <msub class="msub">
        <mi class="mi">H</mi>
        <mn class="mn">2</mn>
       </msub>
      </mrow>
     </mrow>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
    <mrow class="mrow">
     <mi class="mi">P</mi>
     <mo stretchy="false" class="mo">(</mo>
     <mrow class="mrow">
      <mrow class="mrow">
       <msub class="msub">
        <mi class="mi">H</mi>
        <mn class="mn">1</mn>
       </msub>
      </mrow>
     </mrow>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
   </mfrac>
   <mo class="mo">,</mo>
  </math>
 </disp-formula> which follows directly from Bayes' theorem. The Bayes factor 
 <italic class="italic">P</italic>(
 <italic class="italic">D</italic>|
 <italic class="italic">H</italic>
 <sub class="sub">2</sub>)/
 <italic class="italic">P</italic>(
 <italic class="italic">D</italic>|
 <italic class="italic">H</italic>
 <sub class="sub">1</sub>) is independent of the prior likelihoods 
 <italic class="italic">P</italic>(
 <italic class="italic">H</italic>
 <sub class="sub">2</sub>) and 
 <italic class="italic">P</italic>(
 <italic class="italic">H</italic>
 <sub class="sub">1</sub>), so can be considered objective, but it does not represent any sort of absolute knowledge—only an increment in knowledge, relative to the prior beliefs.
</p>
