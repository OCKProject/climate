<?xml version="1.0" encoding="UTF-8"?>
<p class="p">Although the FPH of the species (
 <xref ref-type="fig" rid="pone.0211171.g005" class="xref">Fig 5</xref>) extends beyond the calibration area of the model (
 <bold class="bold">M</bold>), it was already expected an area of potential species habitat larger than the real distribution [
 <xref rid="pone.0211171.ref065" ref-type="bibr" class="xref">65</xref>]. Consequently, projections beyond the time interval of a training dataset (distribution in future dates) require cautious interpretations to avoid possible misinterpretations [
 <xref rid="pone.0211171.ref096" ref-type="bibr" class="xref">96</xref>]. Such caution is because AUC values tend to increase when the selected background area is larger than the observed current habitat of a species [
 <xref rid="pone.0211171.ref097" ref-type="bibr" class="xref">97</xref>]. Although the AUC values (close to 1) showed that the models performed very well with the results [
 <xref rid="pone.0211171.ref090" ref-type="bibr" class="xref">90</xref>, 
 <xref rid="pone.0211171.ref091" ref-type="bibr" class="xref">91</xref>] (better than any model generated with a set of random predictors [
 <xref rid="pone.0211171.ref083" ref-type="bibr" class="xref">83</xref>]), it was necessary to use a different approach to evaluate the models. In the AUC metric, the weight of commission errors is much lower than that of omission errors, which makes it an inappropriate performance measurement [
 <xref rid="pone.0211171.ref098" ref-type="bibr" class="xref">98</xref>].
</p>
