<?xml version="1.0" encoding="UTF-8"?>
<p class="p">The decision tree was carried out singly for each climate model. To avoid over-fitting in the decision tree results, we evaluated the optimal number of subdivisions through 10,000 cross-validations, which measured the relative error with the addition of a new subdivision (
 <italic class="italic">node</italic>); in other words, a balance between accuracy of prediction and model complexity [
 <xref rid="pone.0162500.ref040" ref-type="bibr" class="xref">40</xref>]. Due to cross-validation removing unnecessary subdivisions and the use of one variable for each step (a characteristic of the decision tree), there is no risk of overparameterization because the method selects only the most efficient variables for creating groups [
 <xref rid="pone.0162500.ref040" ref-type="bibr" class="xref">40</xref>]. To evaluate the efficiency of the decision tree to correctly classify landcover categories, we conducted a random forest with 10,000 random trees generated by bootstrap sampling. The analyses were conducted in R software, using the 
 <italic class="italic">rpart</italic> [
 <xref rid="pone.0162500.ref041" ref-type="bibr" class="xref">41</xref>] and 
 <italic class="italic">randomForest</italic> packages [
 <xref rid="pone.0162500.ref042" ref-type="bibr" class="xref">42</xref>].
</p>
