<?xml version="1.0" encoding="UTF-8"?>
<p class="p">The 532 translated text units served as the main text corpus. For analyses, texts were further processed using standard procedures such as lowercase conversion, deletion of stopwords, punctuation, and numbers, and stemming (
 <xref rid="B26" ref-type="bibr" class="xref">Grimmer and Stewart, 2013</xref>; 
 <xref rid="B73" ref-type="bibr" class="xref">Welbers et al., 2017</xref>). According to the 
 <italic class="italic">bag-of-words</italic> assumption, a text is viewed as a collection of words regardless of sequence and linguistic structures (
 <xref rid="B45" ref-type="bibr" class="xref">Lucas et al., 2015</xref>); although this omits information, pertinent research has shown that this approach is able to capture much of the meaningful content. This reduction can be understood as a kind of normalization of texts, condensing natural text to its basic lexical content. For the reduced texts, mean word number was 
 <italic class="italic">M</italic> = 40.9 per recollection (
 <italic class="italic">SD</italic> = 36.8, 
 <italic class="italic">Median</italic> = 31), with little difference between Stage 1 (
 <italic class="italic">M</italic> = 41.5) and Stage 2 (
 <italic class="italic">M</italic> = 40.3). After normalization, 12 text units had zero words and were excluded from the following analyses.
</p>
