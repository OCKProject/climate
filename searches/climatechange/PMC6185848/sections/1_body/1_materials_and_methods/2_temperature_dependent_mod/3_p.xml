<?xml version="1.0" encoding="UTF-8"?>
<p class="p">The deviance information criterion (DIC) was used as a crude index to compare models [
 <xref rid="pone.0205711.ref044" ref-type="bibr" class="xref">44</xref>]. The DIC is the sum of the mean deviance [deviance = −2 log (likelihood)] and of the effective number of parameters (pD; the posterior mean of the deviance minus the deviance of the posterior means). A difference of more than 10 in DIC was taken as a rough index of difference between two models and ruled out the model with the higher DIC [
 <xref rid="pone.0205711.ref044" ref-type="bibr" class="xref">44</xref>]. When the difference in DIC was less than 10, we selected the model with the best goodness of fit, i.e., with the lower deviance. To quantify the accuracy of the mean estimated parameter values, the goodness of fit of the selected model to the observed data for each pathogen was assessed using the root mean square error. The quality or predictive ability of the selected model was assessed using a Bayesian ‘p-value’ analogue calculated from the predictive posterior distribution [
 <xref rid="pone.0205711.ref045" ref-type="bibr" class="xref">45</xref>]. The Bayesian p-value quantifies the proportion of times when the lack of fit of a perfect data set (a replicated data set generated using the same model that is fitted to the actual data set) is greater than the lack of fit of the actual data set. A Bayesian p-value close to 0.5 indicates that the model is not consistently under-predicting (
 <italic class="italic">p</italic>-value near 0) or over-predicting (
 <italic class="italic">p</italic>-value near 1) [
 <xref rid="pone.0205711.ref046" ref-type="bibr" class="xref">46</xref>]. Bayesian p-values of &lt;0.1 and &gt;0.9 were considered extreme values and, hence, indications of where the predictive ability of the model was poor.
</p>
