<?xml version="1.0" encoding="UTF-8"?>
<p class="p">
 <italic class="italic">Objective understanding</italic> was measured as each participant’s accuracy in answering a graph question. Mean accuracy hence measured each participant’s mean accuracy to all graph questions. 
 <italic class="italic">Subjective understanding</italic> was measured as each participant’s confidence that they answered a question correctly. To measure calibration, the C-Index was used. The C-Index determines how much subjective confidence in understanding diverges from objective understanding by assessing the mean weighted difference between subjective confidence and objective understanding, computed for each level of confidence: 1/N·Σ n(r−c)
 <sup class="sup">2</sup>. N is the total number of tasks where subjective confidence ratings were elicited, n is the number of probabilities for each category, r is the numerical value of probability for category, c is the proportion of correct answers in each category [
 <xref rid="B22-ijerph-15-00875" ref-type="bibr" class="xref">22</xref>]. To do so, participants’ continuous confidence ratings were collapsed in three confidence categories: 25–50%, 51–75%, and 76–100% ([
 <xref rid="B22-ijerph-15-00875" ref-type="bibr" class="xref">22</xref>]; 50% and 75% were attached to the lower of two adjacent categories each to reduce overconfidence). To measure over-/underconfidence, the same formula as for calibration was used, only that the differences were not squared to achieve directed deviations: Positive values denote for overconfidence, negative values underconfidence.
</p>
