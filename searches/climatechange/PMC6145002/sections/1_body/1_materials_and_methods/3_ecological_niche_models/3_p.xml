<?xml version="1.0" encoding="UTF-8"?>
<p class="p">We generated the ENMs using four modeling algorithms: generalized linear models (GLM), boosted regression trees (BRT), random forests (RF), and support vector machines (SVM). These are statistical (GLM) and machine‐learning methods (BRT, RF, and SVM) known to produce reasonably reliable results, so detailed descriptions and usefulness of these algorithms can be found elsewhere (e.g., Araújo et al., 
 <xref rid="ece34357-bib-0002" ref-type="ref" class="xref">2011</xref>; Elith et al., 
 <xref rid="ece34357-bib-0018" ref-type="ref" class="xref">2006</xref>; Naimi &amp; Araújo, 
 <xref rid="ece34357-bib-0042" ref-type="ref" class="xref">2016</xref>; Vasconcelos, Antonelli, &amp; Napoli, 
 <xref rid="ece34357-bib-0057" ref-type="ref" class="xref">2017</xref>). The records were split into 20% for model evaluation (random test percentage) and the remaining 80% used for calibration (training). The models were evaluated by two metrics (see Allouche, Tsoar, &amp; Kadmon, 
 <xref rid="ece34357-bib-0001" ref-type="ref" class="xref">2006</xref>) that are briefly summarized: (a) the area under the curve (AUC) of the receiver operation characteristic (ROC), a threshold‐independent statistic that ranges from 0 (model equivalent to a random prediction) to 1 (perfect model discrimination between presence and absence records); and (b) the true skill statistic (TSS), a threshold‐dependent statistic that ranges from −1 (model equivalent to a random prediction) to 1 (perfect model fit). Here, ENMs with AUC &lt;0.75 or TSS &lt;0.3 were excluded from the ensemble procedure (see ahead) because their predictive powers were similar to random predictions.
</p>
