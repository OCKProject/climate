<?xml version="1.0" encoding="UTF-8"?>
<p id="Par35" class="p">To select informative paths, we used 
 <italic class="italic">Stochastic Search Variable Selection</italic> (SSVS) with global adaptation
 <sup class="sup">
  <xref ref-type="bibr" rid="CR66" class="xref">66</xref>
 </sup>. The variable selection procedure can be seen as one of deciding which of the regression parameters 
 <italic class="italic">β</italic>
 <sub class="sub">
  <italic class="italic">j</italic>
 </sub> in a given model are equal to zero. To denote whether the variable 
 <italic class="italic">j</italic> is present in the model, we used an indicator variable 
 <italic class="italic">I</italic>
 <sub class="sub">
  <italic class="italic">j</italic>
 </sub> (where 
 <italic class="italic">I</italic>
 <sub class="sub">
  <italic class="italic">j</italic>
 </sub> = 1 indicates presence, and 
 <italic class="italic">I</italic>
 <sub class="sub">
  <italic class="italic">j</italic>
 </sub> = 0 absence of variable 
 <italic class="italic">j</italic> in the model). The prior inclusion probability of all explanatory variables was set to 
 <italic class="italic">P</italic> = 0.5. The SSVS approach uses a mixture prior for each regression parameter 
 <italic class="italic">β</italic>
 <sub class="sub">
  <italic class="italic">j</italic>
 </sub> following the equation:
 <disp-formula id="Equ12" class="disp-formula">
  <label class="label">12</label>
  <alternatives class="alternatives">
   <tex-math id="M23" class="tex-math">\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$P({\beta }_{j}|{I}_{j})=(1-{I}_{j})\cdot {\rm{Normal}}(0,{\tau }_{\beta })+{I}_{j}\cdot {\rm{Normal}}(0,g{\tau }_{\beta }),$$\end{document}</tex-math>
   <math id="M24" display="block" class="math">
    <mi class="mi">P</mi>
    <mrow class="mrow">
     <mo stretchy="false" class="mo">(</mo>
     <mrow class="mrow">
      <msub class="msub">
       <mrow class="mrow">
        <mi class="mi">β</mi>
       </mrow>
       <mrow class="mrow">
        <mi class="mi">j</mi>
       </mrow>
      </msub>
      <mo class="mo">|</mo>
      <msub class="msub">
       <mrow class="mrow">
        <mi class="mi">I</mi>
       </mrow>
       <mrow class="mrow">
        <mi class="mi">j</mi>
       </mrow>
      </msub>
     </mrow>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
    <mo class="mo">=</mo>
    <mrow class="mrow">
     <mo stretchy="false" class="mo">(</mo>
     <mrow class="mrow">
      <mn class="mn">1</mn>
      <mo class="mo">−</mo>
      <msub class="msub">
       <mrow class="mrow">
        <mi class="mi">I</mi>
       </mrow>
       <mrow class="mrow">
        <mi class="mi">j</mi>
       </mrow>
      </msub>
     </mrow>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
    <mo class="mo">⋅</mo>
    <mi mathvariant="normal" class="mi">Normal</mi>
    <mrow class="mrow">
     <mo stretchy="true" class="mo">(</mo>
     <mrow class="mrow">
      <mn class="mn">0</mn>
      <mo class="mo">,</mo>
      <msub class="msub">
       <mrow class="mrow">
        <mi class="mi">τ</mi>
       </mrow>
       <mrow class="mrow">
        <mi class="mi">β</mi>
       </mrow>
      </msub>
     </mrow>
     <mo stretchy="true" class="mo">)</mo>
    </mrow>
    <mo class="mo">+</mo>
    <msub class="msub">
     <mrow class="mrow">
      <mi class="mi">I</mi>
     </mrow>
     <mrow class="mrow">
      <mi class="mi">j</mi>
     </mrow>
    </msub>
    <mo class="mo">⋅</mo>
    <mi mathvariant="normal" class="mi">Normal</mi>
    <mrow class="mrow">
     <mo stretchy="false" class="mo">(</mo>
     <mrow class="mrow">
      <mn class="mn">0</mn>
      <mo class="mo">,</mo>
      <mi class="mi">g</mi>
      <msub class="msub">
       <mrow class="mrow">
        <mi class="mi">τ</mi>
       </mrow>
       <mrow class="mrow">
        <mi class="mi">β</mi>
       </mrow>
      </msub>
     </mrow>
     <mo stretchy="false" class="mo">)</mo>
    </mrow>
    <mo class="mo">,</mo>
   </math>
   <graphic xlink:href="41598_2017_10772_Article_Equ12.gif" position="anchor" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
  </alternatives>
 </disp-formula>where the first density (the spike) is centred around zero and has a small variance
 <sup class="sup">
  <xref ref-type="bibr" rid="CR66" class="xref">66</xref>
 </sup>. Here we use a random effects variant of SSVS
 <sup class="sup">
  <xref ref-type="bibr" rid="CR66" class="xref">66</xref>
 </sup>, in which in the spike part of the prior 
 <italic class="italic">τ</italic>
 <sub class="sub">
  <italic class="italic">β</italic>
 </sub> is fixed to a constant (
 <italic class="italic">τ</italic>
 <sub class="sub">
  <italic class="italic">β</italic>
 </sub> = 3,600), and in the slab part of the prior the product g
 <italic class="italic">τ</italic>
 <sub class="sub">
  <italic class="italic">β</italic>
 </sub> is estimated by the model. The variance 
 <italic class="italic">σ</italic>
 <sup class="sup">2</sup>
 <sub class="sub">
  <italic class="italic">β</italic>
 </sub> = g
 <italic class="italic">τ</italic>
 <sub class="sub">
  <italic class="italic">β</italic>
 </sub>
 <sup class="sup">−0.5</sup> was drawn from a uniform prior between 0 and 20. This form of global adaptation has the advantage of facilitating the tuning of the variable selection, because the distribution of each coefficient is shrunk towards the correct region of the parameter space by the other coefficients in the model. In order to infer which of the variables should be included in the models, we used Bayes factors
 <sup class="sup">
  <xref ref-type="bibr" rid="CR66" class="xref">66</xref>
 </sup>.
</p>
