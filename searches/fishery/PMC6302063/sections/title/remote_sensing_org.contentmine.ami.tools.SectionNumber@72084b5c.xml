<?xml version="1.0" encoding="UTF-8"?>
<sec id="Sec8" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Remote Sensing</div>
 <p id="Par14" xmlns="http://www.w3.org/1999/xhtml">Using ENVI 5.4 software, area changes for palsas, vegetation, and surface water were assessed at The Big Marsh 
  <span class="italic">—</span>all of which contributed to the characterization of the exposure. This specific peatland was evaluated because it was frequented by community members for berry picking, palsas were present in the bog, and it overlapped with readily accessible satellite imagery. Courtesy of the DigitalGlobe Foundation, a 2004 Quickbird image and a 2016 World View 2 image were acquired — both of which have fine enough spatial resolution to detect palsas. Pre-proccessing of images included radiometric and atmospheric correction with the FLAASH algorithm via tools available through ENVI 5.4. The 2004 and 2016 images were co-registered following the approach of Andresen and Lougheed (
  <a ref-type="bibr" rid="CR2" href="#CR2">2015</a>). For this study, there were a limited number of identifiable tie points due to a coarser resolution in the 2004 image and little built infrastructure surrounding the peatland, so 11 tie points were used with a final RMSE of 1.90 m.
 </p>
 <p id="Par15" xmlns="http://www.w3.org/1999/xhtml">For palsas, the manual target detection approach used by Beck 
  <span class="italic">et al.</span> (
  <a ref-type="bibr" rid="CR8" href="#CR8">2015</a>) and Bouchard 
  <span class="italic">et al.</span> (
  <a ref-type="bibr" rid="CR11" href="#CR11">2014</a>) was applied. Additionally, following the approach of Sannel and Kuhry (
  <a ref-type="bibr" rid="CR54" href="#CR54">2011</a>), we used the panchromatic bands with the aid of the multispectral bands to identify palsas. Automatic target detection, with the matched Filtering (MF) algorithm, was used to identify any green vegetation and surface water in the 2004 and 2016 images. To assess the target detection, the separability between vegetation, water, and the unclassified areas was computed with Jeffries-Matusita separability measures. All combinations of features had Jeffries-Matusita separability measures greater than 1 indicating good spectral separability (Richards and Jia 
  <a ref-type="bibr" rid="CR50" href="#CR50">2006</a>). Following Richards and Jia (
  <a ref-type="bibr" rid="CR50" href="#CR50">2006</a>), we calculated the following classification accuracy metrics: overall accuracy, producer accuracy, and user accuracy. The user accuracy, which is the chance that a pixel labeled vegetation or water is actually vegetation or water, was 81.82 and 87.50% for the surface water class in 2004 and 2016 respectively, and 100% for the vegetation class in both 2004 and 2016. The producer accuracy and the overall accuracy were lower for both classes meaning that not all vegetation or water reference pixels were classified as vegetation or surface water pixels during the automatic target detection.
 </p>
</sec>
