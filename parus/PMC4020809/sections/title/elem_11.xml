<?xml version="1.0" encoding="UTF-8"?>
<sec id="s2d1" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">The spectrogram as an image</div>
 <p xmlns="http://www.w3.org/1999/xhtml">In our work, we do not follow the framework of audio analysis but the framework of image analysis. Treating the audio scene as a picture means looking at the spectrogram as a canvas where the acoustic events appear as localised spectral blobs on a two-dimensional matrix (see 
  <a ref-type="fig" rid="pone-0096936-g003" href="#pone-0096936-g003">Fig. 3</a>). Once these spectral blobs are extracted, many feature extraction techniques can be applied exclusively on these spectral patches while ignoring the rest of the spectrum. In this section we describe how we extract the regions of interest (ROIs) from the spectrogram.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">The recording is firstly amplitude normalized. Then morphological operations are applied on the image. These operation have as function to derive masks of spectral blobs by connecting regions of high amplitude that correspond to calls or phrases and to eliminate small regions of high amplitude that cannot belong to animal vocalizations because they are too small. Several approaches have been tried as: removing from the image a blurred version of the same image as well as removing the morphological opening of the image. First a morphological opening on an image is applied that can remove small bright spots. Opening is defined as an erosion followed by a dilation. Erosion shrinks bright regions and enlarges dark regions. Dilation has the opposite effect of erosion and enlarges bright regions and shrinks dark regions. The border segments are dropped as the lower part correspond almost always to low-pass noise spectral patches. All these different are standard approaches in image processing having as a result to remove background illumination and extract spectral blobs 
  <a rid="pone.0096936-Shih1" ref-type="bibr" href="#pone.0096936-Shih1">[21]</a>.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">As an example, in the sample image (see 
  <a ref-type="fig" rid="pone-0096936-g003" href="#pone-0096936-g003">Fig. 3</a>), the background illumination is less bright at the bottom of the image than at the centre or top. This is due to the sound of nearby running water and wind that corrupt the low frequencies of the spectrum. After the morphological operations are applied the picture of the spectrogram is made binary in order to mark the masks of the spectral blobs.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">Binarization is realised by thresholding the image to the 90% percentile of the data (i.e. that is the highest 90% value). Subsequently we label the connected components in the 2-D binary image to derive the masks where the ROIs exist. We call ROIs the spectral patches cropped by the associated masks. Small masks (smaller than a fixed number of pixels) are discarded (see 
  <a ref-type="fig" rid="pone-0096936-g004" href="#pone-0096936-g004">Fig. 4</a>). The threshold for removing small masks is derived by observing short but perceptible calls from the training data and the number of pixels is set to 100. The ROIs are the patches from the original spectrogram that correspond to the pixel coordinates of the masks. All the ROIs extracted from the training set and test set are stored along with the frequency location from which they were cropped. The time information is dropped as an animal can vocalise at any time within a recording but only at the frequencies of its repertoire (see 
  <a ref-type="fig" rid="pone-0096936-g005" href="#pone-0096936-g005">Fig. 5</a> for the segments extracted from the recording of 
  <a ref-type="fig" rid="pone-0096936-g003" href="#pone-0096936-g003">Fig. 3</a>).
 </p>
 <div id="pone-0096936-g004" orientation="portrait" position="float" class="fig" xmlns="http://www.w3.org/1999/xhtml">
  <span pub-id-type="doi" class="object-id">10.1371/journal.pone.0096936.g004</span>
  <span class="label">Figure 4</span>
  <div class="caption">
   <div class="title">Detected spectrogram blobs of 
    <a ref-type="fig" rid="pone-0096936-g003" href="#pone-0096936-g003">Fig. 3</a>.
   </div>
   <p>Derivations and enumeration of the masks. Axis are enumerated according to their pixel index.</p>
  </div>
  <div xlink:href="pone.0096936.g004" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
 </div>
 <div id="pone-0096936-g005" orientation="portrait" position="float" class="fig" xmlns="http://www.w3.org/1999/xhtml">
  <span pub-id-type="doi" class="object-id">10.1371/journal.pone.0096936.g005</span>
  <span class="label">Figure 5</span>
  <div class="caption">
   <div class="title">ROIs extracted after applying the masks of Fig. 4 onto the spectrogram of 
    <a ref-type="fig" rid="pone-0096936-g003" href="#pone-0096936-g003">Fig. 3</a>, enumerated and catalogued.
   </div>
   <p>The same procedure is followed for all recordings.</p>
  </div>
  <div xlink:href="pone.0096936.g005" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
 </div>
 <p xmlns="http://www.w3.org/1999/xhtml">
  <a ref-type="fig" rid="pone-0096936-g005" href="#pone-0096936-g005">Fig. 5</a> illustrates the ROIâ€™s extracted from a single recording. The 16798 ROIs of all 1687 recordings are automatically extracted, enumerated and catalogued in under 12 minutes using an i7, 3.4 GHz machine. This is a distinct difference from the seminal approach of 
  <a rid="pone.0096936-Briggs1" ref-type="bibr" href="#pone.0096936-Briggs1">[5]</a> where the ROIs are manually extracted, which is very time-consuming and practically impossible when the number of recordings is large. Cataloguing entails storing the spectral patches and the frequency borders in pixel coordinates from where it was extracted. Everything else but the ROIs is discarded from the data.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">The benefits of extracting the ROIs are:</p>
 <div list-type="alpha-lower" class="list" xmlns="http://www.w3.org/1999/xhtml">
  <div class="list-item">
   <p>The great reduction of variability between recordings. Every further analysis of our database will be done in reference to these ROIs alone while the rest of the spectrum is disregarded (compare 
    <a ref-type="fig" rid="pone-0096936-g005" href="#pone-0096936-g005">Fig. 5</a> to the original 
    <a ref-type="fig" rid="pone-0096936-g003" href="#pone-0096936-g003">Fig. 3</a>).
   </p>
  </div>
  <div class="list-item">
   <p>Once extracted these ROIs allow us to derive a plethora of features with gradual increase in sophistication namely: Marginal over time measurements, statistical descriptors of the shape of the ROIs and finally how the ROIs of the training set alone correlate to the spectrograms of the test set.</p>
  </div>
 </div>
</sec>
