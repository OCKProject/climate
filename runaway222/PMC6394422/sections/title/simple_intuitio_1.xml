<?xml version="1.0" encoding="UTF-8"?>
<sec id="Sec2" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Simple intuitions on combining measurements</div>
 <p id="Par5" xmlns="http://www.w3.org/1999/xhtml">Suppose we have one measurement platform for ECS whose sources of error are known and are unbiased. When this platform returns a value for ECS, then the true value for ECS may be either higher or lower according to how the measurement is deflected by its noise. Unable to know the deflection, we intuitively focus on the measured value and ignore the uncertainty. Confronted with the results of two independent measurements, our intuitions are less clear. If the two measurements agree, we tend to see confirmation and feel more confident in the common result. If they strongly disagree, the effect is often to temporize and await more evidence. Such slow deliberative thinking (Kahneman 
  <a ref-type="bibr" rid="CR20" href="#CR20">2011</a>) is often praised as cautious, in contrast to precipitously acting on impulse. However, in cases where decisions cannot be postponed, we need probabilistic thinking. In the simple statistical error model which most practitioners have learned, the measurements would be modeled as perturbed by independent identically distributed additive error terms. The estimate minimizing mean square error is the mean of the observations and the variance of the estimate is the variance of a single error term divided by the number of observations,
  <a ref-type="fn" rid="Fn1" href="#Fn1">1</a> regardless whether the measurements are concordant or discordant.
 </p>
 <p id="Par7" xmlns="http://www.w3.org/1999/xhtml">The intuition that concordant measurements should confer more confidence than discordant measurements is not attested by the simple error model most practitioners know. There are many other examples illustrated in Section 
  <a rid="Sec4" ref-type="sec" href="#Sec4">4</a>. This simple error model cannot account for “negative learning” where we become more uncertain after retrieving a measured value than we were before (Oppenheimer and O’Neill 
  <a ref-type="bibr" rid="CR23" href="#CR23">2008</a>; Hanea et al. 
  <a ref-type="bibr" rid="CR18" href="#CR18">2018</a>). Two measurements may return the same values but with different noise, resulting in different predictions. Two measurements may separately produce the same prediction, yet result in a different prediction when combined. Two strongly conflicting measurements may jointly yield a great deal of information about the unknown quantity.
 </p>
 <p id="Par8" xmlns="http://www.w3.org/1999/xhtml">It is common to attribute such divergence between intuitions and simple error models to a difference between classical and Bayesian approaches. Indeed, the features mentioned in the previous paragraph can be ascribed to the interaction between measurement error and a prior distribution on the variable of interest. Bayesian nets are used to illustrate the complexities of combining measurements. However, the appendix shows that the distinction between classical and Bayesian methods is more apparent than real in the contexts of multiple measurement platforms with well-defined error properties: The key idea is that an unknown variable of interest 
  <span class="italic">X</span> can be modeled as 
  <span class="italic">Z + e</span> where 
  <span class="italic">Z</span> is the unknown measured value and 
  <span class="italic">e</span> is the error with a known distribution. Upon measuring 
  <span class="italic">Z = z</span>, 
  <span class="italic">X</span> can be ascribed the distribution of 
  <span class="italic">z + e</span>. Subsequent measurements can be seen as updating this “prior.” This ascription cannot be described as probabilistic conditionalization as 
  <span class="italic">Z</span> does not have a distribution, but it can be described as “Renyi conditionalization” (Renyi 
  <a ref-type="bibr" rid="CR25" href="#CR25">1970</a>). Alternatively, we can simply compute the conditional error distributions given the observed values and arrive at the same results without ascribing a distribution to 
  <span class="italic">X</span>. The two approaches are equivalent. The appendix gives details and provides a simple mathematical model which mimics the results in Section 
  <a rid="Sec4" ref-type="sec" href="#Sec4">4</a> on concordant and discordant measurements.
 </p>
 <p id="Par9" xmlns="http://www.w3.org/1999/xhtml">Neither the simple error model nor our simple intuitions can do justice to the complexities of probabilistic inference with multiple lines of evidence. Real examples combined with graphical software tools for probabilistic inference can help to hone our intuitions.</p>
</sec>
