<?xml version="1.0" encoding="UTF-8"?>
<sec id="Sec14" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Human centered design – initial design and iterative improvement</div>
 <p id="Par34" xmlns="http://www.w3.org/1999/xhtml">Based on the interviews, we designed an initial version of the performance feedback dashboard between August and November 2017, which was then iteratively improved in two additional design cycles based on additional end-user feedback from five physicians in November and December 2017 (Additional file 
  <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Table S1). The first major iteration was developed after three additional interviews; the second and last major iteration was developed after another two interviews that revealed only minor required changes (Table 
  <a rid="Tab1" ref-type="table" href="#Tab1">1</a>), after which the design process was finalized.
  <div id="Tab1" class="table-wrap">
   <span class="label">Table 1</span>
   <div class="caption">
    <p>Design decisions made during human-centered design</p>
   </div>
   <table frame="hsides" rules="groups">
    <thead>
     <tr>
      <th>Interview observations</th>
      <th>Design solution - initial design</th>
      <th>Rationale</th>
      <th>Iterative improvement based on follow-up interviews</th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td colspan="4">Metrics</td>
     </tr>
     <tr>
      <td> a) Summary measures</td>
      <td>n patients, n patients by area, n patients by shift, n patients by discharge disposition</td>
      <td>To give physicians an overview of the patients they saw in a month. Show the area of care and shifts as it might affect case mix</td>
      <td/>
     </tr>
     <tr>
      <td> b) Length of stay metrics</td>
      <td>Provider to decision time, overall LOS
       <span class="sup">a</span> (median)
      </td>
      <td>Overall LOS is most important for ED, but provider-decision time is easier to influence by provider</td>
      <td>‘Provider to decision time’ changed to ‘Room to decision time’ as patients might see another provider in the waiting area (iteration 1)</td>
     </tr>
     <tr>
      <td> c) Utilization of tests</td>
      <td>CT, MR, US, lab utilization (%)</td>
      <td>Can be affected by physician and is known to affect LOS</td>
      <td/>
     </tr>
     <tr>
      <td> d) Outcomes</td>
      <td>72-h return rates, deaths (%), LOS after admission (median)</td>
      <td>To address concerns about negative outcomes, return-rates and deaths were included. LOS after admission was included as a proxy measure of appropriateness of admissions</td>
      <td>Removed deaths as an outcome as it is not feasible to reliably obtain data from EMR (iteration 1)</td>
     </tr>
     <tr>
      <td colspan="4">Comparisons</td>
     </tr>
     <tr>
      <td> a) Over time</td>
      <td>Monthly intervals</td>
      <td>Balance between too frequent reports with random variation and too infrequent where physicians don’t remember what happened</td>
      <td/>
     </tr>
     <tr>
      <td> b) To peers</td>
      <td>Blinded ranking (e.g. ‘your ranking 46/60’, with outcomes of peers with better or worse numbers shown).
       <span class="break"/>Overall ED medians are shown on separate page
      </td>
      <td>Blinded since all interviewed physicians agreed un-blinded was not desired/needed. A ranking showing neighboring peers was included to give physicians an attainable goal</td>
      <td>Changed the ranking to interquartile range of peers instead, since the optimum rate is likely someplace in the middle, outliers in either direction can be a problem (iteration 1)</td>
     </tr>
     <tr>
      <td colspan="4">Functionality</td>
     </tr>
     <tr>
      <td> a) Ease of access</td>
      <td>Monthly email summary with 3 measures that can be selected by ED leadership based on priorities</td>
      <td>Easy to access</td>
      <td/>
     </tr>
     <tr>
      <td> b) Drilldown functionality</td>
      <td>Option to access full dashboard through a link in monthly email</td>
      <td>Drilldown functionality</td>
      <td>Added tabs to drill down based on the type of shift (e.g. night) and assigned area. (iteration 1)</td>
     </tr>
     <tr>
      <td> c) Customization</td>
      <td>Physicians can select measures to show up on their own favorites page
       <span class="break"/>Leadership can select measures in monthly email
      </td>
      <td>Customization options for individual physicians and leadership based on ED priorities</td>
      <td/>
     </tr>
     <tr>
      <td colspan="4">Barriers</td>
     </tr>
     <tr>
      <td> a) Adverse consequences on quality of care</td>
      <td>Inclusion of outcomes on dashboard</td>
      <td>To avoid focus only on throughput and utilization measures, which might result in adverse consequences</td>
      <td/>
     </tr>
     <tr>
      <td> b) Conflicting teaching responsibilities</td>
      <td>–</td>
      <td>As this was not the goal of the dashboard, no measures related to teaching were included</td>
      <td/>
     </tr>
     <tr>
      <td> c) Data accuracy</td>
      <td>–</td>
      <td>Extensive validation of data is required</td>
      <td>Included definition of the measures on the dashboard.
       <span class="break"/>Made section headers very clear (iteration 2)
      </td>
     </tr>
     <tr>
      <td> d) Case-mix adjustment</td>
      <td>Show total number of patients during different shifts and in different areas of care.</td>
      <td>By showing these measures, physicians can put other measures in context.</td>
      <td>Added tabs to drilldown by area of care and type of shift (iteration 1)</td>
     </tr>
    </tbody>
   </table>
   <div class="table-wrap-foot">
    <p>
     <span class="italic">Abbreviations</span>: 
     <span class="italic">CT</span> computed tomography scan, 
     <span class="italic">ED</span> emergency department, 
     <span class="italic">EMR</span> electronic medical record, 
     <span class="italic">n</span> number, 
     <span class="italic">MR</span> magnetic resonance imaging, 
     <span class="italic">US</span> ultrasound
    </p>
    <p>
     <span class="sup">a</span>Overall LOS is only shown on the overall ED page, not on individual physician dashboards
    </p>
   </div>
  </div>
 </p>
 <p id="Par35" xmlns="http://www.w3.org/1999/xhtml">The design incorporates a monthly summary email that includes a few selected measures to ensure the data is easy to access (Additional file 
  <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Figure S1). A link would be provided to an interactive performance dashboard with a variety of measures that can be accessed on demand (Additional file 
  <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Figure S2), to give physicians the opportunity to dive deeper into the data if desired. The interactive dashboard includes three pages: a “Personal” page showing a physician’s individual performance compared to their peers, an “Emergency Department” page showing the performance of the ED overall as a reference, and a “My Favorites” page that displays measures selected by individual physicians (Fig. 
  <a rid="Fig1" ref-type="fig" href="#Fig1">1</a>). During the iterative interviews, tabs were added to the pages to allow physicians to drill down by the timing of shift and the area of care within the ED as this reflects the severity of the cases, thereby providing an opportunity to adjust for case-mix. Table 
  <a rid="Tab1" ref-type="table" href="#Tab1">1</a> gives a complete overview of the design considerations in the human-centered design process and the iterative improvements made.
  <div id="Fig1" class="fig">
   <span class="label">Fig. 1</span>
   <div class="caption">
    <p>Top section of performance feedback dashboard. The top section of the designed prototype performance feedback dashboard. The name Jane Doe is a false name</p>
   </div>
   <div xlink:href="12913_2019_4084_Fig1_HTML" id="MO1" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
  </div>
 </p>
 <p id="Par36" xmlns="http://www.w3.org/1999/xhtml">The selection of measures for the dashboard was informed by audit and feedback best practices [
  <a ref-type="bibr" rid="CR12" href="#CR12">12</a>–
  <a ref-type="bibr" rid="CR14" href="#CR14">14</a>] and on information obtained during interviews in accordance with a human-centered design approach [
  <a ref-type="bibr" rid="CR18" href="#CR18">18</a>]. We specifically ensured a selection of measures that are actionable to physicians as this is a known requirement for effective audit and feedback interventions [
  <a ref-type="bibr" rid="CR13" href="#CR13">13</a>, 
  <a ref-type="bibr" rid="CR14" href="#CR14">14</a>]. The primary goal of the dashboard was to reduce overall patient LOS. However, to increase actionability of the measure, we focused on the time that can be influenced directly by physicians. In initial versions, this was the time from first physician to the time the physician makes the disposition decision (i.e. decision to admit to hospital, observation, or discharge). After additional interviews, we modified this to the time from when the patient is roomed until the disposition decision is made, as this more accurately represents the period directly influenced by the attending physician.
 </p>
 <p id="Par37" xmlns="http://www.w3.org/1999/xhtml">Test utilization data, including the percentage of patients with a CT scan, MR scan, ultrasound, and lab test, were included because they affect LOS and are directly controlled by the physician. The number of requested consultations was not included as the data were not readily available in the EMR. Outcome data were included to address concerns about unintended consequences related to the quality of care if the focus was merely on LOS and test utilization. Initially, we included 72-h return rates and number of deaths. However, deaths were excluded from later versions in response to concerns about the reliability of EMR-derived death-data. Hospital LOS after admission was included as a proxy measure of appropriateness of admission, with the assumption that a short LOS might indicate that the patient did not need to be admitted. The total number of patients with the breakdown by timing of shift, area of care, and discharge disposition was included to provide more context about the patient population seen. During iterative rounds of improvements, we added detailed definitions of the measures used and clarified section headers to improve comprehension and trust in the dashboard.</p>
 <p id="Par38" xmlns="http://www.w3.org/1999/xhtml">It was decided to report data by monthly intervals to minimize the effect of day-to-day random variation, but to also ensure physicians still remember what happened during a given period. Comparison data were provided on the “Emergency Department” page showing summary measures for the entire ED. On initial designs, comparison data was shown on the “Personal” page as a ranking that included blinded peer data to provide physicians with achievable goals for improvement. However, further feedback made it clear that a ranking was not perceived as appropriate because the highest or lowest score does not necessarily indicate the best or the worst performance. Instead, it was decided to show the interquartile range of all physicians.</p>
</sec>
