<?xml version="1.0" encoding="UTF-8"?>
<sec id="Sec8" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Results</div>
 <sec id="Sec9" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Human-centered design approach - interviews</div>
  <p id="Par27" xmlns="http://www.w3.org/1999/xhtml">A total of eight semi-structured interviews were performed to guide the initial design of the performance feedback dashboard between May and August 2017 (Additional file 
   <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Table S1). Half of the interviewees were male, their median time since starting residency was 12 years (range 9–45), and their median length of employment in the current ED was 8 years (range 2–31). Two of the interviewees had primarily leadership roles, three primarily clinical responsibilities, and three primarily academic responsibilities. Two were employed by the LA County Department of Health and six by USC. The median duration of the interviews was 57 min (range 35–77). Thematic saturation was achieved after seven interviews; no new themes emerged in the eighth interview.
  </p>
  <sec id="Sec10" class="sec">
   <div class="title" xmlns="http://www.w3.org/1999/xhtml">Dashboard content – metrics</div>
   <p id="Par28" xmlns="http://www.w3.org/1999/xhtml">Numerous metrics were discussed in the interviews, including the number of patients, their discharge disposition, and a variety of length of stay, utilization, and outcomes measures (Additional file 
    <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Table S2). Overall, the time between the moment a physician first sees the patient until the moment a disposition decision is made (i.e. decision to admit a patient to the hospital or discharge from the ED), was perceived to be the most relevant LOS metric. “
    <span class="italic">Provider to decision time. Yeah, I think that’s an important metric, I think that there’s probably some wiggle room in there. In general, I think that’s an important part of our job is to have a disposition decision within whatever time frame we deem to be appropriate</span>.” (Interview 7).
   </p>
   <p id="Par29" xmlns="http://www.w3.org/1999/xhtml">Additionally, test utilization, including CT scans, MR scans, and labs, was thought to be of interest, especially if compared to peer utilization. 
    <span class="italic">“I think the number of yes [sic], I order 500 CT-scans in a year, and somebody else orders three, would be interesting. It would be interesting to know the false positives and the false [negatives].”</span> (Interview 5). Interviewees also expressed an interest to know the outcomes of their decisions, or what happened to patients after they left the ED: “
    <span class="italic">Bounce backs, maybe? Stuff that’s, like, more subjective, like, you know, your decisions on the patient. [ …</span>] 
    <span class="italic">you admit someone to the floor and they die. Should they have gone to the ICU? Or you discharge them and they die. [ …</span>] 
    <span class="italic">That’d be nice to know.</span>” (Interview 2).
   </p>
  </sec>
  <sec id="Sec11" class="sec">
   <div class="title" xmlns="http://www.w3.org/1999/xhtml">Dashboard content – comparisons</div>
   <p id="Par30" xmlns="http://www.w3.org/1999/xhtml">Interviewees expressed the importance of comparing their data to others and of including historic trends. “
    <span class="italic">So ideally [the data] would be where you are, where you were the previous month, or the previous time last year. And then where the department is.</span>” (Interview 8). Ideally data would have to be aggregated on a weekly or monthly basis, as a day would not provide useful information because shifts vary day to day, while a year would be too long to remember. “
    <span class="italic">[ …</span>] 
    <span class="italic">if you wait too long then it doesn’t make any sense to you because you’re like, ‘That happened in September of last year. I don’t care. I don’t know what happened then.’ If you do it every day, then they’re kind of like, ‘Well, how am I supposed to know what I’m supposed to change?’</span>” (Interview 2). Interviewees wanted to receive their data compared to their peers in a blinded fashion. Some expressed discomfort with others seeing their data: “
    <span class="italic">I’m personally um, scared you know, scared to be compared with others.</span>” (Interview 3). Others didn’t think it would be necessary to share the data openly to achieve change: “
    <span class="italic">We serve as our sort of biggest critics already and that for us to see it is enough to be like a blow to an ego where you can say, ‘Oh wow, I’m that slow compared to my colleagues?’</span> ” (Interview 7).
   </p>
  </sec>
  <sec id="Sec12" class="sec">
   <div class="title" xmlns="http://www.w3.org/1999/xhtml">Dashboard functionality</div>
   <p id="Par31" xmlns="http://www.w3.org/1999/xhtml">Three key themes emerged in the discussions about desired functionality of the performance feedback dashboard. First, participants emphasized the need for the dashboard to be easily accessible to increase the likelihood that people would actually use the dashboard. “
    <span class="italic">If it’s like one more thing to do, I might not do it. It would have, it would have to be something that was like every time you logged in it popped up or something, or I would not look at it. Yeah. I’m not gonna go seek out that information.”</span> (Interview 4). On the other hand, physicians did want to be able to drill down the data further to know what happened during specific shifts or with specific patients. “
    <span class="italic">Ideally for people that have unscheduled returns, I would like to see why ... I would like their name, their medical record number so I could look them up and also then what happened to them on the return visit.”</span> (Interview 8). Lastly, interviewees expressed that they would like to see a certain level of customization to define metrics of interest for them: “a 
    <span class="italic">good dashboard should give you the ability to, um, customize it, customize the view and the parameters that you look at for your, for your position at that time. Um, and you should be able to change that on the fly.</span>” (Interview 1).
   </p>
  </sec>
  <sec id="Sec13" class="sec">
   <div class="title" xmlns="http://www.w3.org/1999/xhtml">Barriers and unintended consequences</div>
   <p id="Par32" xmlns="http://www.w3.org/1999/xhtml">A variety of concerns were brought up during the interviews. A performance dashboard might increase physician stress levels, dehumanize the patient experience, and potentially negatively affect the quality and safety of care: “
    <span class="italic">Yeah, if I’m seeing four patients an hour and I need to have a dispo [disposition decision] on each of them within an hour and a half or two hours or whatever the ED group tells you is the right metric then probably I’m cutting a lot of corners not having substance of conversations with the patient, not providing great patient care.</span>” (Interview 7). Additional concerns were related to physicians’ responsibility to teach the many residents in the ED, which could be negatively affected. “
    <span class="italic">A lot of times we give the residents a lot of leeway to think things through. And part of that is that we haven’t had to move on a very like super-fast time process. [ …</span>] 
    <span class="italic">if you’re having time in the ED as something you’re thinking about more than necessarily clinical accuracy, it’s ... it is gonna change the way we practice with supervision.”</span> (Interview 4).
   </p>
   <p id="Par33" xmlns="http://www.w3.org/1999/xhtml">Data accuracy was a concern as well, given that electronic medical record (EMR) data might not always be accurate. 
    <span class="italic">“All of your metrics are only as good as the people putting them in, and that’s always gonna be, you know, um, an issue with accuracy [ …</span>]. 
    <span class="italic">”</span> (Interview 1). Interviewees also expressed the need to correct for the acuity of patients seen and the shift. 
    <span class="italic">“Oh, if you work more night shifts you’re gonna see more of them [more challenging cases]. Probably have to control for shift in some way.”</span> (Interview 4). Additionally, concerns were expressed regarding gaming of the system and problems with attribution of patients to the right physician, especially in a teaching hospital with many residents. 
    <span class="italic">“When they’re finally put in to a room, they very well may see a different resident and attending at that point. So, there may be three different [physicians involved]. And that’s not even counting change of shift.</span>” (Interview 8).
   </p>
  </sec>
 </sec>
 <sec id="Sec14" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Human centered design – initial design and iterative improvement</div>
  <p id="Par34" xmlns="http://www.w3.org/1999/xhtml">Based on the interviews, we designed an initial version of the performance feedback dashboard between August and November 2017, which was then iteratively improved in two additional design cycles based on additional end-user feedback from five physicians in November and December 2017 (Additional file 
   <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Table S1). The first major iteration was developed after three additional interviews; the second and last major iteration was developed after another two interviews that revealed only minor required changes (Table 
   <a rid="Tab1" ref-type="table" href="#Tab1">1</a>), after which the design process was finalized.
   <div id="Tab1" class="table-wrap">
    <span class="label">Table 1</span>
    <div class="caption">
     <p>Design decisions made during human-centered design</p>
    </div>
    <table frame="hsides" rules="groups">
     <thead>
      <tr>
       <th>Interview observations</th>
       <th>Design solution - initial design</th>
       <th>Rationale</th>
       <th>Iterative improvement based on follow-up interviews</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td colspan="4">Metrics</td>
      </tr>
      <tr>
       <td> a) Summary measures</td>
       <td>n patients, n patients by area, n patients by shift, n patients by discharge disposition</td>
       <td>To give physicians an overview of the patients they saw in a month. Show the area of care and shifts as it might affect case mix</td>
       <td/>
      </tr>
      <tr>
       <td> b) Length of stay metrics</td>
       <td>Provider to decision time, overall LOS
        <span class="sup">a</span> (median)
       </td>
       <td>Overall LOS is most important for ED, but provider-decision time is easier to influence by provider</td>
       <td>‘Provider to decision time’ changed to ‘Room to decision time’ as patients might see another provider in the waiting area (iteration 1)</td>
      </tr>
      <tr>
       <td> c) Utilization of tests</td>
       <td>CT, MR, US, lab utilization (%)</td>
       <td>Can be affected by physician and is known to affect LOS</td>
       <td/>
      </tr>
      <tr>
       <td> d) Outcomes</td>
       <td>72-h return rates, deaths (%), LOS after admission (median)</td>
       <td>To address concerns about negative outcomes, return-rates and deaths were included. LOS after admission was included as a proxy measure of appropriateness of admissions</td>
       <td>Removed deaths as an outcome as it is not feasible to reliably obtain data from EMR (iteration 1)</td>
      </tr>
      <tr>
       <td colspan="4">Comparisons</td>
      </tr>
      <tr>
       <td> a) Over time</td>
       <td>Monthly intervals</td>
       <td>Balance between too frequent reports with random variation and too infrequent where physicians don’t remember what happened</td>
       <td/>
      </tr>
      <tr>
       <td> b) To peers</td>
       <td>Blinded ranking (e.g. ‘your ranking 46/60’, with outcomes of peers with better or worse numbers shown).
        <span class="break"/>Overall ED medians are shown on separate page
       </td>
       <td>Blinded since all interviewed physicians agreed un-blinded was not desired/needed. A ranking showing neighboring peers was included to give physicians an attainable goal</td>
       <td>Changed the ranking to interquartile range of peers instead, since the optimum rate is likely someplace in the middle, outliers in either direction can be a problem (iteration 1)</td>
      </tr>
      <tr>
       <td colspan="4">Functionality</td>
      </tr>
      <tr>
       <td> a) Ease of access</td>
       <td>Monthly email summary with 3 measures that can be selected by ED leadership based on priorities</td>
       <td>Easy to access</td>
       <td/>
      </tr>
      <tr>
       <td> b) Drilldown functionality</td>
       <td>Option to access full dashboard through a link in monthly email</td>
       <td>Drilldown functionality</td>
       <td>Added tabs to drill down based on the type of shift (e.g. night) and assigned area. (iteration 1)</td>
      </tr>
      <tr>
       <td> c) Customization</td>
       <td>Physicians can select measures to show up on their own favorites page
        <span class="break"/>Leadership can select measures in monthly email
       </td>
       <td>Customization options for individual physicians and leadership based on ED priorities</td>
       <td/>
      </tr>
      <tr>
       <td colspan="4">Barriers</td>
      </tr>
      <tr>
       <td> a) Adverse consequences on quality of care</td>
       <td>Inclusion of outcomes on dashboard</td>
       <td>To avoid focus only on throughput and utilization measures, which might result in adverse consequences</td>
       <td/>
      </tr>
      <tr>
       <td> b) Conflicting teaching responsibilities</td>
       <td>–</td>
       <td>As this was not the goal of the dashboard, no measures related to teaching were included</td>
       <td/>
      </tr>
      <tr>
       <td> c) Data accuracy</td>
       <td>–</td>
       <td>Extensive validation of data is required</td>
       <td>Included definition of the measures on the dashboard.
        <span class="break"/>Made section headers very clear (iteration 2)
       </td>
      </tr>
      <tr>
       <td> d) Case-mix adjustment</td>
       <td>Show total number of patients during different shifts and in different areas of care.</td>
       <td>By showing these measures, physicians can put other measures in context.</td>
       <td>Added tabs to drilldown by area of care and type of shift (iteration 1)</td>
      </tr>
     </tbody>
    </table>
    <div class="table-wrap-foot">
     <p>
      <span class="italic">Abbreviations</span>: 
      <span class="italic">CT</span> computed tomography scan, 
      <span class="italic">ED</span> emergency department, 
      <span class="italic">EMR</span> electronic medical record, 
      <span class="italic">n</span> number, 
      <span class="italic">MR</span> magnetic resonance imaging, 
      <span class="italic">US</span> ultrasound
     </p>
     <p>
      <span class="sup">a</span>Overall LOS is only shown on the overall ED page, not on individual physician dashboards
     </p>
    </div>
   </div>
  </p>
  <p id="Par35" xmlns="http://www.w3.org/1999/xhtml">The design incorporates a monthly summary email that includes a few selected measures to ensure the data is easy to access (Additional file 
   <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Figure S1). A link would be provided to an interactive performance dashboard with a variety of measures that can be accessed on demand (Additional file 
   <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Figure S2), to give physicians the opportunity to dive deeper into the data if desired. The interactive dashboard includes three pages: a “Personal” page showing a physician’s individual performance compared to their peers, an “Emergency Department” page showing the performance of the ED overall as a reference, and a “My Favorites” page that displays measures selected by individual physicians (Fig. 
   <a rid="Fig1" ref-type="fig" href="#Fig1">1</a>). During the iterative interviews, tabs were added to the pages to allow physicians to drill down by the timing of shift and the area of care within the ED as this reflects the severity of the cases, thereby providing an opportunity to adjust for case-mix. Table 
   <a rid="Tab1" ref-type="table" href="#Tab1">1</a> gives a complete overview of the design considerations in the human-centered design process and the iterative improvements made.
   <div id="Fig1" class="fig">
    <span class="label">Fig. 1</span>
    <div class="caption">
     <p>Top section of performance feedback dashboard. The top section of the designed prototype performance feedback dashboard. The name Jane Doe is a false name</p>
    </div>
    <div xlink:href="12913_2019_4084_Fig1_HTML" id="MO1" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
   </div>
  </p>
  <p id="Par36" xmlns="http://www.w3.org/1999/xhtml">The selection of measures for the dashboard was informed by audit and feedback best practices [
   <a ref-type="bibr" rid="CR12" href="#CR12">12</a>–
   <a ref-type="bibr" rid="CR14" href="#CR14">14</a>] and on information obtained during interviews in accordance with a human-centered design approach [
   <a ref-type="bibr" rid="CR18" href="#CR18">18</a>]. We specifically ensured a selection of measures that are actionable to physicians as this is a known requirement for effective audit and feedback interventions [
   <a ref-type="bibr" rid="CR13" href="#CR13">13</a>, 
   <a ref-type="bibr" rid="CR14" href="#CR14">14</a>]. The primary goal of the dashboard was to reduce overall patient LOS. However, to increase actionability of the measure, we focused on the time that can be influenced directly by physicians. In initial versions, this was the time from first physician to the time the physician makes the disposition decision (i.e. decision to admit to hospital, observation, or discharge). After additional interviews, we modified this to the time from when the patient is roomed until the disposition decision is made, as this more accurately represents the period directly influenced by the attending physician.
  </p>
  <p id="Par37" xmlns="http://www.w3.org/1999/xhtml">Test utilization data, including the percentage of patients with a CT scan, MR scan, ultrasound, and lab test, were included because they affect LOS and are directly controlled by the physician. The number of requested consultations was not included as the data were not readily available in the EMR. Outcome data were included to address concerns about unintended consequences related to the quality of care if the focus was merely on LOS and test utilization. Initially, we included 72-h return rates and number of deaths. However, deaths were excluded from later versions in response to concerns about the reliability of EMR-derived death-data. Hospital LOS after admission was included as a proxy measure of appropriateness of admission, with the assumption that a short LOS might indicate that the patient did not need to be admitted. The total number of patients with the breakdown by timing of shift, area of care, and discharge disposition was included to provide more context about the patient population seen. During iterative rounds of improvements, we added detailed definitions of the measures used and clarified section headers to improve comprehension and trust in the dashboard.</p>
  <p id="Par38" xmlns="http://www.w3.org/1999/xhtml">It was decided to report data by monthly intervals to minimize the effect of day-to-day random variation, but to also ensure physicians still remember what happened during a given period. Comparison data were provided on the “Emergency Department” page showing summary measures for the entire ED. On initial designs, comparison data was shown on the “Personal” page as a ranking that included blinded peer data to provide physicians with achievable goals for improvement. However, further feedback made it clear that a ranking was not perceived as appropriate because the highest or lowest score does not necessarily indicate the best or the worst performance. Instead, it was decided to show the interquartile range of all physicians.</p>
 </sec>
 <sec id="Sec15" class="sec">
  <div class="title" xmlns="http://www.w3.org/1999/xhtml">Survey</div>
  <p id="Par39" xmlns="http://www.w3.org/1999/xhtml">In total, 19 attending physicians (34%) responded to both pre- and post-surveys. Forty-two physicians (75%) responded to the pre-survey which included the clinical vignette and measures for value/interest, perceived competence, autonomy support, teamwork climate, and safety climate. Twenty-one physicians (37.5%) responded to the post-survey which included a mockup of the performance feedback dashboard, the clinical vignette, measures for value/interest, perceived competence, autonomy support, and the perceived usefulness of the dashboard and the perceived ease of use (Additional file 
   <a rid="MOESM3" ref-type="media" href="#MOESM3">3</a>: Table S3). Of the 19 physicians that responded to both surveys, 5 had been involved in the development of the dashboard, 7 physicians had more than 30% of their direct network involved in the development, 5 physicians had less than 30% of their direct network involved, and 2 did not answer the network question. Physicians with less exposure to those involved in the development process tended to have less experience and physicians who were directly involved in the development tended to have a more central position in the ED social network. Although all groups selected a roughly equal number of people to ask for advice (out-degree), physicians who were involved in the development were selected more frequently by others (in-degree), and had numerically higher betweenness scores. Closeness scores were similar between groups (Table 
   <a rid="Tab2" ref-type="table" href="#Tab2">2</a>).
   <div id="Tab2" class="table-wrap">
    <span class="label">Table 2</span>
    <div class="caption">
     <p>Characteristics of survey respondents</p>
    </div>
    <table frame="hsides" rules="groups">
     <thead>
      <tr>
       <th rowspan="2"/>
       <th>Involved</th>
       <th>≥30% of network involved
        <span class="sup">a</span>
       </th>
       <th>&lt; 30% of network involved
        <span class="sup">a</span>
       </th>
       <th>
        <span class="italic">p</span>-value
       </th>
      </tr>
      <tr>
       <th>(
        <span class="italic">n</span> = 5)
       </th>
       <th>(
        <span class="italic">n</span> = 7)
       </th>
       <th>(
        <span class="italic">n</span> = 5)
       </th>
       <th/>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>Male gender – 
        <span class="italic">n (%)</span>
       </td>
       <td>3/5</td>
       <td>5/7</td>
       <td>4/5</td>
       <td>1</td>
      </tr>
      <tr>
       <td>Years experience – 
        <span class="italic">median (IQR)</span>
       </td>
       <td>10 (10–15)</td>
       <td>10 (9–14)</td>
       <td>4 (3–9)</td>
       <td>0.15</td>
      </tr>
      <tr>
       <td>Years in this ED – 
        <span class="italic">median (IQR)</span>
       </td>
       <td>10 (6–13)</td>
       <td>7 (2–9)</td>
       <td>2 (1–5)</td>
       <td>0.29</td>
      </tr>
      <tr>
       <td colspan="5">Network centrality measures
        <span class="sup">a</span>
       </td>
      </tr>
      <tr>
       <td> - Out-degree – 
        <span class="italic">median (IQR)</span>
       </td>
       <td>6 (4–7)</td>
       <td>5 (3–7)</td>
       <td>6 (5–7)</td>
       <td>0.88</td>
      </tr>
      <tr>
       <td> - In-degree – 
        <span class="italic">median (IQR)</span>
       </td>
       <td>6 (4–6)</td>
       <td>3 (2–4)</td>
       <td>3 (2–6)</td>
       <td>0.43</td>
      </tr>
      <tr>
       <td> - Closeness – 
        <span class="italic">median (IQR)</span>
       </td>
       <td>0.29 (0.25–0.31)</td>
       <td>0.30 (0.25–0.33)</td>
       <td>0.32 (0.29–0.34)</td>
       <td>0.66</td>
      </tr>
      <tr>
       <td> - Betweenness – 
        <span class="italic">median (IQR)</span>
       </td>
       <td>158 (129–197)</td>
       <td>112 (59–204)</td>
       <td>88 (34–100)</td>
       <td>0.30</td>
      </tr>
     </tbody>
    </table>
    <div class="table-wrap-foot">
     <p>Characteristics of physicians who responded to both pre- and post-survey, categorized by involvement in the design process: those who were involved in the development, those of which ≥ 30% of their network was involved in the development, and those of which &lt; 30% of their network was involved. Two physicians did not finish the social network question and were not included in the social network analyses</p>
     <p>
      <span class="italic">Abbreviations</span>: 
      <span class="italic">ED</span> emergency department, 
      <span class="italic">IQR</span> interquartile range, 
      <span class="italic">n</span> number
     </p>
     <p>
      <span class="sup">a</span>Network measures were calculated based on the question “Who do you discuss problems with at work?”
     </p>
    </div>
   </div>
  </p>
  <p id="Par40" xmlns="http://www.w3.org/1999/xhtml">When comparing pre- and post-survey responses to the clinical vignette, we did not observe any differences in the percentage of physicians who would order imaging after seeing the prototype dashboard (12/19 pre and 14/19 post; 
   <span class="italic">p</span> = 0.69). There were also no significant changes in the self-determination theory-based motivation measures; median pre- and post-values for value/usefulness were 4.4 (IQR 4.2–5.2) and 5.0 (IQR 4.0–5.8), respectively (
   <span class="italic">p</span> = 0.21); the perceived competence values were 5.5 (IQR 4.3–6.0) and 5.0 (IQR 4.0–6.3), respectively (
   <span class="italic">p</span> = 0.88); and the autonomy support values were 5.0 (IQR 2.8–5.7) and 4.0 (IQR 3.0–6.0), respectively (
   <span class="italic">p</span> = 0.83). We then assessed changes in sub-groups based on the level of exposure to people involved in the development process as determined by the social network analysis. We found that higher exposure was significantly associated with changes in the perceived value/usefulness of making quick disposition decisions (
   <span class="italic">p</span> = 0.048) after seeing the dashboard. The perceived value/usefulness-score of physicians who were directly involved in the development rose by a median of 0.6 points, while the score of physicians with low exposure (&lt; 30% of network was involved) decreased by a median of 0.4 points. Similarly, physicians’ perceived competence in making quick disposition decisions increased in those physicians who were actively involved, and decreased in those with low exposure (NS, 
   <span class="italic">p</span> = 0.059). No differences between groups were observed in change-scores for autonomy support by ED leadership (Fig. 
   <a rid="Fig2" ref-type="fig" href="#Fig2">2</a>). No correlation was observed between the physicians’ perception of the culture in the ED and change scores (Table 
   <a rid="Tab3" ref-type="table" href="#Tab3">3</a>).
   <div id="Fig2" class="fig">
    <span class="label">Fig. 2</span>
    <div class="caption">
     <p>The effects of the performance feedback dashboard on motivation. The effect of the prototype performance feedback dashboard on perceived value/usefulness of making quick disposition decisions, perceived competence in making quick disposition decisions, and perceived autonomy support from emergency department leadership in physicians who were involved in the development (Inv, 
      <span class="italic">n</span> = 5), those of which ≥ 30% of their network was involved in the development (≥30%, 
      <span class="italic">n</span> = 7, high exposure), and those with &lt; 30% (&lt; 30%, 
      <span class="italic">n</span> = 4, low exposure). Horizontal bars represent the group average. Each dot represents a unique observation
     </p>
    </div>
    <div xlink:href="12913_2019_4084_Fig2_HTML" id="MO2" class="graphic" xmlns:xlink="http://www.w3.org/1999/xlink"/>
   </div>
   <div id="Tab3" class="table-wrap">
    <span class="label">Table 3</span>
    <div class="caption">
     <p>Correlation between climate and outcome measures</p>
    </div>
    <table frame="hsides" rules="groups">
     <thead>
      <tr>
       <th rowspan="2"/>
       <th colspan="3">Pre-post (Δ) motivation measures</th>
       <th colspan="5">Dashboard evaluation metrics</th>
      </tr>
      <tr>
       <th>Δ Value/usefulness</th>
       <th>Δ Competence</th>
       <th>Δ Autonomy support</th>
       <th>Usefulness</th>
       <th>Ease of use</th>
       <th>Importance of metrics</th>
       <th>Ability to affect metrics</th>
       <th>Recommend</th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>Teamwork climate</td>
       <td char="(" align="char">−0.02 (0.95)</td>
       <td>0.33 (0.19)</td>
       <td>−0.43 (0.07)</td>
       <td char="(" align="char">−0.07 (0.78)</td>
       <td>0.26 (0.30)</td>
       <td>0.05 (0.84)</td>
       <td>
        <span class="bold">0.48 (0.046)</span>
       </td>
       <td>−0.03 (0.92)</td>
      </tr>
      <tr>
       <td>Safety climate</td>
       <td char="(" align="char">0.24 (0.34)</td>
       <td>0.41 (0.09)</td>
       <td>0.10 (0.69)</td>
       <td char="(" align="char">
        <span class="bold">0.55 (0.019)</span>
       </td>
       <td>
        <span class="bold">0.50 (0.035)</span>
       </td>
       <td>
        <span class="bold">0.54 (0.021)</span>
       </td>
       <td>
        <span class="bold">0.71 (0.001)</span>
       </td>
       <td>
        <span class="bold">0.52 (0.028)</span>
       </td>
      </tr>
     </tbody>
    </table>
    <div class="table-wrap-foot">
     <p>Spearman correlation coefficients (
      <span class="italic">p</span>-value); Significant values in bold. Motivation measures are derived from Self-Determination Theory
     </p>
    </div>
   </div>
  </p>
  <p id="Par41" xmlns="http://www.w3.org/1999/xhtml">While the importance of the metrics on the dashboard was generally rated highly (median 6 out of 7, IQR 4–6) and physicians reported they could affect the measures (median 6 out of 7, IQR 5–6), the perceived usefulness of the overall dashboard was only rated a median of 4 out of 7 (IQR 3–4.5). The median ease of use rating was 5 out of 7 (IQR 4.3–5.5) and physicians rated the likelihood they would recommend the dashboard to their peers as 6 out of 10 (IQR 5–7). When looking at specific subgroups, we found that physicians with little exposure to those involved in the development process rated the importance of the metrics significantly lower than others (
   <span class="italic">p</span> = 0.02, Table 
   <a rid="Tab4" ref-type="table" href="#Tab4">4</a>). A trend towards lower scores for perceived usefulness, ease of use, and likelihood to recommend the dashboard was found in these physicians as well (Table 
   <a rid="Tab4" ref-type="table" href="#Tab4">4</a>). Additionally, moderate correlations between the perceived safety climate and positive evaluations of the dashboard were observed. No correlation was observed between perceived teamwork climate and positive evaluations of the dashboard, except for the ability to affect measures (Table 
   <a rid="Tab3" ref-type="table" href="#Tab3">3</a>).
   <div id="Tab4" class="table-wrap">
    <span class="label">Table 4</span>
    <div class="caption">
     <p>Quantitative assessment of the performance feedback dashboard</p>
    </div>
    <table frame="hsides" rules="groups">
     <thead>
      <tr>
       <th>Outcomes
        <span class="break"/>
        <span class="italic">Median (IQR)</span>
       </th>
       <th>Overall
        <span class="break"/>(
        <span class="italic">n</span> = 21)
       </th>
       <th>Involved
        <span class="break"/>(
        <span class="italic">n</span> = 5)
       </th>
       <th>≥30% of network involved
        <span class="sup">a</span>
        <span class="break"/>(
        <span class="italic">n</span> = 7)
       </th>
       <th>&lt; 30% of network involved
        <span class="sup">a</span>
        <span class="break"/>(
        <span class="italic">n</span> = 5)
       </th>
       <th>
        <span class="italic">p</span>-value
        <span class="break"/>Kruskal-Wallis test
       </th>
      </tr>
     </thead>
     <tbody>
      <tr>
       <td>Perceived usefulness (1–7)</td>
       <td>4 (3–4.5)</td>
       <td>4.3 (4.2–4.5)</td>
       <td>4.2 (4–5.7)</td>
       <td>3.5 (2–4)</td>
       <td>0.36</td>
      </tr>
      <tr>
       <td>Perceived ease of use (1–7)</td>
       <td>5 (4.3–5.5)</td>
       <td>5.5 (5–6.2)</td>
       <td>5 (4.3–6)</td>
       <td>4.3 (3.8–5)</td>
       <td>0.12</td>
      </tr>
      <tr>
       <td colspan="6">Importance of metrics (1–7)</td>
      </tr>
      <tr>
       <td> - LOS</td>
       <td>6 (4–6)</td>
       <td>6 (5–6)</td>
       <td>6 (6–7)</td>
       <td>4 (4–4)</td>
       <td>0.03</td>
      </tr>
      <tr>
       <td> - time to disposition decision</td>
       <td>6 (5–6)</td>
       <td>6 (6–7)</td>
       <td>6 (6–7)</td>
       <td>4 (2–4)</td>
       <td>0.02</td>
      </tr>
      <tr>
       <td> - tests ordered</td>
       <td>6 (5–6)</td>
       <td>5 (5–6)</td>
       <td>6 (6–7)</td>
       <td>4 (2–5)</td>
       <td>0.03</td>
      </tr>
      <tr>
       <td> - metrics overall</td>
       <td>6 (4–6)</td>
       <td>5 (5–6)</td>
       <td>6 (6–7)</td>
       <td>3 (2–4)</td>
       <td>0.02</td>
      </tr>
      <tr>
       <td colspan="6">Ability to affect metrics (1–7)</td>
      </tr>
      <tr>
       <td> - LOS</td>
       <td>5 (4–6)</td>
       <td>6 (5–7)</td>
       <td>6 (5–6)</td>
       <td>5 (4–6)</td>
       <td>0.30</td>
      </tr>
      <tr>
       <td> - time to disposition decision</td>
       <td>6 (5–6)</td>
       <td>6 (5–7)</td>
       <td>6 (5–6)</td>
       <td>6 (5–6)</td>
       <td>0.85</td>
      </tr>
      <tr>
       <td> - tests ordered</td>
       <td>6 (5–7)</td>
       <td>6 (5–7)</td>
       <td>6 (5–7)</td>
       <td>6 (6–6)</td>
       <td>0.97</td>
      </tr>
      <tr>
       <td> - overall metrics</td>
       <td>6 (5–6)</td>
       <td>6 (5–7)</td>
       <td>6 (5–6)</td>
       <td>5 (4–6)</td>
       <td>0.30</td>
      </tr>
      <tr>
       <td>Recommend (0–10)</td>
       <td>6 (5–7)</td>
       <td>7 (6–7)</td>
       <td>6 (5–8)</td>
       <td>3 (2–5)</td>
       <td>0.16</td>
      </tr>
     </tbody>
    </table>
    <div class="table-wrap-foot">
     <p>Post-survey results of the assessment of the performance feedback dashboard. Separate for physicians who were involved in the development, those of which ≥ 30% of the people they discuss problems with were involved (high exposure), and those with &lt; 30% (low exposure). No network data was available for the 2 physicians who didn’t fill out the pre-survey and for 2 physicians who didn’t fill out the network question</p>
     <p>
      <span class="italic">Abbreviations</span>: 
      <span class="italic">IQR</span> interquartile range, 
      <span class="italic">LOS</span> length of stay, 
      <span class="italic">n</span> number
     </p>
     <p>
      <span class="sup">a</span>Based on the question “Who do you discuss problems with at work?”
     </p>
    </div>
   </div>
  </p>
  <p id="Par42" xmlns="http://www.w3.org/1999/xhtml">Physicians’ comments in the survey were analyzed qualitatively. Several physicians commented that the ability to have measures available would be a “step up”, would “provide an incentive”, or would be “interesting”. The visual design of the performance dashboard was described with words such as “clear”, “easy to understand”, “pleasant to look at”, and “user friendly”, though one physician commented it was “big brother controlling”. Other concerns were related to data accuracy, negative consequences on patient care or work culture, and the effect on the teaching environment. Lastly, while benchmarks were visualized on the dashboard using an interquartile range, several physicians commented that a benchmark would be needed in the dashboard for it to be useful, implying that a more intuitive design to display this information needs to be considered.</p>
 </sec>
</sec>
