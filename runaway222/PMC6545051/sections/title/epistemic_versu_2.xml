<?xml version="1.0" encoding="UTF-8"?>
<sec id="s3" class="sec">
 <span class="label" xmlns="http://www.w3.org/1999/xhtml">3.</span>
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Epistemic versus aleatoric uncertainty</div>
 <p xmlns="http://www.w3.org/1999/xhtml">Broadly, uncertainty in climate projections arises from three sources: uncertainty in future climate forcing, in the climate system response to that forcing (i.e. the change in climate) and in the actual realization of climate for a particular time window, which is subject to internal variability. The nature of these uncertainties is very different (e.g. [
  <a rid="RSPA20190013C23" ref-type="bibr" href="#RSPA20190013C23">23</a>]). The first depends primarily on human actions and is called the scenario, and the projections are normally made conditional on the scenario. The second is what is known as an 
  <span class="italic">epistemic</span> uncertainty; there is only one truth, but we do not know what it is. The third is what is known as an 
  <span class="italic">aleatoric</span> uncertainty; there is a random element to what will occur, whose probability is known to some extent. Any discussion of climate risk must address the central fact that the nature of the second and third uncertainties is fundamentally different. This is especially important for circulation-related aspects of climate change at the regional scale, for which these two sources of uncertainty tend to dominate the overall uncertainty (see [
  <a rid="RSPA20190013C24" ref-type="bibr" href="#RSPA20190013C24">24</a>] for regional precipitation changes). Yet, it is standard practice in climate science to mingle the two sources of uncertainty together, e.g. in the multi-model ensembles (with one realization taken from each model) that are in such widespread use [
  <a rid="RSPA20190013C2" ref-type="bibr" href="#RSPA20190013C2">2</a>]. In such ensembles, the differences between the individual model projections include both the systematic differences between different model climates (epistemic) and the random differences that arise from the limited sampling of internal variability (aleatoric). Since only the latter possess an underlying probability distribution, this poses challenges in interpretation [
  <a rid="RSPA20190013C25" ref-type="bibr" href="#RSPA20190013C25">25</a>].
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">We first discuss the uncertainty arising from internal variability, since it is conceptually much easier to deal with. Internal variability is a property of the physical climate system, whose random character arises from the chaotic nature of atmospheric and oceanic dynamics, and which can be characterized from observations. Indeed, the definition of climate includes internal variability, which is characterized through statistical measures such as variances and covariances of physical fields, as well as higher order moments such as skewness or extremes, and includes coherent modes of variability such as the El Niño/Southern Oscillation phenomenon. The uncertainty from internal variability is fundamentally irreducible (leaving aside the possibility of finite-time prediction from specified initial conditions), and users of climate information need to understand that the mantra of ‘reducing uncertainty’ is inappropriate in this case; rather, the scientific goal is to better quantify the uncertainty. The magnitude of the uncertainty for any particular quantity can be reduced by taking coarser spatial and temporal averages, but that operation changes and may simultaneously reduce the value of the information provided.</p>
 <p xmlns="http://www.w3.org/1999/xhtml">The concept of internal variability is not without ambiguity since climate has various sources of non-stationarity, and what is meant by internal variability is conditional on any non-stationary influence, including climate change itself. Furthermore, knowledge of internal variability is limited by the finite observational record, and there is uncertainty in how internal variability will respond to global warming. Nevertheless, in most cases, the main uncertainty in what climate conditions will be experienced at a particular place and time arising from internal variability can be considered to be aleatoric, and thus amenable to a straightforward (i.e. frequentist) probabilistic interpretation. The reliability of model simulations of internal variability can be similarly assessed, at least in principle.</p>
 <p xmlns="http://www.w3.org/1999/xhtml">The uncertainty in the climate response to forcing is conceptually very different. It is not a property of the physical climate system; rather, it is a property of a state of knowledge, or degree of belief, and it 
  <span class="italic">can</span> be reduced as knowledge improves. In contrast with aleatoric uncertainty, which is objective, such epistemic uncertainty is 
  <span class="italic">subjective</span> [
  <a rid="RSPA20190013C26" ref-type="bibr" href="#RSPA20190013C26">26</a>]. Therefore, treating epistemic uncertainty as if it were aleatoric, with a focus on the multi-model mean as a best estimate, has no epistemological justification. This has been recognized for some time [
  <a rid="RSPA20190013C21" ref-type="bibr" href="#RSPA20190013C21">21</a>,
  <a rid="RSPA20190013C27" ref-type="bibr" href="#RSPA20190013C27">27</a>,
  <a rid="RSPA20190013C28" ref-type="bibr" href="#RSPA20190013C28">28</a>], but the practice continues to be normative (e.g. as in 
  <a ref-type="fig" rid="RSPA20190013F1" href="#RSPA20190013F1">figure 1</a>). It is interesting to consider why this is so, since, in most areas of science, the essential distinction between systematic and random sources of uncertainty is well recognized. One of the reasons may be that the extent of the epistemic uncertainty is not particularly well known. First, climate models are imperfect representations of reality and share many deficiencies, thus they may exhibit a collective bias and fail to explore important aspects of climate change. Second, even within the world represented by climate models, the forced circulation response of any particular model is obscured by internal variability.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">As an example of the latter, Deser 
  <span class="italic">et al</span>. [
  <a rid="RSPA20190013C29" ref-type="bibr" href="#RSPA20190013C29">29</a>] estimate that, for NH wintertime mid-latitude surface pressure (whose spatial gradient provides an indicator of circulation changes), ensemble sizes of around 30 are generally needed to determine the forced decadal changes of a given model over a 45 year period. This is in striking contrast to surface temperature changes, where the signal-to-noise ratio of the forced response is much larger, and even single simulations can be informative. One might be tempted to think that if such a large ensemble size is needed to detect the signal, then the signal must be small. However, Deser 
  <span class="italic">et al</span>. [
  <a rid="RSPA20190013C29" ref-type="bibr" href="#RSPA20190013C29">29</a>] show that such a change in surface pressure patterns can alter the risk of regional drought or heavy precipitation by a factor of two, which is hardly negligible. Most climate model simulations are performed with much smaller ensemble sizes, although there is a growing interest in large single-model ensembles in order to better characterize the epistemic uncertainty within current models.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">Another conceptual challenge in dealing with the epistemic uncertainty of climate change is that the concept of ‘error’ is not well defined. Although in principle there may be one truth, it is not knowable: there will never be sufficient observations to define all relevant aspects of future climate; future climate will in any case be non-stationary; and model projections are based on climate forcing scenarios that will not be the ones actually realized. Thus, there has been interest in trying to understand the relationship between model errors in observable aspects of climate and the forced response simulated by that model—so-called emergent constraints (e.g. [
  <a rid="RSPA20190013C30" ref-type="bibr" href="#RSPA20190013C30">30</a>]). Such an approach permits a Bayesian probabilistic interpretation of epistemic uncertainty [
  <a rid="RSPA20190013C31" ref-type="bibr" href="#RSPA20190013C31">31</a>]. However, there is a danger that any such relationship is merely statistical and not causal, and many published emergent constraints have been subsequently debunked (see [
  <a rid="RSPA20190013C32" ref-type="bibr" href="#RSPA20190013C32">32</a>–
  <a rid="RSPA20190013C34" ref-type="bibr" href="#RSPA20190013C34">34</a>]). In any case, subjective choices are required in the application of any such constraints.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">That an aleatoric interpretation of multi-model ensembles can blur the climate information contained within those ensembles is not difficult to appreciate. Circulation aspects of climate are related to features such as jet streams. Over Europe during wintertime, some models show an increase in jet strength under climate change and others a decrease (see fig. 4 of [
  <a rid="RSPA20190013C1" ref-type="bibr" href="#RSPA20190013C1">1</a>]); moreover, the location of the changes varies between models. While all models predict a significant jet response somewhere, averaging over the models will lead to a washed-out response. Thus, the multi-model mean may not only be unlikely, but even implausible. The situation is analogous to the idealized case of a bi-modal probability density function, whose mean may not be a physically realizable state.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">A related issue is apparent in 
  <a ref-type="fig" rid="RSPA20190013F1" href="#RSPA20190013F1">figure 1</a>. Because precipitation increases in some regions and decreases in others, the multi-model mean change inevitably passes through zero, and will be small compared with internal variability on either side of that line. However, that does not mean that the change in those regions can be expected to be small compared with internal variability; it just reflects uncertainty in the sign of the change. When there are equally plausible futures that point in different directions, averaging those futures buries relevant information and underestimates risk.
 </p>
 <p xmlns="http://www.w3.org/1999/xhtml">The essential point is that epistemic uncertainties are deterministic, which means that they introduce correlations; unless those correlations are accounted for, inferences may be flawed. For example, Madsen 
  <span class="italic">et al</span>. [
  <a rid="RSPA20190013C35" ref-type="bibr" href="#RSPA20190013C35">35</a>] show that the spread across Coupled Model Intercomparison Project Phase 5 (CMIP5) model projections in temperature and precipitation changes at the gridpoint scale is significantly exaggerated when treating the gridpoints independently, as compared with when the models are ranked by the global-mean changes (where the spread comes mainly from climate sensitivity). This illustrates the general point that, with an inhomogeneous distribution of estimators, one should examine the distribution of responses to a perturbation rather than the overall response of the distribution to the perturbation.
 </p>
</sec>
