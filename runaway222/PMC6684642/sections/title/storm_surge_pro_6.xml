<?xml version="1.0" encoding="UTF-8"?>
<sec id="Sec6" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">Storm surge projections</div>
 <p id="Par18" xmlns="http://www.w3.org/1999/xhtml">We compare stationary (i.e., not time varying) storm surge projections from four studies
  <span class="sup">
   <a ref-type="bibr" rid="CR6" href="#CR6">6</a>,
   <a ref-type="bibr" rid="CR18" href="#CR18">18</a>–
   <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
  </span> to historical observations and projections from an alternative model discussed below (details in Methods). Additionally, we compare stationary storm surge values to non-stationary values in the year 2065. These values are available to decision makers for the Sewell’s Point tide gauge location, are relative to the current NOAA national tidal datum epoch (NTDE; 1983–2001) local mean sea level (MSL), and are compared to historical observations
  <span class="sup">
   <a ref-type="bibr" rid="CR47" href="#CR47">47</a>
  </span>.
 </p>
 <p id="Par19" xmlns="http://www.w3.org/1999/xhtml">Zervas
  <span class="sup">
   <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
  </span> analyzes monthly mean highest water levels over a period from 1927–2010. In order to remove the longer-term signal, Zervas
  <span class="sup">
   <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
  </span> linearly detrends the data by removing the mean sea-level trend (based on data up to 2006), which is relative to the NTDE midpoint. These detrended monthly extremes are used to obtain the annual block maximum (the maximum observation in each year) if a year has four or more months of data. If a year has less than four months of data, then no annual block maxima is estimated for that year. Zervas
  <span class="sup">
   <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
  </span> fits the annual block maxima to a Generalized Extreme Value (GEV) distribution using the extRemes R package
  <span class="sup">
   <a ref-type="bibr" rid="CR48" href="#CR48">48</a>,
   <a ref-type="bibr" rid="CR49" href="#CR49">49</a>
  </span> for estimation of the location, scale, and shape parameters. Using the maximum likelihood estimate of the GEV parameters and a range of exceedance probabilities, Zervas
  <span class="sup">
   <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
  </span> approximates flood return levels with a 95% confidence interval.
 </p>
 <p id="Par20" xmlns="http://www.w3.org/1999/xhtml">The U.S. Army Corps of Engineers
  <span class="sup">
   <a ref-type="bibr" rid="CR6" href="#CR6">6</a>
  </span> study uses the same historic monthly extreme water level values as Zervas
  <span class="sup">
   <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
  </span>, but analyzes a shorter time period from 1927 to 2007. Instead of following the GEV approach laid out in Zervas
  <span class="sup">
   <a ref-type="bibr" rid="CR20" href="#CR20">20</a>
  </span>, the U.S. Army Corps of Engineers
  <span class="sup">
   <a ref-type="bibr" rid="CR6" href="#CR6">6</a>
  </span> study follows a percentile statistical function
  <span class="sup">
   <a ref-type="bibr" rid="CR50" href="#CR50">50</a>
  </span> and only presents return periods that are within the time frame of the data record. For instance, they do not present the 100-yr return period for Sewell’s Point tide gauge because the data record is less than 100 years in length.
 </p>
 <p id="Par21" xmlns="http://www.w3.org/1999/xhtml">Tebaldi 
  <span class="italic">et al</span>.
  <span class="sup">
   <a ref-type="bibr" rid="CR19" href="#CR19">19</a>
  </span> uses a combination of hourly (1979–2008) and monthly (1959–2008) data. Assuming the long-term trends in local sea level are linear, Tebaldi 
  <span class="italic">et al</span>.
  <span class="sup">
   <a ref-type="bibr" rid="CR19" href="#CR19">19</a>
  </span> detrends the hourly data using a linear model fit to the monthly data. These detrended hourly values are used to compute the daily maxima and to perform a peak-over-threshold (POT) analysis. Tebaldi 
  <span class="italic">et al</span>.
  <span class="sup">
   <a ref-type="bibr" rid="CR19" href="#CR19">19</a>
  </span> performs a POT analysis by selecting a threshold corresponding to the 99th percentile and identifying daily values exceeding that threshold. To avoid counting a storm twice, Tebaldi 
  <span class="italic">et al</span>.
  <span class="sup">
   <a ref-type="bibr" rid="CR19" href="#CR19">19</a>
  </span> uses a 1-day declustering timescale identifying the maximum value among consecutive extremes. The exceedance values identified in the POT analysis are fit to a Generalized Pareto distribution (GPD) for parameter estimation. Using the maximum likelihood estimate of the GPD parameters, Tebaldi 
  <span class="italic">et al</span>.
  <span class="sup">
   <a ref-type="bibr" rid="CR19" href="#CR19">19</a>
  </span> computes flood return levels and return periods with a 95% confidence interval.
 </p>
 <p id="Par22" xmlns="http://www.w3.org/1999/xhtml">Wong
  <span class="sup">
   <a ref-type="bibr" rid="CR18" href="#CR18">18</a>
  </span> analyzes 86 years (1928–2013) of hourly data from the tide gauge to generate storm surge projections. First, Wong
  <span class="sup">
   <a ref-type="bibr" rid="CR18" href="#CR18">18</a>
  </span> detrends the data by subtracting a moving window 1-year average and calculates the daily maximum sea levels with the detrended data. Like the analysis in Tebaldi 
  <span class="italic">et al</span>.
  <span class="sup">
   <a ref-type="bibr" rid="CR19" href="#CR19">19</a>
  </span>, Wong
  <span class="sup">
   <a ref-type="bibr" rid="CR18" href="#CR18">18</a>
  </span> uses the 99th percentile as the threshold for extreme events. However, Wong
  <span class="sup">
   <a ref-type="bibr" rid="CR18" href="#CR18">18</a>
  </span> differs by using a declustering timescale of 3 days to identify the maximum value among consecutive extremes. The exceedance values are then fit to a GPD model for parameter estimation using a Bayesian calibration approach with an adaptive Metropolis Hastings algorithm, where non-stationarity is incorporated into the parameters. Non-stationarity is incorporated using several covariates: time, sea level, global mean temperature, the North Atlantic Oscillation (NAO) index, and a combination of all the covariates generated by applying Bayesian model averaging.
 </p>
</sec>
