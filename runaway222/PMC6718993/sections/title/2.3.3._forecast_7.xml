<?xml version="1.0" encoding="UTF-8"?>
<sec id="sec2dot3dot3-ijerph-16-02890" class="sec">
 <div class="title" xmlns="http://www.w3.org/1999/xhtml">2.3.3. Forecast Verification </div>
 <p xmlns="http://www.w3.org/1999/xhtml">With the aim to monitor and improve the forecast quality (the ability of a model to correctly predict an event, that is the degree of agreement between the forecasts and the corresponding observations), the forecasts during summer 2018 were verified against observations. For this purpose, a thorough comparison of the daily WBGT forecasts against the corresponding observed values at the 1798 representative meteorological stations used for downscaling and bias correction procedures was carried out. The probabilistic component of ensemble forecasts requires diverse metrics to characterize their quality in terms of accuracy, reliability association, and discrimination [
  <a rid="B30-ijerph-16-02890" ref-type="bibr" href="#B30-ijerph-16-02890">30</a>,
  <a rid="B62-ijerph-16-02890" ref-type="bibr" href="#B62-ijerph-16-02890">62</a>]. In this work, the continuous ranked probability score (CRPS) was used to assess the accuracy of the forecasts [
  <a rid="B63-ijerph-16-02890" ref-type="bibr" href="#B63-ijerph-16-02890">63</a>]. This metric is widely used in forecast verification and represents the ensemble version of the mean absolute error. It is sensitive to the bias in the ensemble mean and to the over- or under-dispersion of the ensemble (i.e., it also penalizes ensembles with large spread even when having a good ensemble mean prediction). The score can be expressed as a skill score (SS) relative to a reference forecast (CRPSS). A positive CRPSS indicates a better performance of the forecast compared to the reference (perfect score of 1), CRPSS = 0 means that the forecast is as good as the reference and negative scores indicate lower skill than the reference. In this work, the CRPSS of the bias-corrected forecasts is obtained considering two possible reference datasets: (1) Raw forecasts (non-bias-corrected) and (2) observations from the past 20 years (which mimic a 20-member ensemble, hereafter climatological forecasts). The former shows potential added value of the bias-corrected forecasts with respect to the uncorrected forecasts, whereas the latter represents the skill of the forecasts with respect to a naive forecast based on climatological observations. Daily CRPS values were averaged into weekly values (week 1 spans from day 5 to day 11, week 2 from day 12 to day 18, week 3 from day 19 to day 25, week 4 from day 26 to day 32). Final CRPSSs were obtained from the weekly CRPS, for each European location. The verification was conducted considering forecasts which span from April to September 2018, i.e., 40 forecasts.
 </p>
</sec>
